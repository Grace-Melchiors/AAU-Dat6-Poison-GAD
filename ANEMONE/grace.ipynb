{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([False, False, False,  ..., False, False, False])\n",
      "node_attrs\n",
      "[[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "adj\n",
      "SparseTensor(row=tensor([   0,    0,    0,  ..., 2707, 2707, 2707]),\n",
      "             col=tensor([ 633, 1862, 2582,  ...,  598, 1473, 2706]),\n",
      "             val=tensor([1., 1., 1.,  ..., 1., 1., 1.]),\n",
      "             size=(2708, 2708), nnz=11054, density=0.15%)\n",
      "labels\n",
      "tensor([0, 0, 0,  ..., 0, 0, 0])\n",
      "Create triples...\n",
      "Done creating triples...\n",
      "Making model...\n",
      "Starting attack...\n",
      "initial active subnetworkscore: 1.8646916462163183\n",
      "--- In attack stage ---\n",
      "-2 [   2.         1986.            3.76079248]\n",
      "iter 1 active subnetworkscore: 1.4100335427135857\n",
      "-2 [   2.         1666.            2.22937198]\n",
      "iter 2 active subnetworkscore: 0.9340035729301503\n",
      "Running model on poisoned data...\n",
      "torch.Size([2, 0])\n",
      "torch.Size([3665278, 3])\n",
      "auc before poison:\n",
      "0.7675661196639035\n",
      "auc after poison:\n",
      "0.7664382789150171\n",
      "tensor([False, False, False,  ..., False, False, False])\n",
      "node_attrs\n",
      "[[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "adj\n",
      "SparseTensor(row=tensor([   0,    0,    0,  ..., 2707, 2707, 2707]),\n",
      "             col=tensor([ 633, 1862, 2582,  ...,  598, 1473, 2706]),\n",
      "             val=tensor([1., 1., 1.,  ..., 1., 1., 1.]),\n",
      "             size=(2708, 2708), nnz=11054, density=0.15%)\n",
      "labels\n",
      "tensor([0, 0, 0,  ..., 0, 0, 0])\n",
      "Create triples...\n",
      "Done creating triples...\n",
      "Making model...\n",
      "Starting attack...\n",
      "initial active subnetworkscore: 1.8646916462163183\n",
      "--- In attack stage ---\n",
      "-2 [   2.         1986.            3.76079248]\n",
      "iter 1 active subnetworkscore: 1.4100335427135857\n",
      "-2 [   2.         1666.            2.22937198]\n",
      "iter 2 active subnetworkscore: 0.9340035729301503\n",
      "Running model on poisoned data...\n",
      "torch.Size([2, 0])\n",
      "torch.Size([3665278, 3])\n",
      "auc before poison:\n",
      "0.7682569221225962\n",
      "auc after poison:\n",
      "0.766253594992387\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(<Utils.experiment_results.Experiment at 0x240edd88ee0>,\n",
       " <Utils.experiment_results.Experiment at 0x240a673f070>)"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import sys\n",
    "\n",
    "sys.path.append('..')\n",
    "from Poison.greedy import run_greedy\n",
    "\n",
    "run_greedy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#testing with cat\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([], size=(2, 0))\n",
      "tensor([[0.7104, 0.5231, 0.6517],\n",
      "        [0.7096, 0.3245, 0.9439],\n",
      "        [0.5093, 0.8295, 0.1232],\n",
      "        [0.3547, 0.3124, 0.0160],\n",
      "        [0.7869, 0.4176, 0.4849],\n",
      "        [0.4530, 0.8849, 0.4267],\n",
      "        [0.8729, 0.3182, 0.3065],\n",
      "        [0.6186, 0.6048, 0.8804],\n",
      "        [0.9447, 0.1017, 0.5970],\n",
      "        [0.7629, 0.1596, 0.3819]])\n",
      "torch.Size([10, 3])\n",
      "torch.Size([3, 10])\n",
      "tensor([[0.7104, 0.7096, 0.5093, 0.3547, 0.7869, 0.4530, 0.8729, 0.6186, 0.9447,\n",
      "         0.7629],\n",
      "        [0.5231, 0.3245, 0.8295, 0.3124, 0.4176, 0.8849, 0.3182, 0.6048, 0.1017,\n",
      "         0.1596]])\n",
      "tensor([[0.5231, 0.3245, 0.8295, 0.3124, 0.4176, 0.8849, 0.3182, 0.6048, 0.1017,\n",
      "         0.1596],\n",
      "        [0.7104, 0.7096, 0.5093, 0.3547, 0.7869, 0.4530, 0.8729, 0.6186, 0.9447,\n",
      "         0.7629]])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "x = torch.tensor([[],[]])\n",
    "\n",
    "print(x)\n",
    "\n",
    "y = torch.rand(10,3)\n",
    "\n",
    "print(y)\n",
    "print(y.shape)\n",
    "y = torch.transpose(y, 0, 1)\n",
    "print(y.shape)\n",
    "# y_split = y[:2]\n",
    "# print(y_split)\n",
    "\n",
    "for i in range(10):\n",
    "    x = torch.cat((x, y[:2, i:i+1]), dim=-1)\n",
    "\n",
    "print(x)\n",
    "print(torch.flip(x, dims=[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "from torch.autograd import Variable\n",
    "from torch_sparse import SparseTensor\n",
    "\n",
    "# parser = argparse.ArgumentParser(description='')\n",
    "# parser = argparse.ArgumentParser()\n",
    "# parser.add_argument('--seed', type=int, default=666, help='Random seed.')\n",
    "# parser.add_argument('--dataset', type=str, default='citeseer', choices=['bitcoin_alpha','ca_grqc','wikivote','cora_ml','citeseer','blogcatalog'], help='dataset')\n",
    "# parser.add_argument('--trial', type=int, default=1, choices=[1,2,3,4,5], help='trial')\n",
    "# parser.add_argument('--size', type=int, default=10, choices=[10,30], help='target nodes size')\n",
    "# parser.add_argument('--B', type=int, default=35, choices=[35], help='budget B')\n",
    "# parser.add_argument('--device', type=str, default='cuda', choices=['cuda','cpu'], help='device')\n",
    "\n",
    "# args = parser.parse_args()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#target_node_lst = np.loadtxt(root_dir + '/dataset/'+args.dataset+'/' + 'rand'+ str(args.size) + '_' + str(args.trial) + '.txt').astype('int')\n",
    "\n",
    "#mod_dir = root_dir + '/dataset/'+args.dataset+'/GradMaxSearch/' + 'rand'+ str(args.size) + '_' + str(args.trial)\n",
    "\n",
    "# try:\n",
    "#     os.makedirs(mod_dir)\n",
    "# except:\n",
    "#     pass\n",
    "\n",
    "class multiple_AS(nn.Module):\n",
    "    def __init__(self, target_lst, n_node, device):\n",
    "        \"\"\"\n",
    "            target_lst (numpy.ndarray): The target list to be initialized.\n",
    "            n_node (int): The number of nodes.\n",
    "            device (str): The device to be used.\n",
    "\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "        self.lst = target_lst\n",
    "        self.n = n_node\n",
    "        self.device = device\n",
    "    \n",
    "    def adjacency_matrix(self, tri):\n",
    "        A = torch.sparse_coo_tensor(tri[:,:2].T, tri[:,2], size=[self.n,self.n]).to_dense()\n",
    "        A = A + A.T - torch.diag(torch.diag(A)) # symmetric.\n",
    "        return A\n",
    "    \n",
    "    def sparse_matrix_power(self, A, tau):\n",
    "        A_sp = A.to_sparse()\n",
    "        A_sp = torch.sparse_coo_tensor(A_sp.indices(), A_sp.values(), size=[self.n,self.n])\n",
    "        return torch.sparse.mm(torch.sparse.mm(A_sp, A_sp), A_sp).to_dense()\n",
    "    \n",
    "    def extract_NE(self, A):    # Extract node and edge information based on adjecency matrix\n",
    "        N = torch.sum(A, 1)\n",
    "        E = torch.sum(A, 1) + 0.5 * torch.diag(self.sparse_matrix_power(A, 3)).T\n",
    "        N = N.reshape(-1,1)\n",
    "        E = E.reshape(-1,)\n",
    "        return N, E\n",
    "    \n",
    "    def OLS_estimation(self, N, E):\n",
    "        \"\"\"\n",
    "        OLS estimation function that calculates the Ordinary Least Squares estimate.\n",
    "        \n",
    "        Parameters:\n",
    "            N (tensor): Input tensor for independent variable N\n",
    "            E (tensor): Input tensor for dependent variable E\n",
    "        \n",
    "        Returns:\n",
    "            tensor: Tensor result of the OLS estimation\n",
    "        \"\"\"\n",
    "        logN = torch.log(N + 1e-20)\n",
    "        logE = torch.log(E + 1e-20)\n",
    "        logN1 = torch.cat((torch.ones((len(logN),1)).to(self.device), logN), 1)\n",
    "        return torch.linalg.pinv(logN1) @ logE\n",
    "        \n",
    "    def forward(self, tri): # Calculate the loss function\n",
    "        A = self.adjacency_matrix(tri)\n",
    "        N, E = self.extract_NE(A)\n",
    "        theta = self.OLS_estimation(N, E)\n",
    "        b = theta[0]\n",
    "        w = theta[1]\n",
    "        tmp = 0.\n",
    "        for i in range(len(self.lst)):\n",
    "            tmp += (torch.exp(b) * (N[self.lst[i]]**w) - E[self.lst[i]])**2\n",
    "        return tmp\n",
    "    \n",
    "    def true_AS(self, tri): # Calculate the true active subnetworkscore by using OLS (How influential is this subnetwork)\n",
    "        A = self.adjacency_matrix(tri)\n",
    "        N, E = self.extract_NE(A)\n",
    "        theta = self.OLS_estimation(N, E)\n",
    "        b = theta[0]\n",
    "        w = theta[1] \n",
    "        tmp = 0.\n",
    "        for i in range(len(self.lst)):\n",
    "            tmp += (torch.max(E[self.lst[i]],torch.exp(b)*(N[self.lst[i]]**w))\\\n",
    "                   /torch.min(E[self.lst[i]],torch.exp(b)*(N[self.lst[i]]**w)))*\\\n",
    "                    torch.log(torch.abs(E[self.lst[i]]-torch.exp(b)*(N[self.lst[i]]**w))+1)\n",
    "        return tmp\n",
    "\n",
    "def Poison_attack(model, triple, B):\n",
    "    triple_copy = triple.copy()\n",
    "    #np.savetxt(mod_dir+'/triple_mod_'+str(0)+'.txt',triple_copy,fmt='%d')\n",
    "    triple_torch = Variable(torch.from_numpy(triple_copy), requires_grad = True)\n",
    "    AS = []\n",
    "    perturb = []\n",
    "    AS.append(model.true_AS(triple_torch).data.numpy()[0])\n",
    "    print('initial active subnetworkscore:', model.true_AS(triple_torch).data.numpy()[0])\n",
    "    \n",
    "\n",
    "    print(\"--- In attack stage ---\")\n",
    "\n",
    "    for i in range(1,B+1):\n",
    "        loss = model.forward(triple_torch)\n",
    "        loss.backward()\n",
    "        \n",
    "        tmp = triple_torch.grad.data.numpy()\n",
    "\n",
    "\n",
    "        grad = np.concatenate((triple_torch[:,:2].data.numpy(),tmp[:,2:]),1)\n",
    "        \n",
    "\n",
    "        v_grad = np.zeros((len(grad),3))\n",
    "\n",
    "        for j in range(len(grad)):\n",
    "            v_grad[j,0] = grad[j,0]\n",
    "            v_grad[j,1] = grad[j,1]\n",
    "            if triple_copy[j,2] == 0 and grad[j,2] < 0:\n",
    "                v_grad[j,2] = grad[j,2]\n",
    "            elif triple_copy[j,2] == 1 and grad[j,2] > 0:\n",
    "                v_grad[j,2] = grad[j,2]\n",
    "            else:\n",
    "                continue\n",
    "        v_grad = v_grad[np.abs(v_grad[:,2]).argsort()]\n",
    "        # attack w.r.t gradient information.\n",
    "        K = -1\n",
    "\n",
    "        while v_grad[K][:2].astype('int').tolist() in perturb:\n",
    "            K -= 1\n",
    "            \n",
    "            \n",
    "        # do not delete edge from singleton.\n",
    "        while v_grad[int(K)][2] > 0 and \\\n",
    "             (model.adjacency_matrix(triple_torch).data.numpy()[int(v_grad[int(K)][0])].sum() <= 1 or \\\n",
    "              model.adjacency_matrix(triple_torch).data.numpy()[int(v_grad[int(K)][1]) ].sum() <= 1):\n",
    "            K -= 1\n",
    "        \n",
    "        target_grad = v_grad[int(K)]\n",
    "        print(K, target_grad)\n",
    "        target_index = np.where(np.all((triple[:,:2] == target_grad[:2]), axis = 1) == True)[0][0]\n",
    "        triple_copy[target_index,2] -= np.sign(target_grad[2])\n",
    "        #np.savetxt(mod_dir+'/triple_mod_'+str(i)+'.txt',triple_copy,fmt='%d')\n",
    "        triple_torch = Variable(torch.from_numpy(triple_copy), requires_grad = True)\n",
    "        perturb.append([int(target_grad[0]),int(target_grad[1])])\n",
    "        true_AScore = model.true_AS(triple_torch).data.numpy()[0]\n",
    "        AS.append(true_AScore)\n",
    "        print('iter', i, 'active subnetworkscore:', true_AScore)\n",
    "    AS = np.array(AS)    \n",
    "\n",
    "    # From Local Dice: \n",
    "    # # 5. build perturbed adjacency\n",
    "    # A_rows, A_cols, A_vals = adj.coo()\n",
    "    # A_idx = torch.stack([A_rows, A_cols], dim=0)\n",
    "\n",
    "    # is_before = A_rows < model.lst\n",
    "    # is_after = A_rows > node_idx\n",
    "\n",
    "    # i_col = (\n",
    "    #     torch.cat([neighbors_idx[~delete_neighbors_mask], add_neighbors_idx], dim=0)\n",
    "    #     .sort()\n",
    "    #     .values\n",
    "    # )\n",
    "    # i_row = torch.full_like(i_col, node_idx)\n",
    "    # i_idx = torch.stack([i_row, i_col], dim=0)\n",
    "    # i_val = torch.ones(i_idx.shape[1])\n",
    "\n",
    "    # A_idx = torch.cat((A_idx[:, is_before], i_idx, A_idx[:, is_after]), dim=-1)\n",
    "    # A_weights = torch.cat((A_vals[is_before], i_val, A_vals[is_after]), dim=-1)\n",
    "\n",
    "    # triple_sparse = SparseTensor.from_edge_index(\n",
    "    #         A_idx, A_weights, (self.n, self.n)\n",
    "    #     )\n",
    "    \n",
    "    # return triple_sparse, AS\n",
    "\n",
    "    # Assuming triple_torch_data is a tuple of three tensors representing the COO format\n",
    "    # Create a sparse tensor from the COO format data\n",
    "\n",
    "    #convert to sparse\n",
    "\n",
    "    sparse_tensor = triple_torch.to_sparse()\n",
    "\n",
    "    return triple_torch, AS\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([False, False, False,  ..., False, False, False])\n",
      "node_attrs\n",
      "[[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "adj\n",
      "SparseTensor(row=tensor([   0,    0,    0,  ..., 2707, 2707, 2707]),\n",
      "             col=tensor([ 633, 1862, 2582,  ...,  598, 1473, 2706]),\n",
      "             val=tensor([1., 1., 1.,  ..., 1., 1., 1.]),\n",
      "             size=(2708, 2708), nnz=11054, density=0.15%)\n",
      "labels\n",
      "tensor([0, 0, 0,  ..., 0, 0, 0])\n",
      "Create triples...\n",
      "Done creating triples...\n",
      "Making model...\n",
      "Starting attack...\n",
      "initial active subnetworkscore: 1.8646916462163183\n",
      "--- In attack stage ---\n",
      "-2 [   2.         1986.            3.76079248]\n",
      "iter 1 active subnetworkscore: 1.4100335427135857\n",
      "-2 [   2.         1666.            2.22937198]\n",
      "iter 2 active subnetworkscore: 0.9340035729301503\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from pygod.detector import DOMINANT\n",
    "import torch_geometric.transforms as T\n",
    "from torch_geometric.datasets import Planetoid\n",
    "from Utils.graph_utils import prepare_graph, adj_matrix_sparse_coo_to_dense\n",
    "from Utils.poison_utils import poison_n_nodes\n",
    "from Utils.experiment_results import Experiment\n",
    "from Poison.local_dice import LocalDICE\n",
    "from pygod.metric import eval_roc_auc\n",
    "import torch\n",
    "from pygod.utils import load_data\n",
    "import copy\n",
    "from typing import Tuple, List, Any\n",
    "\n",
    "import sys\n",
    "\n",
    "from sklearn.metrics import (\n",
    "roc_auc_score,\n",
    "average_precision_score,\n",
    "f1_score\n",
    ")\n",
    "\n",
    "\n",
    "sys.path.append('..')\n",
    "#data = Planetoid(\"./data/Cora\", \"Cora\", transform=T.NormalizeFeatures())[0]\n",
    "data = load_data(\"inj_cora\")\n",
    "y_binary: List[int] = data.y.bool()\n",
    "print(y_binary)\n",
    "\n",
    "detector = DOMINANT(hid_dim=64, num_layers=4, epoch=100)\n",
    "detector.fit(data)\n",
    "\n",
    "pred, score, prob, conf = detector.predict(data,\n",
    "                                    return_pred=True,\n",
    "                                    return_score=True,\n",
    "                                    return_prob=True,\n",
    "                                    return_conf=True)\n",
    "experiment_before_poison = Experiment(data=data, pred=pred, prob=prob, score=score, conf=conf)\n",
    "\n",
    "node_attr, adj, labels = prepare_graph(data)\n",
    "\n",
    "\n",
    "amount_of_nodes = data.num_nodes\n",
    "\n",
    "# 'triple' is a list that will store the perturbed triples during the poisoning process.\n",
    "# Each triple represents an edge modification in the form of (node1, node2, edge_label).\n",
    "\n",
    "\n",
    "dense_adj = adj.to_dense()  #Fill in zeroes where there are no edges\n",
    "\n",
    "\n",
    "print(\"Create triples...\")\n",
    "triple = []\n",
    "for i in range(amount_of_nodes):\n",
    "    for j in range(i+1,amount_of_nodes):\n",
    "        triple.append([i,j,dense_adj[i,j]])  #Fill with 0, then insert actual after\n",
    "\n",
    "\n",
    "triple = np.array(triple)\n",
    "\n",
    "print(\"Done creating triples...\")\n",
    "\n",
    "\n",
    "# flat_adj = torch.flatten(dense_adj)    #Flatten the matrix to 1 dim (list)\n",
    "# #print(dense_adj)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# print(\"Create triples...\")\n",
    "# trple = []\n",
    "# for i in range(amount_of_nodes):\n",
    "#     for j in range(i+1,amount_of_nodes):\n",
    "#         triple.append([i,j,flat_adj[amount_of_nodes*i,j]])  #Fill with 0, then insert actual after\n",
    "\n",
    "# print(\"Done creating triples...\")\n",
    "\n",
    "# print(triple)\n",
    "\n",
    "# triple = np.array(triple)\n",
    "\n",
    "\n",
    "\n",
    "target_node_lst = np.array([2,3,5])\n",
    "\n",
    "print(\"Making model...\")\n",
    "model = multiple_AS(target_lst = target_node_lst, n_node = amount_of_nodes, device = 'cpu')\n",
    "\n",
    "budget = 2\n",
    "\n",
    "print(\"Starting attack...\")\n",
    "\n",
    "adj_adversary, AS = Poison_attack(model, triple, budget)\n",
    "#np.savetxt(mod_dir+'/AS.txt',AS)\n",
    "#plt.plot(AS)\n",
    "\n",
    "# ld = LocalDICE(adj=adj, attr=node_attr, labels=labels, target_node_id=2)\n",
    "# # Todo: Vary perburtations\n",
    "# ld, node_idxs = poison_n_nodes(ld, 10, 75)\n",
    "# print(\"These are the node_idxs: ${}\".format(node_idxs))\n",
    "\n",
    "\n",
    "# Convert adversary adjecency matrix into compatible dense tensor\n",
    "#adj_adversary = adj_matrix_sparse_coo_to_dense(ld.adj_adversary)\n",
    "#adj_adversary = adj_matrix_sparse_coo_to_dense(A_mod)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running model on poisoned data...\n",
      "torch.Size([2, 0])\n",
      "torch.Size([3665278, 3])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Data compare ---\n",
      "Data(x=[2708, 1433], edge_index=[2, 11060], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], s=[2708, 2708])\n",
      "auc before poison:\n",
      "0.7692494219816163\n",
      "auc after poison:\n",
      "0.7666102746292224\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(\"Running model on poisoned data...\")\n",
    "\n",
    "# Create Edge Index'\n",
    "#edge_index = torch.tensor([torch.tensor([]), torch.tensor([])], dtype=torch.long)\n",
    "edge_index = torch.tensor([[],[]])\n",
    "print(edge_index.shape)\n",
    "\n",
    "#adj_adversary = adj_adversary.type(torch.int64)\n",
    "\n",
    "print(adj_adversary.shape)\n",
    "# Transpose it to make shape compatible\n",
    "transposed_adj_adversary = torch.transpose(adj_adversary, 0, 1)\n",
    "\n",
    "for i in range(len(adj_adversary)):\n",
    "    if(adj_adversary[i][2] != 0):\n",
    "        #Add edge to edge index \n",
    "        edge_index = torch.cat((edge_index, transposed_adj_adversary[:2, i:i+1]), -1)\n",
    "        # edge_index[0] = torch.cat((edge_index[0], torch.tensor([adj_adversary[i][0]])))\n",
    "        # edge_index[1] = torch.cat((edge_index[1], torch.tensor([adj_adversary[i][1]])))\n",
    "        # Dataset uses edges both ways so add reverse edge as well\n",
    "        edge_index = torch.cat((edge_index, torch.flip(transposed_adj_adversary[:2, i:i+1], dims=[0])), -1)\n",
    "        # edge_index[0] = torch.cat((edge_index[0], torch.tensor([adj_adversary[i][1]])))\n",
    "        # edge_index[1] = torch.cat((edge_index[1], torch.tensor([adj_adversary[i][0]])))\n",
    "    \n",
    "    \n",
    "print(\"--- Data compare ---\")\n",
    "\n",
    "print(data)\n",
    "\n",
    "\n",
    "data_after_poison = copy.deepcopy(data)\n",
    "\n",
    "edge_index = edge_index.type(torch.int64)\n",
    "\n",
    "data_after_poison.edge_index = edge_index\n",
    "\n",
    "\n",
    "detector_poisoned = DOMINANT(hid_dim=64, num_layers=4, epoch=100)\n",
    "detector_poisoned.fit(data_after_poison)\n",
    "\n",
    "pred_after, score_after, prob_after, conf_after = detector_poisoned.predict(data_after_poison,\n",
    "                                        return_pred=True,\n",
    "                                        return_score=True,\n",
    "                                        return_prob=True,\n",
    "                                        return_conf=True)\n",
    "experiment_after_poison = Experiment(data=data_after_poison, pred=pred_after, score=score_after, prob=prob_after, conf=conf_after)\n",
    "\n",
    "\n",
    "print(\"auc before poison:\")\n",
    "print(roc_auc_score(y_binary, score))\n",
    "print(\"auc after poison:\")\n",
    "print(roc_auc_score(y_binary, score_after))\n",
    "#print(roc_auc_score(data_inj.y.detach().numpy(), score_inj.detach.numpy()))\n",
    "\n",
    "\n",
    "#return experiment_before_poison, experiment_after_poison #, node_idxs, y_binary\n",
    "\n",
    "#return pred, score, prob, conf, pred_after, score_after, prob_after, conf_after"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PyG2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
