{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gad_adversarial_robustness.gad.dominant import dominant\n",
    "from pygod.utils import load_data\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch_geometric.data import Data\n",
    "from sklearn.metrics import roc_auc_score\n",
    "import os\n",
    "from gad_adversarial_robustness.utils.graph_utils import prepare_graph\n",
    "from torch_geometric.data import Data\n",
    "import numpy as np\n",
    "from gad_adversarial_robustness.utils.graph_utils import get_n_anomaly_indexes\n",
    "from typing import List\n",
    "from gad_adversarial_robustness.poison.greedy import multiple_AS\n",
    "import copy\n",
    "from gad_adversarial_robustness.poison.greedy import poison_attack\n",
    "\n",
    "PRELOADED_EDGE_INDEX = True\n",
    "EDGE_INDEX_PT = \"276_budget_greedy_edge_index.pt\"\n",
    "\n",
    "\n",
    "script_dir = os.path.abspath('')\n",
    "\n",
    "\n",
    "dataset_caching_path = os.path.join(script_dir, '..', '..', '..', 'data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_data: Data = load_data(\"inj_cora\", dataset_caching_path)\n",
    "poisoned_data: Data = load_data(\"inj_cora\", dataset_caching_path)\n",
    "\n",
    "if PRELOADED_EDGE_INDEX is False:\n",
    "    truth: List[int] = poisoned_data.y.bool()\n",
    "    amount_of_nodes = poisoned_data.num_nodes\n",
    "    _, adj, _ = prepare_graph(poisoned_data)\n",
    "    dense_adj = adj.to_dense()  #Fill in zeroes where there are no edges\n",
    "\n",
    "\n",
    "    print(\"Create poison compatible adjacency matrix...\")\n",
    "    triple = []\n",
    "    for i in range(amount_of_nodes):\n",
    "        for j in range(i + 1, amount_of_nodes):\n",
    "            triple.append([i, j, dense_adj[i,j]])  #Fill with 0, then insert actual after\n",
    "\n",
    "\n",
    "\n",
    "    triple = np.array(triple)\n",
    "\n",
    "    # These are the nodes we try reduce the active subnetwork score for (disguising anonomaly nodes)\n",
    "    target_node_lst = get_n_anomaly_indexes(truth, 69)\n",
    "    #target_node_lst = get_n_anomaly_indexes(truth, 10)\n",
    "    print(type(target_node_lst)), print(f'target node list: {target_node_lst}'), print(target_node_lst)\n",
    "\n",
    "    print(\"Making model...\")\n",
    "    model = multiple_AS(target_lst = target_node_lst, n_node = amount_of_nodes, device = 'cpu')\n",
    "    budget = 276  # The amount of edges to change\n",
    "\n",
    "\n",
    "    print(\"Starting attack...\")\n",
    "\n",
    "    adj_adversary, _, _ = poison_attack(model, triple, budget)\n",
    "\n",
    "    print(\"Converting to compatible tensor...\")\n",
    "\n",
    "    # Create Edge Index'\n",
    "    edge_index = torch.tensor([[],[]])\n",
    "\n",
    "    # Transpose it to make shape compatible\n",
    "    transposed_adj_adversary = torch.transpose(adj_adversary, 0, 1)\n",
    "\n",
    "    for i in range(len(adj_adversary)):\n",
    "        if(adj_adversary[i][2] != 0):   #If edge value is not 0 (no edge)\n",
    "            #Add edge to edge index, choosing first 2 elements (edges), and then the ith edge\n",
    "            edge_index = torch.cat((edge_index, transposed_adj_adversary[:2, i:i+1]), -1)\n",
    "            # Dataset uses edges both ways so add reverse edge as well\n",
    "            edge_index = torch.cat((edge_index, torch.flip(transposed_adj_adversary[:2, i:i+1], dims=[0])), -1)\n",
    "\n",
    "\n",
    "    edge_index = edge_index.type(torch.int64)\n",
    "    poisoned_data.edge_index = edge_index\n",
    "\n",
    "else:\n",
    "    poisoned_data.edge_index = torch.load(EDGE_INDEX_PT)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(poisoned_data.edge_index, \"half_276_budget_greedy_edge_index.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DOMINANT  on CLEAN data:\n",
      "Epoch: 0119, Auc: 0.8147155021710935\n",
      "DOMINANT  on POISONED data (greedy w/ 300 budget):\n",
      "Epoch: 0119, Auc: 0.6191309987029832\n"
     ]
    }
   ],
   "source": [
    "import yaml\n",
    "#from gad_adversarial_robustness.gad.dominant.dominant import Dominant\n",
    "import scipy.sparse as sp\n",
    "from gad_adversarial_robustness.gad.dominant.dominant_cuda import Dominant \n",
    "from gad_adversarial_robustness.gad.dominant.dominant_neigh import Dominant as DominantNeigh\n",
    "from gad_adversarial_robustness.utils.graph_utils import load_anomaly_detection_dataset\n",
    "from torch_geometric.utils import to_torch_sparse_tensor\n",
    "yaml_path = os.path.join(script_dir, '..', 'configs', 'dominant_config.yaml')\n",
    "with open(yaml_path) as file:\n",
    "        config = yaml.safe_load(file)\n",
    "\n",
    "# DominantDiffusion on poisoned data\n",
    "\n",
    "\n",
    "print(\"DOMINANT  on CLEAN data:\")\n",
    "dataset: Data = load_data(\"inj_cora\")\n",
    "adj, _, _, adj_label = load_anomaly_detection_dataset(clean_data, config['model']['device'])\n",
    "#edge_index = torch.LongTensor(np.array(sp.coo_matrix(adj).nonzero()))\n",
    "adj_label = torch.FloatTensor(adj_label).to(config['model']['device'])\n",
    "#attrs = torch.FloatTensor(attrs)\n",
    "\n",
    "edge_index = dataset.edge_index.to(config['model']['device'])\n",
    "label = torch.Tensor(dataset.y.bool()).to(config['model']['device'])\n",
    "attrs = dataset.x.to(config['model']['device'])\n",
    "\n",
    "\n",
    "sparse_adj = to_torch_sparse_tensor(edge_index)\n",
    "\n",
    "\n",
    "\n",
    "model = DominantNeigh(feat_size=attrs.size(1), hidden_size=config['model']['hidden_dim'], dropout=config['model']['dropout'],\n",
    "                device=config['model']['device'], edge_index=sparse_adj, adj_label=adj_label, attrs=attrs, label=label)\n",
    "model.to(config['model']['device'])\n",
    "model.fit(config, verbose=False)\n",
    "\n",
    "print(\"DOMINANT  on POISONED data (greedy w/ 300 budget):\")\n",
    "\n",
    "dataset: Data = load_data(\"inj_cora\")\n",
    "adj, _, _, adj_label = load_anomaly_detection_dataset(poisoned_data, config['model']['device'])\n",
    "#edge_index = torch.LongTensor(np.array(sp.coo_matrix(adj).nonzero()))\n",
    "adj_label = torch.FloatTensor(adj_label).to(config['model']['device'])\n",
    "#attrs = torch.FloatTensor(attrs)\n",
    "\n",
    "edge_index = poisoned_data.edge_index.to(config['model']['device'])\n",
    "label = torch.Tensor(poisoned_data.y.bool()).to(config['model']['device'])\n",
    "attrs = poisoned_data.x.to(config['model']['device'])\n",
    "\n",
    "\n",
    "sparse_adj = to_torch_sparse_tensor(edge_index)\n",
    "\n",
    "\n",
    "\n",
    "model = DominantNeigh(feat_size=attrs.size(1), hidden_size=config['model']['hidden_dim'], dropout=config['model']['dropout'],\n",
    "                device=config['model']['device'], edge_index=sparse_adj, adj_label=adj_label, attrs=attrs, label=label)\n",
    "model.to(config['model']['device'])\n",
    "model.fit(config, verbose=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DOMINANT modified w/ new TAGConv on CLEAN data:\n",
      "Epoch: 0119, Auc: 0.8195172841594767\n",
      "DOMINANT modified w/ TAGConv on POISONED data (greedy w/ 300 budget):\n",
      "Epoch: 0000, train_loss=0.81185, train/struct_loss=2.10209, train/feat_loss=0.25889\n",
      "Epoch: 0000, Auc: 0.6099475554051768\n",
      "Epoch: 0001, train_loss=0.89915, train/struct_loss=2.29767, train/feat_loss=0.29979\n",
      "Epoch: 0002, train_loss=0.80871, train/struct_loss=2.10009, train/feat_loss=0.25526\n",
      "Epoch: 0003, train_loss=0.80867, train/struct_loss=2.10108, train/feat_loss=0.25478\n",
      "Epoch: 0004, train_loss=0.80848, train/struct_loss=2.10133, train/feat_loss=0.25440\n",
      "Epoch: 0005, train_loss=0.80832, train/struct_loss=2.10094, train/feat_loss=0.25434\n",
      "Epoch: 0006, train_loss=0.80837, train/struct_loss=2.10098, train/feat_loss=0.25439\n",
      "Epoch: 0007, train_loss=0.80842, train/struct_loss=2.10098, train/feat_loss=0.25446\n",
      "Epoch: 0008, train_loss=0.80834, train/struct_loss=2.10083, train/feat_loss=0.25442\n",
      "Epoch: 0009, train_loss=0.80826, train/struct_loss=2.10076, train/feat_loss=0.25433\n",
      "Epoch: 0010, train_loss=0.80817, train/struct_loss=2.10071, train/feat_loss=0.25422\n",
      "Epoch: 0010, Auc: 0.6189054305532059\n",
      "Epoch: 0011, train_loss=0.80801, train/struct_loss=2.10041, train/feat_loss=0.25412\n",
      "Epoch: 0012, train_loss=0.80792, train/struct_loss=2.10029, train/feat_loss=0.25404\n",
      "Epoch: 0013, train_loss=0.80784, train/struct_loss=2.10014, train/feat_loss=0.25400\n",
      "Epoch: 0014, train_loss=0.80776, train/struct_loss=2.09989, train/feat_loss=0.25399\n",
      "Epoch: 0015, train_loss=0.80770, train/struct_loss=2.09963, train/feat_loss=0.25401\n",
      "Epoch: 0016, train_loss=0.80765, train/struct_loss=2.09949, train/feat_loss=0.25401\n",
      "Epoch: 0017, train_loss=0.80756, train/struct_loss=2.09925, train/feat_loss=0.25399\n",
      "Epoch: 0018, train_loss=0.80763, train/struct_loss=2.09956, train/feat_loss=0.25395\n",
      "Epoch: 0019, train_loss=0.80744, train/struct_loss=2.09901, train/feat_loss=0.25391\n",
      "Epoch: 0020, train_loss=0.80742, train/struct_loss=2.09903, train/feat_loss=0.25388\n",
      "Epoch: 0020, Auc: 0.618854677719506\n",
      "Epoch: 0021, train_loss=0.80731, train/struct_loss=2.09874, train/feat_loss=0.25384\n",
      "Epoch: 0022, train_loss=0.80725, train/struct_loss=2.09871, train/feat_loss=0.25377\n",
      "Epoch: 0023, train_loss=0.80716, train/struct_loss=2.09845, train/feat_loss=0.25375\n",
      "Epoch: 0024, train_loss=0.80708, train/struct_loss=2.09831, train/feat_loss=0.25369\n",
      "Epoch: 0025, train_loss=0.80691, train/struct_loss=2.09786, train/feat_loss=0.25365\n",
      "Epoch: 0026, train_loss=0.80685, train/struct_loss=2.09768, train/feat_loss=0.25364\n",
      "Epoch: 0027, train_loss=0.80679, train/struct_loss=2.09771, train/feat_loss=0.25354\n",
      "Epoch: 0028, train_loss=0.80651, train/struct_loss=2.09688, train/feat_loss=0.25350\n",
      "Epoch: 0029, train_loss=0.80641, train/struct_loss=2.09670, train/feat_loss=0.25343\n",
      "Epoch: 0030, train_loss=0.80616, train/struct_loss=2.09600, train/feat_loss=0.25337\n",
      "Epoch: 0030, Auc: 0.6199007500140981\n",
      "Epoch: 0031, train_loss=0.80633, train/struct_loss=2.09672, train/feat_loss=0.25331\n",
      "Epoch: 0032, train_loss=0.80586, train/struct_loss=2.09525, train/feat_loss=0.25327\n",
      "Epoch: 0033, train_loss=0.80546, train/struct_loss=2.09410, train/feat_loss=0.25319\n",
      "Epoch: 0034, train_loss=0.80551, train/struct_loss=2.09433, train/feat_loss=0.25315\n",
      "Epoch: 0035, train_loss=0.80546, train/struct_loss=2.09425, train/feat_loss=0.25313\n",
      "Epoch: 0036, train_loss=0.80559, train/struct_loss=2.09478, train/feat_loss=0.25308\n",
      "Epoch: 0037, train_loss=0.80507, train/struct_loss=2.09315, train/feat_loss=0.25303\n",
      "Epoch: 0038, train_loss=0.80513, train/struct_loss=2.09336, train/feat_loss=0.25303\n",
      "Epoch: 0039, train_loss=0.80491, train/struct_loss=2.09290, train/feat_loss=0.25291\n",
      "Epoch: 0040, train_loss=0.80515, train/struct_loss=2.09367, train/feat_loss=0.25293\n",
      "Epoch: 0040, Auc: 0.6206845993345739\n",
      "Epoch: 0041, train_loss=0.80518, train/struct_loss=2.09387, train/feat_loss=0.25289\n",
      "Epoch: 0042, train_loss=0.80501, train/struct_loss=2.09344, train/feat_loss=0.25283\n",
      "Epoch: 0043, train_loss=0.80477, train/struct_loss=2.09263, train/feat_loss=0.25283\n",
      "Epoch: 0044, train_loss=0.80470, train/struct_loss=2.09256, train/feat_loss=0.25276\n",
      "Epoch: 0045, train_loss=0.80447, train/struct_loss=2.09189, train/feat_loss=0.25272\n",
      "Epoch: 0046, train_loss=0.80480, train/struct_loss=2.09306, train/feat_loss=0.25269\n",
      "Epoch: 0047, train_loss=0.80425, train/struct_loss=2.09134, train/feat_loss=0.25264\n",
      "Epoch: 0048, train_loss=0.80431, train/struct_loss=2.09170, train/feat_loss=0.25257\n",
      "Epoch: 0049, train_loss=0.80415, train/struct_loss=2.09117, train/feat_loss=0.25257\n",
      "Epoch: 0050, train_loss=0.80434, train/struct_loss=2.09193, train/feat_loss=0.25251\n",
      "Epoch: 0050, Auc: 0.6207832854001014\n",
      "Epoch: 0051, train_loss=0.80387, train/struct_loss=2.09055, train/feat_loss=0.25244\n",
      "Epoch: 0052, train_loss=0.80394, train/struct_loss=2.09086, train/feat_loss=0.25241\n",
      "Epoch: 0053, train_loss=0.80387, train/struct_loss=2.09065, train/feat_loss=0.25239\n",
      "Epoch: 0054, train_loss=0.80356, train/struct_loss=2.08969, train/feat_loss=0.25236\n",
      "Epoch: 0055, train_loss=0.80352, train/struct_loss=2.08979, train/feat_loss=0.25227\n",
      "Epoch: 0056, train_loss=0.80339, train/struct_loss=2.08944, train/feat_loss=0.25222\n",
      "Epoch: 0057, train_loss=0.80344, train/struct_loss=2.08958, train/feat_loss=0.25224\n",
      "Epoch: 0058, train_loss=0.80297, train/struct_loss=2.08822, train/feat_loss=0.25215\n",
      "Epoch: 0059, train_loss=0.80294, train/struct_loss=2.08810, train/feat_loss=0.25215\n",
      "Epoch: 0060, train_loss=0.80338, train/struct_loss=2.08968, train/feat_loss=0.25211\n",
      "Epoch: 0060, Auc: 0.620568995657813\n",
      "Epoch: 0061, train_loss=0.80313, train/struct_loss=2.08897, train/feat_loss=0.25205\n",
      "Epoch: 0062, train_loss=0.80266, train/struct_loss=2.08754, train/feat_loss=0.25200\n",
      "Epoch: 0063, train_loss=0.80295, train/struct_loss=2.08850, train/feat_loss=0.25200\n",
      "Epoch: 0064, train_loss=0.80248, train/struct_loss=2.08692, train/feat_loss=0.25200\n",
      "Epoch: 0065, train_loss=0.80249, train/struct_loss=2.08710, train/feat_loss=0.25194\n",
      "Epoch: 0066, train_loss=0.80223, train/struct_loss=2.08629, train/feat_loss=0.25191\n",
      "Epoch: 0067, train_loss=0.80252, train/struct_loss=2.08745, train/feat_loss=0.25184\n",
      "Epoch: 0068, train_loss=0.80232, train/struct_loss=2.08687, train/feat_loss=0.25179\n",
      "Epoch: 0069, train_loss=0.80208, train/struct_loss=2.08604, train/feat_loss=0.25182\n",
      "Epoch: 0070, train_loss=0.80206, train/struct_loss=2.08606, train/feat_loss=0.25177\n",
      "Epoch: 0070, Auc: 0.6202757570631027\n",
      "Epoch: 0071, train_loss=0.80186, train/struct_loss=2.08548, train/feat_loss=0.25174\n",
      "Epoch: 0072, train_loss=0.80230, train/struct_loss=2.08706, train/feat_loss=0.25168\n",
      "Epoch: 0073, train_loss=0.80157, train/struct_loss=2.08470, train/feat_loss=0.25166\n",
      "Epoch: 0074, train_loss=0.80183, train/struct_loss=2.08557, train/feat_loss=0.25166\n",
      "Epoch: 0075, train_loss=0.80156, train/struct_loss=2.08479, train/feat_loss=0.25160\n",
      "Epoch: 0076, train_loss=0.80121, train/struct_loss=2.08388, train/feat_loss=0.25150\n",
      "Epoch: 0077, train_loss=0.80128, train/struct_loss=2.08399, train/feat_loss=0.25155\n",
      "Epoch: 0078, train_loss=0.80099, train/struct_loss=2.08311, train/feat_loss=0.25151\n",
      "Epoch: 0079, train_loss=0.80098, train/struct_loss=2.08312, train/feat_loss=0.25149\n",
      "Epoch: 0080, train_loss=0.80109, train/struct_loss=2.08358, train/feat_loss=0.25145\n",
      "Epoch: 0080, Auc: 0.6202419218406361\n",
      "Epoch: 0081, train_loss=0.80088, train/struct_loss=2.08279, train/feat_loss=0.25149\n",
      "Epoch: 0082, train_loss=0.80083, train/struct_loss=2.08289, train/feat_loss=0.25137\n",
      "Epoch: 0083, train_loss=0.80059, train/struct_loss=2.08212, train/feat_loss=0.25136\n",
      "Epoch: 0084, train_loss=0.80047, train/struct_loss=2.08173, train/feat_loss=0.25136\n",
      "Epoch: 0085, train_loss=0.80026, train/struct_loss=2.08118, train/feat_loss=0.25129\n",
      "Epoch: 0086, train_loss=0.79986, train/struct_loss=2.07974, train/feat_loss=0.25134\n",
      "Epoch: 0087, train_loss=0.80032, train/struct_loss=2.08143, train/feat_loss=0.25128\n",
      "Epoch: 0088, train_loss=0.80030, train/struct_loss=2.08146, train/feat_loss=0.25123\n",
      "Epoch: 0089, train_loss=0.79998, train/struct_loss=2.08036, train/feat_loss=0.25124\n",
      "Epoch: 0090, train_loss=0.79959, train/struct_loss=2.07907, train/feat_loss=0.25124\n",
      "Epoch: 0090, Auc: 0.6197907855410816\n",
      "Epoch: 0091, train_loss=0.79944, train/struct_loss=2.07867, train/feat_loss=0.25120\n",
      "Epoch: 0092, train_loss=0.80006, train/struct_loss=2.08071, train/feat_loss=0.25121\n",
      "Epoch: 0093, train_loss=0.79978, train/struct_loss=2.07978, train/feat_loss=0.25121\n",
      "Epoch: 0094, train_loss=0.79944, train/struct_loss=2.07877, train/feat_loss=0.25115\n",
      "Epoch: 0095, train_loss=0.79971, train/struct_loss=2.07984, train/feat_loss=0.25108\n",
      "Epoch: 0096, train_loss=0.79934, train/struct_loss=2.07838, train/feat_loss=0.25117\n",
      "Epoch: 0097, train_loss=0.79907, train/struct_loss=2.07761, train/feat_loss=0.25112\n",
      "Epoch: 0098, train_loss=0.79883, train/struct_loss=2.07689, train/feat_loss=0.25108\n",
      "Epoch: 0099, train_loss=0.79881, train/struct_loss=2.07697, train/feat_loss=0.25103\n",
      "Epoch: 0100, train_loss=0.79908, train/struct_loss=2.07786, train/feat_loss=0.25102\n",
      "Epoch: 0100, Auc: 0.6203095922855694\n",
      "Epoch: 0101, train_loss=0.79836, train/struct_loss=2.07546, train/feat_loss=0.25104\n",
      "Epoch: 0102, train_loss=0.79983, train/struct_loss=2.08013, train/feat_loss=0.25113\n",
      "Epoch: 0103, train_loss=0.79858, train/struct_loss=2.07633, train/feat_loss=0.25097\n",
      "Epoch: 0104, train_loss=0.79931, train/struct_loss=2.07879, train/feat_loss=0.25096\n",
      "Epoch: 0105, train_loss=0.79854, train/struct_loss=2.07613, train/feat_loss=0.25101\n",
      "Epoch: 0106, train_loss=0.79793, train/struct_loss=2.07416, train/feat_loss=0.25097\n",
      "Epoch: 0107, train_loss=0.79800, train/struct_loss=2.07453, train/feat_loss=0.25092\n",
      "Epoch: 0108, train_loss=0.79820, train/struct_loss=2.07497, train/feat_loss=0.25101\n",
      "Epoch: 0109, train_loss=0.79775, train/struct_loss=2.07380, train/feat_loss=0.25087\n",
      "Epoch: 0110, train_loss=0.79803, train/struct_loss=2.07471, train/feat_loss=0.25088\n",
      "Epoch: 0110, Auc: 0.620515423222241\n",
      "Epoch: 0111, train_loss=0.79809, train/struct_loss=2.07472, train/feat_loss=0.25096\n",
      "Epoch: 0112, train_loss=0.79790, train/struct_loss=2.07436, train/feat_loss=0.25084\n",
      "Epoch: 0113, train_loss=0.79797, train/struct_loss=2.07457, train/feat_loss=0.25086\n",
      "Epoch: 0114, train_loss=0.79823, train/struct_loss=2.07523, train/feat_loss=0.25094\n",
      "Epoch: 0115, train_loss=0.79785, train/struct_loss=2.07414, train/feat_loss=0.25087\n",
      "Epoch: 0116, train_loss=0.79803, train/struct_loss=2.07484, train/feat_loss=0.25082\n",
      "Epoch: 0117, train_loss=0.79772, train/struct_loss=2.07374, train/feat_loss=0.25085\n",
      "Epoch: 0118, train_loss=0.79722, train/struct_loss=2.07207, train/feat_loss=0.25085\n",
      "Epoch: 0119, train_loss=0.79720, train/struct_loss=2.07186, train/feat_loss=0.25091\n",
      "Epoch: 0119, Auc: 0.6210878024023008\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(config['model']['epochs'])\n",
    "\n",
    "\"\"\"\n",
    "Dominant Aggr on poisoned data\n",
    "\"\"\"\n",
    "\n",
    "print(\"DOMINANT modified w/ new TAGConv on CLEAN data:\")\n",
    "adj, _, _, adj_label = load_anomaly_detection_dataset(clean_data, config['model']['device'])\n",
    "#edge_index = torch.LongTensor(np.array(sp.coo_matrix(adj).nonzero()))\n",
    "adj_label = torch.FloatTensor(adj_label).to(config['model']['device'])\n",
    "#attrs = torch.FloatTensor(attrs)\n",
    "\n",
    "edge_index = clean_data.edge_index.to(config['model']['device'])\n",
    "label = torch.Tensor(clean_data.y.bool()).to(config['model']['device'])\n",
    "attrs = clean_data.x.to(config['model']['device'])\n",
    "\n",
    "jaccard_params= {\n",
    "    \"threshold\": 0.01\n",
    "}\n",
    "\n",
    "model = Dominant(feat_size=attrs.size(1), hidden_size=config['model']['hidden_dim'], dropout=config['model']['dropout'],\n",
    "                    device=config['model']['device'], edge_index=edge_index, adj_label=adj_label, attrs=attrs, label=label)\n",
    "model.to(config['model']['device'])\n",
    "model.fit(config, verbose=False)\n",
    "\n",
    "print(\"DOMINANT modified w/ TAGConv on POISONED data (greedy w/ 300 budget):\")\n",
    "\n",
    "adj, _, _, adj_label = load_anomaly_detection_dataset(poisoned_data, config['model']['device'])\n",
    "#edge_index = torch.LongTensor(np.array(sp.coo_matrix(adj).nonzero()))\n",
    "adj_label = torch.FloatTensor(adj_label).to(config['model']['device'])\n",
    "#attrs = torch.FloatTensor(attrs)\n",
    "\n",
    "edge_index = poisoned_data.edge_index.to(config['model']['device'])\n",
    "label = torch.Tensor(poisoned_data.y.bool()).to(config['model']['device'])\n",
    "attrs = poisoned_data.x.to(config['model']['device'])\n",
    "\n",
    "jaccard_params= {\n",
    "    \"threshold\": 0.01\n",
    "}\n",
    "\n",
    "model = Dominant(feat_size=attrs.size(1), hidden_size=config['model']['hidden_dim'], dropout=config['model']['dropout'],\n",
    "                    device=config['model']['device'], edge_index=edge_index, adj_label=adj_label, attrs=attrs, label=label)\n",
    "model.to(config['model']['device'])\n",
    "model.fit(config, verbose=False)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nimport yaml\\n#from gad_adversarial_robustness.gad.dominant.dominant import Dominant\\n\\nfrom gad_adversarial_robustness.gad.dominant.dominant import Dominant \\nfrom gad_adversarial_robustness.gad.dominant.dominant_diffusion import Dominant as DominantDiff\\nfrom gad_adversarial_robustness.utils.graph_utils import load_anomaly_detection_dataset\\n\\nyaml_path = os.path.join(script_dir, \\'..\\', \\'configs\\', \\'dominant_config.yaml\\')\\nwith open(yaml_path) as file:\\n        config = yaml.safe_load(file)\\n\\n#DominantDiffusion on poisoned data\\n\\n\\nprint(\"Classic DOMINANT on CLEAN data:\")\\nadj, attrs, label, adj_label = load_anomaly_detection_dataset(clean_data)\\nadj = torch.FloatTensor(adj)\\nadj_label = torch.FloatTensor(adj_label)\\nattrs = torch.FloatTensor(attrs)\\n\\nmodel = Dominant(\\n        feat_size=attrs.size(1),\\n        hidden_size=config[\"model\"][\"hidden_dim\"],\\n        dropout=config[\"model\"][\"dropout\"],\\n        device=config[\"model\"][\"device\"],\\n        adj=adj,\\n        adj_label=adj_label,\\n        attrs=attrs,\\n        label=label,\\n    )\\nmodel.fit(config)\\n\\nprint(\"Classic DOMINANT on POISONED data (greedy w/ 300 budget):\")\\nadj, attrs, label, adj_label = load_anomaly_detection_dataset(poisoned_data)\\nadj = torch.FloatTensor(adj)\\nadj_label = torch.FloatTensor(adj_label)\\nattrs = torch.FloatTensor(attrs)\\n\\nmodel = Dominant(\\n        feat_size=attrs.size(1),\\n        hidden_size=config[\"model\"][\"hidden_dim\"],\\n        dropout=config[\"model\"][\"dropout\"],\\n        device=config[\"model\"][\"device\"],\\n        adj=adj,\\n        adj_label=adj_label,\\n        attrs=attrs,\\n        label=label,\\n    )\\nmodel.fit(config)\\n\\n\\n\\n#DominantDiffusion on poisoned data\\n\\n\\nprint(\"DOMINANT modified w/ diffusion on CLEAN data:\")\\nadj, attrs, label, adj_label = load_anomaly_detection_dataset(clean_data)\\nadj = torch.FloatTensor(adj)\\nadj_label = torch.FloatTensor(adj_label)\\nattrs = torch.FloatTensor(attrs)\\nmodel = DominantDiff(\\n        feat_size=attrs.size(1),\\n        hidden_size=config[\"model\"][\"hidden_dim\"],\\n        dropout=config[\"model\"][\"dropout\"],\\n        device=config[\"model\"][\"device\"],\\n        adj=adj,\\n        adj_label=adj_label,\\n        attrs=attrs,\\n        label=label,\\n    )\\n\\nmodel.fit(config)\\n\\nprint(\"DOMINANT modified w/ diffusion on POISONED data (greedy w/ 300 budget):\")\\n\\n\\nadj, attrs, label, adj_label = load_anomaly_detection_dataset(poisoned_data)\\nadj = torch.FloatTensor(adj)\\nadj_label = torch.FloatTensor(adj_label)\\nattrs = torch.FloatTensor(attrs)\\nmodel = DominantDiff(\\n        feat_size=attrs.size(1),\\n        hidden_size=config[\"model\"][\"hidden_dim\"],\\n        dropout=config[\"model\"][\"dropout\"],\\n        device=config[\"model\"][\"device\"],\\n        adj=adj,\\n        adj_label=adj_label,\\n        attrs=attrs,\\n        label=label,\\n    )\\n\\nmodel.fit(config)\\n\\n'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "import yaml\n",
    "#from gad_adversarial_robustness.gad.dominant.dominant import Dominant\n",
    "\n",
    "from gad_adversarial_robustness.gad.dominant.dominant import Dominant \n",
    "from gad_adversarial_robustness.gad.dominant.dominant_diffusion import Dominant as DominantDiff\n",
    "from gad_adversarial_robustness.utils.graph_utils import load_anomaly_detection_dataset\n",
    "\n",
    "yaml_path = os.path.join(script_dir, '..', 'configs', 'dominant_config.yaml')\n",
    "with open(yaml_path) as file:\n",
    "        config = yaml.safe_load(file)\n",
    "\n",
    "#DominantDiffusion on poisoned data\n",
    "\n",
    "\n",
    "print(\"Classic DOMINANT on CLEAN data:\")\n",
    "adj, attrs, label, adj_label = load_anomaly_detection_dataset(clean_data)\n",
    "adj = torch.FloatTensor(adj)\n",
    "adj_label = torch.FloatTensor(adj_label)\n",
    "attrs = torch.FloatTensor(attrs)\n",
    "\n",
    "model = Dominant(\n",
    "        feat_size=attrs.size(1),\n",
    "        hidden_size=config[\"model\"][\"hidden_dim\"],\n",
    "        dropout=config[\"model\"][\"dropout\"],\n",
    "        device=config[\"model\"][\"device\"],\n",
    "        adj=adj,\n",
    "        adj_label=adj_label,\n",
    "        attrs=attrs,\n",
    "        label=label,\n",
    "    )\n",
    "model.fit(config)\n",
    "\n",
    "print(\"Classic DOMINANT on POISONED data (greedy w/ 300 budget):\")\n",
    "adj, attrs, label, adj_label = load_anomaly_detection_dataset(poisoned_data)\n",
    "adj = torch.FloatTensor(adj)\n",
    "adj_label = torch.FloatTensor(adj_label)\n",
    "attrs = torch.FloatTensor(attrs)\n",
    "\n",
    "model = Dominant(\n",
    "        feat_size=attrs.size(1),\n",
    "        hidden_size=config[\"model\"][\"hidden_dim\"],\n",
    "        dropout=config[\"model\"][\"dropout\"],\n",
    "        device=config[\"model\"][\"device\"],\n",
    "        adj=adj,\n",
    "        adj_label=adj_label,\n",
    "        attrs=attrs,\n",
    "        label=label,\n",
    "    )\n",
    "model.fit(config)\n",
    "\n",
    "\n",
    "\n",
    "#DominantDiffusion on poisoned data\n",
    "\n",
    "\n",
    "print(\"DOMINANT modified w/ diffusion on CLEAN data:\")\n",
    "adj, attrs, label, adj_label = load_anomaly_detection_dataset(clean_data)\n",
    "adj = torch.FloatTensor(adj)\n",
    "adj_label = torch.FloatTensor(adj_label)\n",
    "attrs = torch.FloatTensor(attrs)\n",
    "model = DominantDiff(\n",
    "        feat_size=attrs.size(1),\n",
    "        hidden_size=config[\"model\"][\"hidden_dim\"],\n",
    "        dropout=config[\"model\"][\"dropout\"],\n",
    "        device=config[\"model\"][\"device\"],\n",
    "        adj=adj,\n",
    "        adj_label=adj_label,\n",
    "        attrs=attrs,\n",
    "        label=label,\n",
    "    )\n",
    "\n",
    "model.fit(config)\n",
    "\n",
    "print(\"DOMINANT modified w/ diffusion on POISONED data (greedy w/ 300 budget):\")\n",
    "\n",
    "\n",
    "adj, attrs, label, adj_label = load_anomaly_detection_dataset(poisoned_data)\n",
    "adj = torch.FloatTensor(adj)\n",
    "adj_label = torch.FloatTensor(adj_label)\n",
    "attrs = torch.FloatTensor(attrs)\n",
    "model = DominantDiff(\n",
    "        feat_size=attrs.size(1),\n",
    "        hidden_size=config[\"model\"][\"hidden_dim\"],\n",
    "        dropout=config[\"model\"][\"dropout\"],\n",
    "        device=config[\"model\"][\"device\"],\n",
    "        adj=adj,\n",
    "        adj_label=adj_label,\n",
    "        attrs=attrs,\n",
    "        label=label,\n",
    "    )\n",
    "\n",
    "model.fit(config)\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PyG",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
