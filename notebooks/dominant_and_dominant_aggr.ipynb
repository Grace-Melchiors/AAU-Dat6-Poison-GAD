{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gad_adversarial_robustness.gad.dominant import dominant\n",
    "from pygod.utils import load_data\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch_geometric.data import Data\n",
    "from sklearn.metrics import roc_auc_score\n",
    "import os\n",
    "from gad_adversarial_robustness.utils.graph_utils import prepare_graph\n",
    "from torch_geometric.data import Data\n",
    "import numpy as np\n",
    "from gad_adversarial_robustness.utils.graph_utils import get_n_anomaly_indexes\n",
    "from typing import List\n",
    "from gad_adversarial_robustness.poison.greedy import multiple_AS\n",
    "import copy\n",
    "from gad_adversarial_robustness.poison.greedy import poison_attack\n",
    "\n",
    "PRELOADED_EDGE_INDEX = True\n",
    "EDGE_INDEX_PT = \"100_budget_greedy_edge_index.pt\"\n",
    "\n",
    "\n",
    "script_dir = os.path.abspath('')\n",
    "\n",
    "\n",
    "dataset_caching_path = os.path.join(script_dir, '..', '..', '..', 'data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_data: Data = load_data(\"inj_cora\", dataset_caching_path)\n",
    "poisoned_data: Data = load_data(\"inj_cora\", dataset_caching_path)\n",
    "\n",
    "if PRELOADED_EDGE_INDEX is False:\n",
    "    truth: List[int] = poisoned_data.y.bool()\n",
    "    amount_of_nodes = poisoned_data.num_nodes\n",
    "    _, adj, _ = prepare_graph(poisoned_data)\n",
    "    dense_adj = adj.to_dense()  #Fill in zeroes where there are no edges\n",
    "\n",
    "\n",
    "    print(\"Create poison compatible adjacency matrix...\")\n",
    "    triple = []\n",
    "    for i in range(amount_of_nodes):\n",
    "        for j in range(i + 1, amount_of_nodes):\n",
    "            triple.append([i, j, dense_adj[i,j]])  #Fill with 0, then insert actual after\n",
    "\n",
    "\n",
    "\n",
    "    triple = np.array(triple)\n",
    "\n",
    "    # These are the nodes we try reduce the active subnetwork score for (disguising anonomaly nodes)\n",
    "    target_node_lst = get_n_anomaly_indexes(truth, 999)\n",
    "    #target_node_lst = get_n_anomaly_indexes(truth, 10)\n",
    "    print(type(target_node_lst)), print(f'target node list: {target_node_lst}'), print(target_node_lst)\n",
    "\n",
    "    print(\"Making model...\")\n",
    "    model = multiple_AS(target_lst = target_node_lst, n_node = amount_of_nodes, device = 'cpu')\n",
    "    budget = 100  # The amount of edges to change\n",
    "\n",
    "\n",
    "    print(\"Starting attack...\")\n",
    "\n",
    "    adj_adversary, _, _ = poison_attack(model, triple, budget)\n",
    "\n",
    "    print(\"Converting to compatible tensor...\")\n",
    "\n",
    "    # Create Edge Index'\n",
    "    edge_index = torch.tensor([[],[]])\n",
    "\n",
    "    # Transpose it to make shape compatible\n",
    "    transposed_adj_adversary = torch.transpose(adj_adversary, 0, 1)\n",
    "\n",
    "    for i in range(len(adj_adversary)):\n",
    "        if(adj_adversary[i][2] != 0):   #If edge value is not 0 (no edge)\n",
    "            #Add edge to edge index, choosing first 2 elements (edges), and then the ith edge\n",
    "            edge_index = torch.cat((edge_index, transposed_adj_adversary[:2, i:i+1]), -1)\n",
    "            # Dataset uses edges both ways so add reverse edge as well\n",
    "            edge_index = torch.cat((edge_index, torch.flip(transposed_adj_adversary[:2, i:i+1], dims=[0])), -1)\n",
    "\n",
    "\n",
    "    edge_index = edge_index.type(torch.int64)\n",
    "    poisoned_data.edge_index = edge_index\n",
    "\n",
    "else:\n",
    "    poisoned_data.edge_index = torch.load(EDGE_INDEX_PT)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DOMINANT  on CLEAN data:\n",
      "Epoch: 0119, Auc: 0.8202447414425083\n",
      "DOMINANT  on POISONED data (greedy w/ 300 budget):\n",
      "Epoch: 0119, Auc: 0.8005075283369989\n"
     ]
    }
   ],
   "source": [
    "import yaml\n",
    "#from gad_adversarial_robustness.gad.dominant.dominant import Dominant\n",
    "import scipy.sparse as sp\n",
    "from gad_adversarial_robustness.gad.dominant.dominant import Dominant \n",
    "from gad_adversarial_robustness.gad.dominant.dominant_tagconv import Dominant as DominantAggr\n",
    "from gad_adversarial_robustness.utils.graph_utils import load_anomaly_detection_dataset\n",
    "\n",
    "yaml_path = os.path.join(script_dir, '..', 'configs', 'dominant_config.yaml')\n",
    "with open(yaml_path) as file:\n",
    "        config = yaml.safe_load(file)\n",
    "\n",
    "# DominantDiffusion on poisoned data\n",
    "\n",
    "\n",
    "print(\"DOMINANT  on CLEAN data:\")\n",
    "adj, attrs, label, adj_label = load_anomaly_detection_dataset(clean_data)\n",
    "edge_index = torch.LongTensor(np.array(sp.coo_matrix(adj).nonzero()))\n",
    "adj_label = torch.FloatTensor(adj_label)\n",
    "attrs = torch.FloatTensor(attrs)\n",
    "\n",
    "model = Dominant(feat_size=attrs.size(1), hidden_size=config['model']['hidden_dim'], dropout=config['model']['dropout'],\n",
    "                    device='cpu', edge_index=edge_index, adj_label=adj_label, attrs=attrs, label=label)\n",
    "\n",
    "model.fit(config, verbose=False)\n",
    "\n",
    "print(\"DOMINANT  on POISONED data (greedy w/ 300 budget):\")\n",
    "\n",
    "dataset = load_data(\"inj_cora\")\n",
    "adj, attrs, label, adj_label = load_anomaly_detection_dataset(poisoned_data)\n",
    "edge_index = torch.LongTensor(np.array(sp.coo_matrix(adj).nonzero()))\n",
    "adj_label = torch.FloatTensor(adj_label)\n",
    "attrs = torch.FloatTensor(attrs)\n",
    "\n",
    "model = Dominant(feat_size=attrs.size(1), hidden_size=config['model']['hidden_dim'], dropout=config['model']['dropout'],\n",
    "                    device='cpu', edge_index=edge_index, adj_label=adj_label, attrs=attrs, label=label)\n",
    "\n",
    "\n",
    "model.fit(config, verbose = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DOMINANT modified w/ new TAGConv on CLEAN data:\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "mat1 and mat2 shapes cannot be multiplied (2x11060 and 2708x96)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[4], line 22\u001b[0m\n\u001b[0;32m     19\u001b[0m model \u001b[38;5;241m=\u001b[39m DominantAggr(feat_size\u001b[38;5;241m=\u001b[39mattrs\u001b[38;5;241m.\u001b[39msize(\u001b[38;5;241m1\u001b[39m), hidden_size\u001b[38;5;241m=\u001b[39mconfig[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmodel\u001b[39m\u001b[38;5;124m'\u001b[39m][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mhidden_dim\u001b[39m\u001b[38;5;124m'\u001b[39m], dropout\u001b[38;5;241m=\u001b[39mconfig[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmodel\u001b[39m\u001b[38;5;124m'\u001b[39m][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdropout\u001b[39m\u001b[38;5;124m'\u001b[39m],\n\u001b[0;32m     20\u001b[0m                     device\u001b[38;5;241m=\u001b[39mconfig[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmodel\u001b[39m\u001b[38;5;124m'\u001b[39m][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdevice\u001b[39m\u001b[38;5;124m'\u001b[39m], edge_index\u001b[38;5;241m=\u001b[39medge_index, adj_label\u001b[38;5;241m=\u001b[39madj_label, attrs\u001b[38;5;241m=\u001b[39mattrs, label\u001b[38;5;241m=\u001b[39mlabel)\n\u001b[0;32m     21\u001b[0m model\u001b[38;5;241m.\u001b[39mto(config[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmodel\u001b[39m\u001b[38;5;124m'\u001b[39m][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdevice\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[1;32m---> 22\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[0;32m     24\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDOMINANT modified w/ TAGConv on POISONED data (greedy w/ 300 budget):\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     26\u001b[0m adj, _, _, adj_label \u001b[38;5;241m=\u001b[39m load_anomaly_detection_dataset(poisoned_data, config[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmodel\u001b[39m\u001b[38;5;124m'\u001b[39m][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdevice\u001b[39m\u001b[38;5;124m'\u001b[39m])\n",
      "File \u001b[1;32mc:\\users\\andwh\\documents\\p6\\aau-dat6-poison-gad\\gad_adversarial_robustness\\gad\\dominant\\dominant_neigh.py:182\u001b[0m, in \u001b[0;36mDominant.fit\u001b[1;34m(self, config, verbose)\u001b[0m\n\u001b[0;32m    180\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrain()\n\u001b[0;32m    181\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[1;32m--> 182\u001b[0m A_hat, X_hat \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mforward\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43medge_index\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    183\u001b[0m loss, struct_loss, feat_loss \u001b[38;5;241m=\u001b[39m loss_func(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39madj_label, A_hat, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mattrs, X_hat, config[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmodel\u001b[39m\u001b[38;5;124m'\u001b[39m][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124malpha\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[0;32m    184\u001b[0m loss \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mmean(loss)\n",
      "File \u001b[1;32mc:\\users\\andwh\\documents\\p6\\aau-dat6-poison-gad\\gad_adversarial_robustness\\gad\\dominant\\dominant_neigh.py:171\u001b[0m, in \u001b[0;36mDominant.forward\u001b[1;34m(self, x, edge_index)\u001b[0m\n\u001b[0;32m    170\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x: torch\u001b[38;5;241m.\u001b[39mTensor, edge_index: torch\u001b[38;5;241m.\u001b[39mTensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tuple[torch\u001b[38;5;241m.\u001b[39mTensor, torch\u001b[38;5;241m.\u001b[39mTensor]:\n\u001b[1;32m--> 171\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mshared_encoder\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43medge_index\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    172\u001b[0m     x_hat \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mattr_decoder(x, edge_index)\n\u001b[0;32m    173\u001b[0m     struct_reconstructed \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstruct_decoder(x, edge_index)\n",
      "File \u001b[1;32mc:\\Users\\andwh\\Anaconda3\\envs\\PyGcuda\\lib\\site-packages\\torch\\nn\\modules\\module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\andwh\\Anaconda3\\envs\\PyGcuda\\lib\\site-packages\\torch\\nn\\modules\\module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32mc:\\users\\andwh\\documents\\p6\\aau-dat6-poison-gad\\gad_adversarial_robustness\\gad\\dominant\\dominant_neigh.py:123\u001b[0m, in \u001b[0;36mEncoder.forward\u001b[1;34m(self, x, edge_index)\u001b[0m\n\u001b[0;32m    121\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x: torch\u001b[38;5;241m.\u001b[39mTensor, edge_index: torch\u001b[38;5;241m.\u001b[39mTensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m torch\u001b[38;5;241m.\u001b[39mTensor:\n\u001b[0;32m    122\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlinear(x)\n\u001b[1;32m--> 123\u001b[0m     x \u001b[38;5;241m=\u001b[39m F\u001b[38;5;241m.\u001b[39mrelu(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgc1\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43medge_index\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[0;32m    124\u001b[0m     x \u001b[38;5;241m=\u001b[39m F\u001b[38;5;241m.\u001b[39mdropout(x, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdropout, training\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtraining)\n\u001b[0;32m    125\u001b[0m     x \u001b[38;5;241m=\u001b[39m F\u001b[38;5;241m.\u001b[39mrelu(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgc2(x, edge_index))\n",
      "File \u001b[1;32mc:\\Users\\andwh\\Anaconda3\\envs\\PyGcuda\\lib\\site-packages\\torch\\nn\\modules\\module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\andwh\\Anaconda3\\envs\\PyGcuda\\lib\\site-packages\\torch\\nn\\modules\\module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32mc:\\users\\andwh\\documents\\p6\\aau-dat6-poison-gad\\gad_adversarial_robustness\\gad\\dominant\\dominant_neigh.py:90\u001b[0m, in \u001b[0;36mNeighbourGraphConvolution.forward\u001b[1;34m(self, input, adj)\u001b[0m\n\u001b[0;32m     87\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m, adj):\n\u001b[0;32m     88\u001b[0m     \u001b[38;5;66;03m# AGGREGATE function (e.g., sum of neighbors' features)\u001b[39;00m\n\u001b[0;32m     89\u001b[0m     \u001b[38;5;66;03m# For simplicity, we use matrix multiplication with the adjacency matrix to aggregate features\u001b[39;00m\n\u001b[1;32m---> 90\u001b[0m     aggregated_neighbors \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mspmm\u001b[49m\u001b[43m(\u001b[49m\u001b[43madj\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m     92\u001b[0m     \u001b[38;5;66;03m# COMBINE function (weighted sum of the node's own features and aggregated neighbors' features)\u001b[39;00m\n\u001b[0;32m     93\u001b[0m     support \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mmm(\u001b[38;5;28minput\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mweight)\n",
      "\u001b[1;31mRuntimeError\u001b[0m: mat1 and mat2 shapes cannot be multiplied (2x11060 and 2708x96)"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "\"\"\"\n",
    "Dominant Aggr on poisoned data\n",
    "\"\"\"\n",
    "\n",
    "print(\"DOMINANT modified w/ new TAGConv on CLEAN data:\")\n",
    "adj, _, _, adj_label = load_anomaly_detection_dataset(clean_data, config['model']['device'])\n",
    "#edge_index = torch.LongTensor(np.array(sp.coo_matrix(adj).nonzero()))\n",
    "adj_label = torch.FloatTensor(adj_label).to(config['model']['device'])\n",
    "#attrs = torch.FloatTensor(attrs)\n",
    "\n",
    "edge_index = clean_data.edge_index.to(config['model']['device'])\n",
    "label = torch.Tensor(clean_data.y.bool()).to(config['model']['device'])\n",
    "attrs = clean_data.x.to(config['model']['device'])\n",
    "\n",
    "jaccard_params= {\n",
    "    \"threshold\": 0.01\n",
    "}\n",
    "\n",
    "model = DominantAggr(feat_size=attrs.size(1), hidden_size=config['model']['hidden_dim'], dropout=config['model']['dropout'],\n",
    "                    device=config['model']['device'], edge_index=edge_index, adj_label=adj_label, attrs=attrs, label=label)\n",
    "model.to(config['model']['device'])\n",
    "model.fit(config, verbose=False)\n",
    "\n",
    "print(\"DOMINANT modified w/ TAGConv on POISONED data (greedy w/ 300 budget):\")\n",
    "\n",
    "adj, _, _, adj_label = load_anomaly_detection_dataset(poisoned_data, config['model']['device'])\n",
    "#edge_index = torch.LongTensor(np.array(sp.coo_matrix(adj).nonzero()))\n",
    "adj_label = torch.FloatTensor(adj_label).to(config['model']['device'])\n",
    "#attrs = torch.FloatTensor(attrs)\n",
    "\n",
    "edge_index = poisoned_data.edge_index.to(config['model']['device'])\n",
    "label = torch.Tensor(poisoned_data.y.bool()).to(config['model']['device'])\n",
    "attrs = poisoned_data.x.to(config['model']['device'])\n",
    "\n",
    "jaccard_params= {\n",
    "    \"threshold\": 0.01\n",
    "}\n",
    "\n",
    "model = DominantAggr(feat_size=attrs.size(1), hidden_size=config['model']['hidden_dim'], dropout=config['model']['dropout'],\n",
    "                    device=config['model']['device'], edge_index=edge_index, adj_label=adj_label, attrs=attrs, label=label)\n",
    "model.to(config['model']['device'])\n",
    "model.fit(config, verbose=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nimport yaml\\n#from gad_adversarial_robustness.gad.dominant.dominant import Dominant\\n\\nfrom gad_adversarial_robustness.gad.dominant.dominant import Dominant \\nfrom gad_adversarial_robustness.gad.dominant.dominant_diffusion import Dominant as DominantDiff\\nfrom gad_adversarial_robustness.utils.graph_utils import load_anomaly_detection_dataset\\n\\nyaml_path = os.path.join(script_dir, \\'..\\', \\'configs\\', \\'dominant_config.yaml\\')\\nwith open(yaml_path) as file:\\n        config = yaml.safe_load(file)\\n\\n#DominantDiffusion on poisoned data\\n\\n\\nprint(\"Classic DOMINANT on CLEAN data:\")\\nadj, attrs, label, adj_label = load_anomaly_detection_dataset(clean_data)\\nadj = torch.FloatTensor(adj)\\nadj_label = torch.FloatTensor(adj_label)\\nattrs = torch.FloatTensor(attrs)\\n\\nmodel = Dominant(\\n        feat_size=attrs.size(1),\\n        hidden_size=config[\"model\"][\"hidden_dim\"],\\n        dropout=config[\"model\"][\"dropout\"],\\n        device=config[\"model\"][\"device\"],\\n        adj=adj,\\n        adj_label=adj_label,\\n        attrs=attrs,\\n        label=label,\\n    )\\nmodel.fit(config)\\n\\nprint(\"Classic DOMINANT on POISONED data (greedy w/ 300 budget):\")\\nadj, attrs, label, adj_label = load_anomaly_detection_dataset(poisoned_data)\\nadj = torch.FloatTensor(adj)\\nadj_label = torch.FloatTensor(adj_label)\\nattrs = torch.FloatTensor(attrs)\\n\\nmodel = Dominant(\\n        feat_size=attrs.size(1),\\n        hidden_size=config[\"model\"][\"hidden_dim\"],\\n        dropout=config[\"model\"][\"dropout\"],\\n        device=config[\"model\"][\"device\"],\\n        adj=adj,\\n        adj_label=adj_label,\\n        attrs=attrs,\\n        label=label,\\n    )\\nmodel.fit(config)\\n\\n\\n\\n#DominantDiffusion on poisoned data\\n\\n\\nprint(\"DOMINANT modified w/ diffusion on CLEAN data:\")\\nadj, attrs, label, adj_label = load_anomaly_detection_dataset(clean_data)\\nadj = torch.FloatTensor(adj)\\nadj_label = torch.FloatTensor(adj_label)\\nattrs = torch.FloatTensor(attrs)\\nmodel = DominantDiff(\\n        feat_size=attrs.size(1),\\n        hidden_size=config[\"model\"][\"hidden_dim\"],\\n        dropout=config[\"model\"][\"dropout\"],\\n        device=config[\"model\"][\"device\"],\\n        adj=adj,\\n        adj_label=adj_label,\\n        attrs=attrs,\\n        label=label,\\n    )\\n\\nmodel.fit(config)\\n\\nprint(\"DOMINANT modified w/ diffusion on POISONED data (greedy w/ 300 budget):\")\\n\\n\\nadj, attrs, label, adj_label = load_anomaly_detection_dataset(poisoned_data)\\nadj = torch.FloatTensor(adj)\\nadj_label = torch.FloatTensor(adj_label)\\nattrs = torch.FloatTensor(attrs)\\nmodel = DominantDiff(\\n        feat_size=attrs.size(1),\\n        hidden_size=config[\"model\"][\"hidden_dim\"],\\n        dropout=config[\"model\"][\"dropout\"],\\n        device=config[\"model\"][\"device\"],\\n        adj=adj,\\n        adj_label=adj_label,\\n        attrs=attrs,\\n        label=label,\\n    )\\n\\nmodel.fit(config)\\n\\n'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "import yaml\n",
    "#from gad_adversarial_robustness.gad.dominant.dominant import Dominant\n",
    "\n",
    "from gad_adversarial_robustness.gad.dominant.dominant import Dominant \n",
    "from gad_adversarial_robustness.gad.dominant.dominant_diffusion import Dominant as DominantDiff\n",
    "from gad_adversarial_robustness.utils.graph_utils import load_anomaly_detection_dataset\n",
    "\n",
    "yaml_path = os.path.join(script_dir, '..', 'configs', 'dominant_config.yaml')\n",
    "with open(yaml_path) as file:\n",
    "        config = yaml.safe_load(file)\n",
    "\n",
    "#DominantDiffusion on poisoned data\n",
    "\n",
    "\n",
    "print(\"Classic DOMINANT on CLEAN data:\")\n",
    "adj, attrs, label, adj_label = load_anomaly_detection_dataset(clean_data)\n",
    "adj = torch.FloatTensor(adj)\n",
    "adj_label = torch.FloatTensor(adj_label)\n",
    "attrs = torch.FloatTensor(attrs)\n",
    "\n",
    "model = Dominant(\n",
    "        feat_size=attrs.size(1),\n",
    "        hidden_size=config[\"model\"][\"hidden_dim\"],\n",
    "        dropout=config[\"model\"][\"dropout\"],\n",
    "        device=config[\"model\"][\"device\"],\n",
    "        adj=adj,\n",
    "        adj_label=adj_label,\n",
    "        attrs=attrs,\n",
    "        label=label,\n",
    "    )\n",
    "model.fit(config)\n",
    "\n",
    "print(\"Classic DOMINANT on POISONED data (greedy w/ 300 budget):\")\n",
    "adj, attrs, label, adj_label = load_anomaly_detection_dataset(poisoned_data)\n",
    "adj = torch.FloatTensor(adj)\n",
    "adj_label = torch.FloatTensor(adj_label)\n",
    "attrs = torch.FloatTensor(attrs)\n",
    "\n",
    "model = Dominant(\n",
    "        feat_size=attrs.size(1),\n",
    "        hidden_size=config[\"model\"][\"hidden_dim\"],\n",
    "        dropout=config[\"model\"][\"dropout\"],\n",
    "        device=config[\"model\"][\"device\"],\n",
    "        adj=adj,\n",
    "        adj_label=adj_label,\n",
    "        attrs=attrs,\n",
    "        label=label,\n",
    "    )\n",
    "model.fit(config)\n",
    "\n",
    "\n",
    "\n",
    "#DominantDiffusion on poisoned data\n",
    "\n",
    "\n",
    "print(\"DOMINANT modified w/ diffusion on CLEAN data:\")\n",
    "adj, attrs, label, adj_label = load_anomaly_detection_dataset(clean_data)\n",
    "adj = torch.FloatTensor(adj)\n",
    "adj_label = torch.FloatTensor(adj_label)\n",
    "attrs = torch.FloatTensor(attrs)\n",
    "model = DominantDiff(\n",
    "        feat_size=attrs.size(1),\n",
    "        hidden_size=config[\"model\"][\"hidden_dim\"],\n",
    "        dropout=config[\"model\"][\"dropout\"],\n",
    "        device=config[\"model\"][\"device\"],\n",
    "        adj=adj,\n",
    "        adj_label=adj_label,\n",
    "        attrs=attrs,\n",
    "        label=label,\n",
    "    )\n",
    "\n",
    "model.fit(config)\n",
    "\n",
    "print(\"DOMINANT modified w/ diffusion on POISONED data (greedy w/ 300 budget):\")\n",
    "\n",
    "\n",
    "adj, attrs, label, adj_label = load_anomaly_detection_dataset(poisoned_data)\n",
    "adj = torch.FloatTensor(adj)\n",
    "adj_label = torch.FloatTensor(adj_label)\n",
    "attrs = torch.FloatTensor(attrs)\n",
    "model = DominantDiff(\n",
    "        feat_size=attrs.size(1),\n",
    "        hidden_size=config[\"model\"][\"hidden_dim\"],\n",
    "        dropout=config[\"model\"][\"dropout\"],\n",
    "        device=config[\"model\"][\"device\"],\n",
    "        adj=adj,\n",
    "        adj_label=adj_label,\n",
    "        attrs=attrs,\n",
    "        label=label,\n",
    "    )\n",
    "\n",
    "model.fit(config)\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PyG",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
