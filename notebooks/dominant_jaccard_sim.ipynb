{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "import numpy as np\n",
    "import pygod\n",
    "from pygod.utils import load_data\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch_geometric.data import Data\n",
    "import torch_sparse\n",
    "from torch_sparse import SparseTensor\n",
    "from typing import List\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from gad_adversarial_robustness.utils.graph_utils import prepare_graph, get_n_anomaly_indexes, load_anomaly_detection_dataset\n",
    "from gad_adversarial_robustness.poison.greedy import multiple_AS, poison_attack\n",
    "\n",
    "import argparse\n",
    "import scipy.sparse as sp\n",
    "from scipy.sparse import coo_matrix\n",
    "from torch_geometric.utils.convert import from_scipy_sparse_matrix\n",
    "\n",
    "# --------- related to dataset import\n",
    "from pygod.generator import gen_contextual_outlier, gen_structural_outlier\n",
    "from torch_geometric.datasets import AttributedGraphDataset\n",
    "\n",
    "# --------- jaccard\n",
    "from gad_adversarial_robustness.gad.dominant.dominant_cuda_Jaccard_similarity import Dominant"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_CLASSES = 2\n",
    "PRELOADED_EDGE_INDEX = False\n",
    "EDGE_INDEX_PT = \"300_budget_greedy_edge_index.pt\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Import Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ------- datasets: \n",
    "data_name = [\"Cora\", \"Wiki\", \"Facebook\", \"Blogcatalog\"] # blogcataog not an option yet\n",
    "string = data_name[2]\n",
    "\n",
    "dataset = AttributedGraphDataset(root = \"data/\"+string, name = string)\n",
    "data = dataset[0]\n",
    "clean_data = data # save for later use\n",
    "\n",
    "# ------- inject dataset through pygod:\n",
    "seed = None\n",
    "num_nodes_to_inject = 20\n",
    "num_nodes_per_clique = 10\n",
    "num_cliques = (num_nodes_to_inject // 2) // num_nodes_per_clique\n",
    "num_contextual_outliers = num_nodes_to_inject - num_cliques * num_nodes_per_clique\n",
    "\n",
    "data, ya = gen_contextual_outlier(data, n = num_contextual_outliers, k = 50, seed = seed) \n",
    "#n (int) – Number of nodes converting to outliers.\n",
    "#k (int) – Number of candidate nodes for each outlier node.\n",
    "\n",
    "data, ys = gen_structural_outlier(data, m = num_nodes_per_clique, n = num_cliques, seed = seed)\n",
    "#m (int) - Number nodes in the outlier cliques.\n",
    "#n (int) - Number of outlier clique\n",
    "\n",
    "data.y = torch.logical_or(ys, ya).long() # where ys = y structural and ya = y attribute\n",
    "\n",
    "y_binary: List[int] = data.y.bool()\n",
    "anomaly_list = np.where(y_binary == True)[0]  # Used for list for which nodes to hide"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Data(x=[4039, 1283], edge_index=[2, 88324], y=[4039])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Modify data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([88324])\n",
      "88324\n"
     ]
    }
   ],
   "source": [
    "# -----> to obtain the dense_adj matrix from edge_index tensor \n",
    "edge_weight = torch.ones(data.edge_index.size(1))\n",
    "edge_weight = edge_weight.cpu()\n",
    "print(edge_weight.shape) # 11060\n",
    "\n",
    "adj = sp.csr_matrix((edge_weight, data.edge_index), (data.num_nodes, data.num_nodes))\n",
    "print(adj.size) # 11054\n",
    "\n",
    "adj = torch_sparse.SparseTensor.from_scipy(adj).coalesce().to(\"cpu\")\n",
    "\n",
    "# adj matrix based on edge_index\n",
    "data.adj = adj.to_dense()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0., 1., 1.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "torch.Size([4039, 4039])\n"
     ]
    }
   ],
   "source": [
    "print(data.adj)\n",
    "print(data.adj.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Posion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Create poison compatible adjacency matrix...\n",
      "Anomalies indexes: [  11  217  318  668  934 1670 1685 1710 2084 2334 2360 2661 2778 2961\n",
      " 2963 3326 3476 3536 3631 3702]\n",
      "Making model...\n",
      "Starting attack...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\karenscode\\dat6_gad\\aau-dat6-poison-gad\\gad_adversarial_robustness\\poison\\greedy.py:43: UserWarning: Sparse CSR tensor support is in beta state. If you miss a functionality in the sparse tensor support, please submit a feature request to https://github.com/pytorch/pytorch/issues. (Triggered internally at C:\\cb\\pytorch_1000000000000\\work\\aten\\src\\ATen\\SparseCsrTensorImpl.cpp:55.)\n",
      "  return torch.sparse.mm(torch.sparse.mm(A_sp, A_sp), A_sp).to_dense()\n",
      "d:\\karenscode\\dat6_gad\\aau-dat6-poison-gad\\gad_adversarial_robustness\\poison\\greedy.py:47: UserWarning: The use of `x.T` on tensors of dimension other than 2 to reverse their shape is deprecated and it will throw an error in a future release. Consider `x.mT` to transpose batches of matrices or `x.permute(*torch.arange(x.ndim - 1, -1, -1))` to reverse the dimensions of a tensor. (Triggered internally at C:\\cb\\pytorch_1000000000000\\work\\aten\\src\\ATen\\native\\TensorShape.cpp:3618.)\n",
      "  E = torch.sum(A, 1) + 0.5 * torch.diag(self.sparse_matrix_power(A, 3)).T\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "initial anomaly score: 106.60519312429084\n",
      "Iteration: 1 --- Anomaly score: 106.57597807740956\n",
      "Iteration: 2 --- Anomaly score: 106.45028160148823\n",
      "Iteration: 3 --- Anomaly score: 106.4160821603449\n",
      "Iteration: 4 --- Anomaly score: 106.29799505068871\n",
      "Iteration: 5 --- Anomaly score: 106.16275784404255\n",
      "Iteration: 6 --- Anomaly score: 106.04575996098119\n",
      "Iteration: 7 --- Anomaly score: 105.92977189159757\n",
      "Iteration: 8 --- Anomaly score: 105.7995460430152\n",
      "Iteration: 9 --- Anomaly score: 105.68213118733848\n",
      "Iteration: 10 --- Anomaly score: 105.55238190689516\n",
      "Iteration: 11 --- Anomaly score: 105.43609091554195\n",
      "Iteration: 12 --- Anomaly score: 105.31848432329144\n",
      "Iteration: 13 --- Anomaly score: 105.19952063037036\n",
      "Iteration: 14 --- Anomaly score: 105.0776321666385\n",
      "Iteration: 15 --- Anomaly score: 104.95407621874465\n",
      "Iteration: 16 --- Anomaly score: 104.83611051273868\n",
      "Iteration: 17 --- Anomaly score: 104.55144451090808\n",
      "Iteration: 18 --- Anomaly score: 104.37101774261379\n",
      "Iteration: 19 --- Anomaly score: 104.18439546117418\n",
      "Iteration: 20 --- Anomaly score: 104.00506522284091\n",
      "Iteration: 21 --- Anomaly score: 103.81987544366865\n",
      "Iteration: 22 --- Anomaly score: 103.64143606030977\n",
      "Iteration: 23 --- Anomaly score: 103.45747750328844\n",
      "Iteration: 24 --- Anomaly score: 103.27970484778763\n",
      "Iteration: 25 --- Anomaly score: 103.09676069316723\n",
      "Iteration: 26 --- Anomaly score: 102.91940802193906\n",
      "Iteration: 27 --- Anomaly score: 102.73724236265554\n",
      "Iteration: 28 --- Anomaly score: 102.56003508192272\n",
      "Iteration: 29 --- Anomaly score: 102.37838850735335\n",
      "Iteration: 30 --- Anomaly score: 102.20101751598551\n",
      "Iteration: 31 --- Anomaly score: 102.01960155028542\n",
      "Iteration: 32 --- Anomaly score: 101.84171466119003\n",
      "Iteration: 33 --- Anomaly score: 101.35737059090965\n",
      "Iteration: 34 --- Anomaly score: 101.17828440808464\n",
      "Iteration: 35 --- Anomaly score: 100.99601312074735\n",
      "Iteration: 36 --- Anomaly score: 100.8131703523471\n",
      "Iteration: 37 --- Anomaly score: 100.63238184534363\n",
      "Iteration: 38 --- Anomaly score: 100.44819354047443\n",
      "Iteration: 39 --- Anomaly score: 100.26541855948496\n",
      "Iteration: 40 --- Anomaly score: 100.07930229927189\n",
      "Iteration: 41 --- Anomaly score: 99.89385524614794\n",
      "Iteration: 42 --- Anomaly score: 99.70510776494879\n",
      "Iteration: 43 --- Anomaly score: 99.18540791634302\n",
      "Iteration: 44 --- Anomaly score: 98.99271527994844\n",
      "Iteration: 45 --- Anomaly score: 98.7987882299019\n",
      "Iteration: 46 --- Anomaly score: 98.6015596600084\n",
      "Iteration: 47 --- Anomaly score: 98.4017695924046\n",
      "Iteration: 48 --- Anomaly score: 98.19863009738884\n",
      "Iteration: 49 --- Anomaly score: 97.99121967277851\n",
      "Iteration: 50 --- Anomaly score: 97.78035809623518\n",
      "Iteration: 51 --- Anomaly score: 97.56294493782086\n",
      "Iteration: 52 --- Anomaly score: 97.34189961999017\n",
      "Iteration: 53 --- Anomaly score: 97.11113175366485\n",
      "Iteration: 54 --- Anomaly score: 96.87642731704861\n",
      "Iteration: 55 --- Anomaly score: 96.62736482415144\n",
      "Iteration: 56 --- Anomaly score: 96.37385610077453\n",
      "Iteration: 57 --- Anomaly score: 96.09876863893402\n",
      "Iteration: 58 --- Anomaly score: 95.81835394472147\n",
      "Iteration: 59 --- Anomaly score: 95.50411673240181\n",
      "Iteration: 60 --- Anomaly score: 95.51175957351035\n",
      "Iteration: 61 --- Anomaly score: 95.19108636199614\n",
      "Iteration: 62 --- Anomaly score: 94.93463166083119\n",
      "Iteration: 63 --- Anomaly score: 94.55552984722071\n",
      "Iteration: 64 --- Anomaly score: 94.26592278080834\n",
      "Iteration: 65 --- Anomaly score: 93.8727565904866\n",
      "Iteration: 66 --- Anomaly score: 93.57300758238857\n",
      "Iteration: 67 --- Anomaly score: 93.26350793773132\n",
      "Iteration: 68 --- Anomaly score: 92.9394591664793\n",
      "Iteration: 69 --- Anomaly score: 92.40623769847534\n",
      "Iteration: 70 --- Anomaly score: 91.8519913618489\n",
      "Iteration: 71 --- Anomaly score: 91.48783327723164\n",
      "Iteration: 72 --- Anomaly score: 91.08821124350617\n",
      "Iteration: 73 --- Anomaly score: 90.80791076508883\n",
      "Iteration: 74 --- Anomaly score: 90.34920594947314\n",
      "Iteration: 75 --- Anomaly score: 89.3085510403698\n",
      "Iteration: 76 --- Anomaly score: 89.01964374767464\n",
      "Iteration: 77 --- Anomaly score: 87.88406487587986\n",
      "Iteration: 78 --- Anomaly score: 87.57424575823416\n",
      "Iteration: 79 --- Anomaly score: 86.99519790551872\n",
      "Iteration: 80 --- Anomaly score: 86.3215757339042\n",
      "Iteration: 81 --- Anomaly score: 85.97103630874138\n",
      "Iteration: 82 --- Anomaly score: 85.35559292585565\n",
      "Iteration: 83 --- Anomaly score: 84.36570541268\n",
      "Iteration: 84 --- Anomaly score: 83.99102575582026\n",
      "Iteration: 85 --- Anomaly score: 83.08031311778629\n",
      "Iteration: 86 --- Anomaly score: 82.58827835048005\n",
      "Iteration: 87 --- Anomaly score: 82.49710444670949\n",
      "Iteration: 88 --- Anomaly score: 81.42612317010642\n",
      "Iteration: 89 --- Anomaly score: 81.30248654387589\n",
      "Iteration: 90 --- Anomaly score: 81.40284111948242\n",
      "Iteration: 91 --- Anomaly score: 81.07989378964021\n",
      "Iteration: 92 --- Anomaly score: 81.36405921946015\n",
      "Iteration: 93 --- Anomaly score: 80.67513670388182\n",
      "Iteration: 94 --- Anomaly score: 80.00783055139854\n",
      "Iteration: 95 --- Anomaly score: 78.44573587638659\n",
      "Iteration: 96 --- Anomaly score: 76.77185025816814\n",
      "Iteration: 97 --- Anomaly score: 75.25468800465794\n",
      "Iteration: 98 --- Anomaly score: 76.42169900490052\n",
      "Iteration: 99 --- Anomaly score: 74.66587123276844\n",
      "Iteration: 100 --- Anomaly score: 73.77213400295507\n",
      "Converting to compatible tensor...\n"
     ]
    }
   ],
   "source": [
    "# ----- compute new or load in poisoned data\n",
    "if PRELOADED_EDGE_INDEX is False :\n",
    "\n",
    "    # truth, of type int list, is instantiated to the T/F labels indicating whether a node is an anomalous node\n",
    "    truth: List[int] = data.y.bool()\n",
    "\n",
    "    print(\"Create poison compatible adjacency matrix...\") # based on code from: https://github.com/zhuyulin-tony/BinarizedAttack/blob/main/src/Greedy.py\n",
    "    triple = []\n",
    "    for i in range(data.num_nodes): # Cora has 2708 nodes\n",
    "        for j in range(i + 1, data.num_nodes):\n",
    "            triple.append([i, j, data.adj[i,j]])  #Fill with 0, then insert actual after\n",
    "\n",
    "    # convert tripple to numpy array\n",
    "    triple = np.array(triple)\n",
    "\n",
    "    # These are the nodes we try reduce the \"active subnetwork score\" for (i.e. disguising anonomalous nodes)\n",
    "    target_node_lst = get_n_anomaly_indexes(truth, 999) # the indexes of the anomalies\n",
    "\n",
    "    # print(type(target_node_lst)), print(f'target node list: {target_node_lst}'), print(target_node_lst)\n",
    "\n",
    "    print(\"Making model...\")\n",
    "    model = multiple_AS(target_lst = target_node_lst, n_node = data.num_nodes, device = 'cpu')\n",
    "    budget = 100  # The amount of edges to change\n",
    "\n",
    "\n",
    "    print(\"Starting attack...\")\n",
    "    adj_adversary, _, _ = poison_attack(model, triple, budget)\n",
    "\n",
    "\n",
    "    print(\"Converting to compatible tensor...\")\n",
    "\n",
    "    # Create Edge Index'\n",
    "    edge_index = torch.tensor([[],[]])\n",
    "\n",
    "    # Transpose it to make shape compatible\n",
    "    transposed_adj_adversary = torch.transpose(adj_adversary, 0, 1)\n",
    "\n",
    "    for i in range(len(adj_adversary)):\n",
    "        if(adj_adversary[i][2] != 0):   #If edge value is not 0 (no edge)\n",
    "            #Add edge to edge index, choosing first 2 elements (edges), and then the ith edge\n",
    "            edge_index = torch.cat((edge_index, transposed_adj_adversary[:2, i:i+1]), -1)\n",
    "            # Dataset uses edges both ways so add reverse edge as well\n",
    "            edge_index = torch.cat((edge_index, torch.flip(transposed_adj_adversary[:2, i:i+1], dims=[0])), -1)\n",
    "\n",
    "\n",
    "    edge_index = edge_index.type(torch.int64)\n",
    "    data.edge_index = edge_index # assign to dataset obj\n",
    "\n",
    "else : \n",
    "    data.edge_index = torch.load(EDGE_INDEX_PT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data(x=[4039, 1283], edge_index=[2, 176626], y=[4039], adj=[4039, 4039])\n",
      "Data(x=[4039, 1283], edge_index=[2, 176626], y=[4039], adj=[4039, 4039])\n"
     ]
    }
   ],
   "source": [
    "print(data)\n",
    "print(clean_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GAD: DOMINANT JACCARD SIMILARITY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# num_nodes = data.y.shape[0] # note: data already has attribute .num_nodes\n",
    "\n",
    "# # ---------- make adj matrix from data in coo format\n",
    "# edge_weight = torch.ones(data.edge_index.size(1))\n",
    "# edge_weight = edge_weight.cpu()\n",
    "\n",
    "# adj = sp.csr_matrix((edge_weight, data.edge_index), (data.num_nodes, data.num_nodes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # make a train/validation/test split #\n",
    "# labels = data.y\n",
    "\n",
    "# # ----------- create new masks with specified split \n",
    "# split = [0.6, 0.2, 0.2]\n",
    "# train_ratio = split[0]\n",
    "# val_ratio = split[1]\n",
    "# test_ratio = split[2]\n",
    "\n",
    "# # Create a random permutation of node indices\n",
    "# node_indices = torch.randperm(num_nodes)\n",
    "# print(node_indices)\n",
    "\n",
    "# # Calculate the split indices\n",
    "# train_size = int(num_nodes * train_ratio)\n",
    "# val_size = int(num_nodes * val_ratio)\n",
    "# test_size = num_nodes - train_size - val_size\n",
    "\n",
    "#     # Create new masks based on the split indices\n",
    "# new_train_mask = torch.zeros(num_nodes, dtype=torch.bool)\n",
    "# new_train_mask[node_indices[:train_size]] = True\n",
    "\n",
    "# new_val_mask = torch.zeros(num_nodes, dtype=torch.bool)\n",
    "# new_val_mask[node_indices[train_size:train_size+val_size]] = True\n",
    "\n",
    "# new_test_mask = torch.zeros(num_nodes, dtype=torch.bool)\n",
    "# new_test_mask[node_indices[train_size+val_size:]] = True\n",
    "\n",
    "# # Assign the new masks to the data object\n",
    "# data.train_mask = new_train_mask\n",
    "# data.val_mask = new_val_mask\n",
    "# data.test_mask = new_test_mask\n",
    "\n",
    "# # Extract the new indices for the training, validation, and test sets\n",
    "# idx_train = np.where(data.train_mask == True)[0]\n",
    "# idx_val = np.where(data.val_mask == True)[0]\n",
    "# idx_test = np.where(data.test_mask == True)[0]\n",
    "\n",
    "# # from the RTGNN github ----------------------------------------------\n",
    "# train_labels = labels[idx_train]\n",
    "# val_labels = labels[idx_val]\n",
    "\n",
    "# # Concatenating training and validation labels\n",
    "# train_val_labels = np.concatenate([train_labels, val_labels],axis=0)\n",
    "\n",
    "# # Concatenating training and validation masks\n",
    "# idx = np.concatenate([idx_train, idx_val],axis=0)\n",
    "\n",
    "\n",
    "# # # convert the T/F labels to integers --> used in the following call of \"noisyfy_with_P\"\n",
    "# train_val_labels_int = train_val_labels.astype(int)\n",
    "# # idx_int = idx.astype(int)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PyG",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
