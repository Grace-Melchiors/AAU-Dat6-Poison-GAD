{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "from torch.autograd import Variable\n",
    "#from torch_sparse import SparseTensor\n",
    "\n",
    "\n",
    "class multiple_AS(nn.Module):\n",
    "    def __init__(self, target_lst, n_node, device):\n",
    "        \"\"\"\n",
    "            target_lst (numpy.ndarray): The target list to be initialized.\n",
    "            n_node (int): The number of nodes.  \n",
    "            device (str): The device to be used.\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "        self.lst = target_lst\n",
    "        self.n = n_node\n",
    "        self.device = device\n",
    "    \n",
    "    def adjacency_matrix(self, tri):\n",
    "        A = torch.sparse_coo_tensor(tri[:,:2].T, tri[:,2], size=[self.n,self.n]).to_dense()\n",
    "        A = A + A.T - torch.diag(torch.diag(A)) # symmetric.\n",
    "        return A\n",
    "    \n",
    "    def sparse_matrix_power(self, A, tau):\n",
    "        A_sp = A.to_sparse()\n",
    "        A_sp = torch.sparse_coo_tensor(A_sp.indices(), A_sp.values(), size=[self.n,self.n])\n",
    "        return torch.sparse.mm(torch.sparse.mm(A_sp, A_sp), A_sp).to_dense()\n",
    "    \n",
    "    def extract_NE(self, A):    # Extract node and edge information based on adjecency matrix\n",
    "        N = torch.sum(A, 1)\n",
    "        E = torch.sum(A, 1) + 0.5 * torch.diag(self.sparse_matrix_power(A, 3)).T\n",
    "        N = N.reshape(-1,1)\n",
    "        E = E.reshape(-1,)\n",
    "        return N, E\n",
    "    \n",
    "    def OLS_estimation(self, N, E):\n",
    "        \"\"\"\n",
    "        OLS estimation function that calculates the Ordinary Least Squares estimate.\n",
    "        \n",
    "        Parameters:\n",
    "            N (tensor): Input tensor for independent variable N\n",
    "            E (tensor): Input tensor for dependent variable E\n",
    "        \n",
    "        Returns:\n",
    "            tensor: Tensor result of the OLS estimation\n",
    "        \"\"\"\n",
    "        logN = torch.log(N + 1e-20)\n",
    "        logE = torch.log(E + 1e-20)\n",
    "        logN1 = torch.cat((torch.ones((len(logN),1)).to(self.device), logN), 1)\n",
    "        return torch.linalg.pinv(logN1) @ logE\n",
    "        \n",
    "    def forward(self, tri): # Calculate the loss function / How much the output deviates from expected least squares estimate\n",
    "        A = self.adjacency_matrix(tri)\n",
    "        N, E = self.extract_NE(A)\n",
    "        theta = self.OLS_estimation(N, E)\n",
    "        b = theta[0] # Intercept\n",
    "        w = theta[1] # Coefficient\n",
    "        tmp = 0.\n",
    "        for i in range(len(self.lst)):\n",
    "            tmp += (torch.exp(b) * (N[self.lst[i]]**w) - E[self.lst[i]])**2 # Accumulate squared difference between expected (b * N[i]**w) and actual E[i]\n",
    "        return tmp\n",
    "    \n",
    "    def true_AS(self, tri): # Calculate the true anomaly score by using OLS (Page 3 https://arxiv.org/pdf/2106.09989.pdf)\n",
    "        # Originally from https://www.cs.cmu.edu/~christos/courses/826.F11/CMU-ONLY/oddball.pdf\n",
    "        # Or https://www.researchgate.net/profile/Leman-Akoglu/publication/220894884_OddBall_Spotting_Anomalies_in_Weighted_Graphs/links/0fcfd50b2ea00b30d2000000/OddBall-Spotting-Anomalies-in-Weighted-Graphs.pdf\n",
    "\n",
    "        A = self.adjacency_matrix(tri)\n",
    "        N, E = self.extract_NE(A)\n",
    "        theta = self.OLS_estimation(N, E)\n",
    "        b = theta[0] # Intercept\n",
    "        w = theta[1] # Coefficient\n",
    "        tmp = 0.\n",
    "        for i in range(len(self.lst)):\n",
    "            tmp += (torch.max(E[self.lst[i]],torch.exp(b)*(N[self.lst[i]]**w))\\\n",
    "                   /torch.min(E[self.lst[i]],torch.exp(b)*(N[self.lst[i]]**w)))*\\\n",
    "                    torch.log(torch.abs(E[self.lst[i]]-torch.exp(b)*(N[self.lst[i]]**w))+1)\n",
    "        return tmp\n",
    "\n",
    "def poison_attack(model, triple, B, print_stats = False):\n",
    "    triple_copy = triple.copy()\n",
    "    print(f'triple copy type: {type(triple_copy)}')\n",
    "    triple_torch = Variable(torch.from_numpy(triple_copy), requires_grad = True) \n",
    "    AS = []\n",
    "    perturb = []\n",
    "    AS.append(model.true_AS(triple_torch).data.numpy()[0])\n",
    "    if(print_stats): print('initial anomaly score:', model.true_AS(triple_torch).data.numpy()[0])\n",
    "    \n",
    "    for i in range(1,B+1):\n",
    "        loss = model.forward(triple_torch)\n",
    "        loss.backward()\n",
    "        \n",
    "        tmp = triple_torch.grad.data.numpy() # Get gradient of tensor with respect to data, stored in tmp\n",
    "\n",
    "\n",
    "        grad = np.concatenate((triple_torch[:,:2].data.numpy(),tmp[:,2:]),1) # Concat edge descriptor with gradients\n",
    "        \n",
    "\n",
    "        v_grad = np.zeros((len(grad),3))\n",
    "\n",
    "        for j in range(len(grad)):\n",
    "            v_grad[j,0] = grad[j,0]\n",
    "            v_grad[j,1] = grad[j,1]\n",
    "            if triple_copy[j,2] == 0 and grad[j,2] < 0: # If no edge and gradient is negative\n",
    "                v_grad[j,2] = grad[j,2]\n",
    "            elif triple_copy[j,2] == 1 and grad[j,2] > 0: # If edge and gradient is positive\n",
    "                v_grad[j,2] = grad[j,2]\n",
    "            else:\n",
    "                continue\n",
    "\n",
    "        # Get indexes of sorted gradients in descending order [3,1,2]->[1,2,0]\n",
    "        v_grad = v_grad[np.abs(v_grad[:,2]).argsort()] \n",
    "        \n",
    "\n",
    "        # attack w.r.t gradient information.\n",
    "        K = -1\n",
    "\n",
    "        # Takes the edge with largest gradient by using neg K value(last k element)and finds the first that isn't already changed\n",
    "        # Thusly changing the edge with the highest value\n",
    "        while v_grad[K][:2].astype('int').tolist() in perturb:\n",
    "            K -= 1\n",
    "\n",
    "        #print(v_grad[K])\n",
    "        \n",
    "        # for count in range(10):\n",
    "        #     print(v_grad[K-count])\n",
    "            \n",
    "            \n",
    "        # do not delete edge from singleton.\n",
    "        while v_grad[int(K)][2] > 0 and \\\n",
    "             (model.adjacency_matrix(triple_torch).data.numpy()[int(v_grad[int(K)][0])].sum() <= 1 or \\\n",
    "              model.adjacency_matrix(triple_torch).data.numpy()[int(v_grad[int(K)][1]) ].sum() <= 1):\n",
    "            K -= 1\n",
    "        \n",
    "        target_grad = v_grad[int(K)] #Picks edge to target\n",
    "\n",
    "        # Get index of target in triple\n",
    "        target_index = np.where(np.all((triple[:,:2] == target_grad[:2]), axis = 1) == True)[0][0]\n",
    "\n",
    "        # Update representation of adjacency matrix (triple_torch)\n",
    "        triple_copy[target_index,2] -= np.sign(target_grad[2])\n",
    "        #triple_torch = Variable(torch.from_numpy(triple_copy), requires_grad = True)\n",
    "\n",
    "        # Add perturb to list of perturbs\n",
    "        perturb.append([int(target_grad[0]),int(target_grad[1]), int(0 < target_grad[2])]) \n",
    "\n",
    "        # Get updated anomaly score\n",
    "        # if print_stats:\n",
    "        #     true_AScore = model.true_AS(triple_torch).data.numpy()[0] \n",
    "        #     print('iter', i, 'anomaly score:', true_AScore)\n",
    "\n",
    "        print('iter', i, \"perturb:\", v_grad[K]) # Temp\n",
    "\n",
    "    #AS = np.array(AS)    \n",
    "\n",
    "    sparse_tensor = triple_torch.to_sparse()\n",
    "\n",
    "    return triple_torch, AS, perturb\n",
    "\n",
    "from pygod.detector import DOMINANT\n",
    "from gad_adversarial_robustness.utils.graph_utils import prepare_graph, adj_matrix_sparse_coo_to_dense\n",
    "from gad_adversarial_robustness.utils.experiment_results import Experiment\n",
    "import torch\n",
    "from pygod.utils import load_data\n",
    "import copy\n",
    "from typing import Tuple, List, Any\n",
    "\n",
    "from sklearn.metrics import (\n",
    "    roc_auc_score,\n",
    "    average_precision_score,\n",
    "    f1_score\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.optim.sgd import SGD\n",
    "from torch.optim.optimizer import required\n",
    "from torch.optim import Optimizer\n",
    "import torch\n",
    "import sklearn\n",
    "import numpy as np\n",
    "import scipy.sparse as sp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([False, False, False,  ..., False, False, False])\n",
      "[  10   50   70   76  104  124  127  143  151  170  179  181  196  214\n",
      "  217  224  227  287  289  294  311  333  425  438  451  454  459  539\n",
      "  565  572  578  581  615  619  641  652  654  660  670  674  692  711\n",
      "  722  738  781  833  843  869  874  878  882  891  895  915  923  938\n",
      "  980  982  996 1002 1014 1035 1053 1079 1090 1096 1133 1135 1206 1211\n",
      " 1224 1229 1235 1287 1293 1310 1362 1391 1414 1426 1533 1540 1543 1547\n",
      " 1570 1573 1575 1606 1623 1633 1656 1674 1728 1730 1732 1783 1808 1818\n",
      " 1833 1854 1881 1885 1901 1918 1946 1999 2004 2041 2052 2055 2056 2078\n",
      " 2089 2121 2126 2198 2215 2234 2263 2265 2294 2307 2336 2340 2375 2382\n",
      " 2386 2397 2475 2479 2506 2518 2551 2600 2624 2654 2658 2693]\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.])\n",
      "node_attrs\n",
      "[[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "adj\n",
      "SparseTensor(row=tensor([   0,    0,    0,  ..., 2707, 2707, 2707]),\n",
      "             col=tensor([ 633, 1862, 2582,  ...,  598, 1473, 2706]),\n",
      "             val=tensor([1., 1., 1.,  ..., 1., 1., 1.]),\n",
      "             size=(2708, 2708), nnz=11054, density=0.15%)\n",
      "labels\n",
      "tensor([0, 0, 0,  ..., 0, 0, 0])\n",
      "Create poison compatible adjacency matrix...\n"
     ]
    }
   ],
   "source": [
    "data = load_data(\"inj_cora\")\n",
    "y_binary: List[int] = data.y.bool()\n",
    "print(y_binary)\n",
    "\n",
    "anomaly_list = np.where(y_binary == True)[0]  # Used for list for which nodes to hide\n",
    "print(anomaly_list)\n",
    "\n",
    "detector = DOMINANT(hid_dim=64, num_layers=4, epoch=100)\n",
    "detector.fit(data)\n",
    "\n",
    "pred, score, prob, conf = detector.predict(data,\n",
    "                                    return_pred=True,\n",
    "                                    return_score=True,\n",
    "                                    return_prob=True,\n",
    "                                    return_conf=True)\n",
    "experiment_before_poison = Experiment(data=data, pred=pred, prob=prob, score=score, conf=conf)\n",
    "\n",
    "_, adj, _ = prepare_graph(data)\n",
    "\n",
    "\n",
    "amount_of_nodes = data.num_nodes\n",
    "\n",
    "# 'triple' is a list that will store the perturbed triples during the poisoning process.\n",
    "# Each triple represents an edge modification in the form of (node1, node2, edge_label).\n",
    "\n",
    "dense_adj = adj.to_dense()  #Fill in zeroes where there are no edges\n",
    "\n",
    "\n",
    "print(\"Create poison compatible adjacency matrix...\")\n",
    "triple = []\n",
    "for i in range(amount_of_nodes):\n",
    "    for j in range(i + 1, amount_of_nodes):\n",
    "        triple.append([i, j, dense_adj[i,j]])  #Fill with 0, then insert actual after\n",
    "\n",
    "triple = np.array(triple)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[  10   50   70   76  104  124  127  143  151  170  179  181  196  214\n",
      "  217  224  227  287  289  294  311  333  425  438  451  454  459  539\n",
      "  565  572  578  581  615  619  641  652  654  660  670  674  692  711\n",
      "  722  738  781  833  843  869  874  878  882  891  895  915  923  938\n",
      "  980  982  996 1002 1014 1035 1053 1079 1090 1096 1133 1135 1206 1211\n",
      " 1224 1229 1235 1287 1293 1310 1362 1391 1414 1426 1533 1540 1543 1547\n",
      " 1570 1573 1575 1606 1623 1633 1656 1674 1728 1730 1732 1783 1808 1818\n",
      " 1833 1854 1881 1885 1901 1918 1946 1999 2004 2041 2052 2055 2056 2078\n",
      " 2089 2121 2126 2198 2215 2234 2263 2265 2294 2307 2336 2340 2375 2382\n",
      " 2386 2397 2475 2479 2506 2518 2551 2600 2624 2654 2658 2693]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "target_list = anomaly_list\n",
    "print(target_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Making model...\n",
      "Starting attack...\n",
      "triple copy type: <class 'numpy.ndarray'>\n",
      "initial anomaly score: 350.9628624456122\n",
      "iter 1 perturb: [151.         843.         771.53671275]\n",
      "iter 2 perturb: [ 641.         2600.         1511.41512842]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(\"Making model...\")\n",
    "model = multiple_AS(target_lst = target_list, n_node = amount_of_nodes, device = 'cpu')\n",
    "\n",
    "budget = target_list.shape[0] * 2  # The amount of edges to change\n",
    "\n",
    "budget = 2\n",
    "print(\"Starting attack...\")\n",
    "\n",
    "adj_adversary, AS, perturb = poison_attack(model, triple, budget, print_stats = True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Testing area\n",
    "edge_index = data.edge_index # Get a copy of original\n",
    "\n",
    "for change in perturb:\n",
    "    if (change[2] == 1):    #If to add edge\n",
    "        edge_index = torch.cat((edge_index, torch.tensor([[change[0], change[1]], [change[1], change[0]]])), -1)\n",
    "    else:   #Delete edge\n",
    "\n",
    "        for i in reversed(range(edge_index.size(dim = 1))):   #Cycle through all edges in reverse, if matches delete\n",
    "            if ((edge_index[0][i] == change[0] and edge_index[1][i] == change[1]) or\n",
    "                (edge_index[0][i] == change[1] and edge_index[1][i] == change[0])):\n",
    "                edge_index = torch.cat((edge_index[:, :i], edge_index[:, i+1:]), axis = 1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running model on poisoned data...\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "edge_index = torch.load('edge_index_after_poison276.pt')\n",
    "\n",
    "# Make new data object with new edge index\n",
    "data_after_poison = copy.deepcopy(data)\n",
    "edge_index = edge_index.type(torch.int64)\n",
    "data_after_poison.edge_index = edge_index\n",
    "\n",
    "print(\"Running model on poisoned data...\")\n",
    "\n",
    "detector_poisoned = DOMINANT(hid_dim=64, num_layers=4, epoch=100)\n",
    "detector_poisoned.fit(data_after_poison)\n",
    "\n",
    "pred_after, score_after, prob_after, conf_after = detector_poisoned.predict(data_after_poison,\n",
    "                                    return_pred=True,\n",
    "                                    return_score=True,\n",
    "                                    return_prob=True,\n",
    "                                    return_conf=True)\n",
    "experiment_after_poison = Experiment(data=data_after_poison, pred=pred_after, score=score_after, prob=prob_after, conf=conf_after)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before poison:\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import yaml\n",
    "#from torch_sparse import SparseTensor\n",
    "\n",
    "from gad_adversarial_robustness.gad.dominant.dominant import Dominant \n",
    "from gad_adversarial_robustness.utils.graph_utils import load_anomaly_detection_dataset\n",
    "from torch_geometric.data import Data\n",
    "from torch_geometric.utils import to_torch_sparse_tensor\n",
    "\n",
    "script_dir = os.path.abspath('')\n",
    "yaml_path = os.path.join(script_dir, '..', 'configs', 'dominant_config.yaml')\n",
    "with open(yaml_path) as file:\n",
    "        config = yaml.safe_load(file)\n",
    "\n",
    "dataset_caching_path = os.path.join(script_dir, '..', '..', '..', 'data')\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    config['model']['device'] = 'cuda'\n",
    "else:\n",
    "    config['model']['device'] = 'cpu'\n",
    "\n",
    "\n",
    "clean_data: Data = load_data(\"inj_cora\", dataset_caching_path)\n",
    "poisoned_data: Data = load_data(\"inj_cora\", dataset_caching_path)\n",
    "\n",
    "dataset: Data = load_data(\"inj_cora\")\n",
    "adj, _, _, adj_label = load_anomaly_detection_dataset(clean_data, config['model']['device'])\n",
    "#edge_index = torch.LongTensor(np.array(sp.coo_matrix(adj).nonzero()))\n",
    "adj_label = torch.FloatTensor(adj_label).to(config['model']['device'])\n",
    "#attrs = torch.FloatTensor(attrs)\n",
    "\n",
    "edge_index = dataset.edge_index.to(config['model']['device'])\n",
    "label = torch.Tensor(dataset.y.bool()).to(config['model']['device'])\n",
    "attrs = dataset.x.to(config['model']['device'])\n",
    "\n",
    "\n",
    "sparse_adj = to_torch_sparse_tensor(edge_index)\n",
    "\n",
    "print(\"Before poison:\")\n",
    "dom_model = Dominant(feat_size=attrs.size(1), hidden_size=config['model']['hidden_dim'], dropout=config['model']['dropout'],\n",
    "                device=config['model']['device'], edge_index=sparse_adj, adj_label=adj_label, attrs=attrs, label=label)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\grace\\anaconda3\\envs\\PyG2\\lib\\site-packages\\torch_geometric\\utils\\_spmm.py:60: UserWarning: Converting sparse tensor to CSR format for more efficient processing. Consider converting your sparse tensor to CSR format beforehand to avoid repeated conversion (got 'torch.sparse_coo')\n",
      "  warnings.warn(f\"Converting sparse tensor to CSR format for more \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0199, Auc: 0.8236846557266113\n"
     ]
    }
   ],
   "source": [
    "testingModel = Dominant(feat_size=attrs.size(1), hidden_size=config['model']['hidden_dim'], dropout=config['model']['dropout'],\n",
    "                device=config['model']['device'], edge_index=sparse_adj, adj_label=adj_label, attrs=attrs, label=label)\n",
    "testingModel.to(config['model']['device'])\n",
    "testingModel.fit(config, verbose=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(indices=tensor([[   0,    0,    0,  ..., 2707, 2707, 2707],\n",
      "                       [ 633, 1862, 2582,  ...,  598, 1473, 2706]]),\n",
      "       values=tensor([1., 1., 1.,  ..., 1., 1., 1.]),\n",
      "       size=(2708, 2708), nnz=11054, layout=torch.sparse_coo)\n",
      "torch.Size([2708, 2708])\n",
      "torch.sparse.FloatTensor\n",
      "tensor([[1., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 1.,  ..., 0., 0., 0.],\n",
      "        [0., 1., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 1., 0.]])\n",
      "torch.Size([2708, 2708])\n",
      "torch.FloatTensor\n",
      "tensor(indices=tensor([[   0,    0,    0,  ..., 2707, 2707, 2707],\n",
      "                       [   0,  633, 1862,  ...,  598, 1473, 2706]]),\n",
      "       values=tensor([1., 1., 1.,  ..., 1., 1., 1.]),\n",
      "       size=(2708, 2708), nnz=11055, layout=torch.sparse_coo)\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Making model...\n",
      "Starting attack...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\grace\\AppData\\Local\\Temp\\ipykernel_21016\\3428229394.py:30: UserWarning: Sparse CSR tensor support is in beta state. If you miss a functionality in the sparse tensor support, please submit a feature request to https://github.com/pytorch/pytorch/issues. (Triggered internally at C:\\cb\\pytorch_1000000000000\\work\\aten\\src\\ATen\\SparseCsrTensorImpl.cpp:55.)\n",
      "  return torch.sparse.mm(torch.sparse.mm(A_sp, A_sp), A_sp).to_dense()\n",
      "C:\\Users\\grace\\AppData\\Local\\Temp\\ipykernel_21016\\3428229394.py:34: UserWarning: The use of `x.T` on tensors of dimension other than 2 to reverse their shape is deprecated and it will throw an error in a future release. Consider `x.mT` to transpose batches of matrices or `x.permute(*torch.arange(x.ndim - 1, -1, -1))` to reverse the dimensions of a tensor. (Triggered internally at C:\\cb\\pytorch_1000000000000\\work\\aten\\src\\ATen\\native\\TensorShape.cpp:3618.)\n",
      "  E = torch.sum(A, 1) + 0.5 * torch.diag(self.sparse_matrix_power(A, 3)).T\n",
      "c:\\Users\\grace\\anaconda3\\envs\\PyG2\\lib\\site-packages\\torch_geometric\\utils\\_spmm.py:60: UserWarning: Converting sparse tensor to CSR format for more efficient processing. Consider converting your sparse tensor to CSR format beforehand to avoid repeated conversion (got 'torch.sparse_coo')\n",
      "  warnings.warn(f\"Converting sparse tensor to CSR format for more \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0199, Auc: 0.8225201601533864\n",
      "initial anomaly score: 350.9628624456122\n",
      "Flag 1\n",
      "Flag 2\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "Cannot assign to a sparse tensor",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[9], line 11\u001b[0m\n\u001b[0;32m      7\u001b[0m budget \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m2\u001b[39m\n\u001b[0;32m      9\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mStarting attack...\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m---> 11\u001b[0m _, AS, AS_DOM, AUC_DOM, ACC_DOM, perturb, edge_index \u001b[38;5;241m=\u001b[39m \u001b[43mgreedy_attack_with_statistics\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m     12\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtriple\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdom_model\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtarget_list\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbudget\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprint_stats\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\grace\\anaconda3\\envs\\PyG2\\lib\\site-packages\\gad_adversarial_robustness\\poison\\greedy.py:268\u001b[0m, in \u001b[0;36mgreedy_attack_with_statistics\u001b[1;34m(model, triple, DOMINANT_model, config, target_list, B, CPI, print_stats)\u001b[0m\n\u001b[0;32m    266\u001b[0m true_AScore \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mtrue_AS(triple_torch)\u001b[38;5;241m.\u001b[39mdata\u001b[38;5;241m.\u001b[39mnumpy()[\u001b[38;5;241m0\u001b[39m] \n\u001b[0;32m    267\u001b[0m AS\u001b[38;5;241m.\u001b[39mappend(true_AScore)\n\u001b[1;32m--> 268\u001b[0m AS_DOM_temp, AUC_DOM_temp, ACC_DOM_temp \u001b[38;5;241m=\u001b[39m \u001b[43mget_DOMINANT_eval_values\u001b[49m\u001b[43m(\u001b[49m\u001b[43mDOMINANT_model\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtarget_list\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mperturb\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    269\u001b[0m AS_DOM\u001b[38;5;241m.\u001b[39mappend(AS_DOM_temp)\n\u001b[0;32m    270\u001b[0m AUC_DOM\u001b[38;5;241m.\u001b[39mappend(AUC_DOM_temp)\n",
      "File \u001b[1;32mc:\\Users\\grace\\anaconda3\\envs\\PyG2\\lib\\site-packages\\gad_adversarial_robustness\\poison\\greedy.py:155\u001b[0m, in \u001b[0;36mget_DOMINANT_eval_values\u001b[1;34m(model, config, target_list, perturb)\u001b[0m\n\u001b[0;32m    141\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    142\u001b[0m \u001b[38;5;124;03m    parameters:\u001b[39;00m\n\u001b[0;32m    143\u001b[0m \u001b[38;5;124;03m    - model: The DOMINANT model\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    151\u001b[0m \u001b[38;5;124;03m    - ACC_DOM: AUC value only considering target nodes, according to DOMINANT\u001b[39;00m\n\u001b[0;32m    152\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    154\u001b[0m \u001b[38;5;66;03m#model.edge_index = update_edge_data_with_perturb(model.edge_index, perturb)\u001b[39;00m\n\u001b[1;32m--> 155\u001b[0m model\u001b[38;5;241m.\u001b[39medge_index \u001b[38;5;241m=\u001b[39m \u001b[43mupdate_adj_matrix_with_perturb\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43medge_index\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mperturb\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    157\u001b[0m model\u001b[38;5;241m.\u001b[39mto(config[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmodel\u001b[39m\u001b[38;5;124m'\u001b[39m][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdevice\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[0;32m    158\u001b[0m model\u001b[38;5;241m.\u001b[39mfit(config, verbose\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "File \u001b[1;32mc:\\Users\\grace\\anaconda3\\envs\\PyG2\\lib\\site-packages\\gad_adversarial_robustness\\poison\\greedy.py:100\u001b[0m, in \u001b[0;36mupdate_adj_matrix_with_perturb\u001b[1;34m(adj_matrix, perturb)\u001b[0m\n\u001b[0;32m     89\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m     90\u001b[0m \u001b[38;5;124;03m    A faster way of converting perturbations to the edge_data\u001b[39;00m\n\u001b[0;32m     91\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     97\u001b[0m \u001b[38;5;124;03m    - adj_matrix: The updated adjacency matrix\u001b[39;00m\n\u001b[0;32m     98\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m     99\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m change \u001b[38;5;129;01min\u001b[39;00m perturb:\n\u001b[1;32m--> 100\u001b[0m     \u001b[43madj_matrix\u001b[49m\u001b[43m[\u001b[49m\u001b[43mchange\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mchange\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m]\u001b[49m \u001b[38;5;241m=\u001b[39m change[\u001b[38;5;241m2\u001b[39m]\n\u001b[0;32m    101\u001b[0m     adj_matrix[change[\u001b[38;5;241m1\u001b[39m], change[\u001b[38;5;241m0\u001b[39m]] \u001b[38;5;241m=\u001b[39m change[\u001b[38;5;241m2\u001b[39m]\n\u001b[0;32m    103\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m adj_matrix\n",
      "\u001b[1;31mTypeError\u001b[0m: Cannot assign to a sparse tensor"
     ]
    }
   ],
   "source": [
    "\n",
    "from gad_adversarial_robustness.poison.greedy import greedy_attack_with_statistics\n",
    "print(\"Making model...\")\n",
    "model = multiple_AS(target_lst = target_list, n_node = amount_of_nodes, device = config['model']['device'])\n",
    "\n",
    "budget = target_list.shape[0] * 2  # The amount of edges to change\n",
    "\n",
    "budget = 2\n",
    "\n",
    "print(\"Starting attack...\")\n",
    "\n",
    "_, AS, AS_DOM, AUC_DOM, ACC_DOM, perturb, edge_index = greedy_attack_with_statistics(\n",
    "    model, triple, dom_model, config, target_list, budget, print_stats = True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(indices=tensor([[   0,    0,    0,  ..., 2707, 2707, 2707],\n",
      "                       [ 633, 1862, 2582,  ...,  598, 1473, 2706]]),\n",
      "       values=tensor([1., 1., 1.,  ..., 1., 1., 1.]),\n",
      "       size=(2708, 2708), nnz=11054, layout=torch.sparse_coo)\n",
      "tensor([False, False, False,  ..., False, False, False])\n",
      "tensor([True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True])\n",
      "[  10   50   70   76  104  124  127  143  151  170  179  181  196  214\n",
      "  217  224  227  287  289  294  311  333  425  438  451  454  459  539\n",
      "  565  572  578  581  615  619  641  652  654  660  670  674  692  711\n",
      "  722  738  781  833  843  869  874  878  882  891  895  915  923  938\n",
      "  980  982  996 1002 1014 1035 1053 1079 1090 1096 1133 1135 1206 1211\n",
      " 1224 1229 1235 1287 1293 1310 1362 1391 1414 1426 1533 1540 1543 1547\n",
      " 1570 1573 1575 1606 1623 1633 1656 1674 1728 1730 1732 1783 1808 1818\n",
      " 1833 1854 1881 1885 1901 1918 1946 1999 2004 2041 2052 2055 2056 2078\n",
      " 2089 2121 2126 2198 2215 2234 2263 2265 2294 2307 2336 2340 2375 2382\n",
      " 2386 2397 2475 2479 2506 2518 2551 2600 2624 2654 2658 2693]\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'Dominant' object has no attribute 'score'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[132], line 22\u001b[0m\n\u001b[0;32m     15\u001b[0m \u001b[38;5;28mprint\u001b[39m(target_node_mask(target_list, model\u001b[38;5;241m.\u001b[39mlabel))\n\u001b[0;32m     18\u001b[0m \u001b[38;5;28mprint\u001b[39m(target_list)\n\u001b[1;32m---> 22\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAuc: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mroc_auc_score(model\u001b[38;5;241m.\u001b[39mlabel,\u001b[38;5;250m \u001b[39mmodel\u001b[38;5;241m.\u001b[39mscore)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     25\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAfter poison:\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     27\u001b[0m edge_index \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mload(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124medge_index_after_poison276.pt\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\grace\\anaconda3\\envs\\PyG2\\lib\\site-packages\\torch\\nn\\modules\\module.py:1695\u001b[0m, in \u001b[0;36mModule.__getattr__\u001b[1;34m(self, name)\u001b[0m\n\u001b[0;32m   1693\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01min\u001b[39;00m modules:\n\u001b[0;32m   1694\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m modules[name]\n\u001b[1;32m-> 1695\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mAttributeError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mtype\u001b[39m(\u001b[38;5;28mself\u001b[39m)\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m object has no attribute \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'Dominant' object has no attribute 'score'"
     ]
    }
   ],
   "source": [
    "print(model.edge_index)\n",
    "\n",
    "\n",
    "def target_node_mask(target_list, tuple_list):\n",
    "    new_list = []\n",
    "    for index in target_list:\n",
    "        new_list.append(tuple_list[index])\n",
    "    \n",
    "    t = torch.tensor(new_list)\n",
    "\n",
    "    return t\n",
    "\n",
    "\n",
    "print(model.label)\n",
    "\n",
    "print(target_node_mask(target_list, model.label))\n",
    "\n",
    "\n",
    "print(target_list)\n",
    "\n",
    "\n",
    "\n",
    "print(f\"Auc: {roc_auc_score(model.label, model.score)}\")\n",
    "\n",
    "\n",
    "print(\"After poison:\")\n",
    "\n",
    "edge_index = torch.load('edge_index_after_poison276.pt')\n",
    "\n",
    "\n",
    "sparse_adj = to_torch_sparse_tensor(edge_index)\n",
    "model = Dominant(feat_size=attrs.size(1), hidden_size=config['model']['hidden_dim'], dropout=config['model']['dropout'],\n",
    "                device=config['model']['device'], edge_index=sparse_adj, adj_label=adj_label, attrs=attrs, label=label)\n",
    "model.to(config['model']['device'])\n",
    "model.fit(config, verbose=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "# torch.save(data_after_poison.edge_index, 'edge_index_after_poison.pt')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch_geometric.utils.mask import index_to_mask\n",
    "from torch_geometric.utils.num_nodes import maybe_num_nodes\n",
    "\n",
    "def getAvgScoreOfNeighbors(anomalyIndex, prob, data):\n",
    "\n",
    "    edge_index = data.edge_index\n",
    "    subset = torch.from_numpy(anomalyIndex)\n",
    "\n",
    "    num_nodes = maybe_num_nodes(edge_index) # gets amount of nodes present in edges\n",
    "    node_mask = index_to_mask(subset, size=num_nodes) # creates node mask\n",
    "\n",
    "    edge_mask = node_mask[edge_index[0]] # create edge mask to find nodes starting from origin\n",
    "\n",
    "    edge_index = edge_index[:, edge_mask] # apply mask\n",
    "\n",
    "    neighbor_nodes = edge_index[1]  # get the edge destinations \n",
    "\n",
    "    #neighbor_nodes = torch.unique(neighbor_nodes)\n",
    "\n",
    "    neighbor_nodes = neighbor_nodes.numpy()\n",
    "    sum = 0\n",
    "    anomaly_percent = 0\n",
    "    len = neighbor_nodes.size\n",
    "    for node in neighbor_nodes:\n",
    "\n",
    "        #print(\"anomaly score for \" + str(node) + \" before poison: \" + str(score[node].item()) + \" after poison: \" + str(score_after[node].item()))\n",
    "        sum += prob[node].item()\n",
    "        if(node in anomaly_list):\n",
    "            anomaly_percent += 1\n",
    "\n",
    "\n",
    "    return neighbor_nodes, sum/len, anomaly_percent/len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "auc before poison:\n",
      "0.7682428241132351\n",
      "auc after poison:\n",
      "0.571313370552078\n",
      "List of perturbed edges:\n",
      "[[0, 633, 0], [0, 1862, 0]]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "\n",
    "print(\"auc before poison:\")\n",
    "print(roc_auc_score(y_binary, score))\n",
    "print(\"auc after poison:\")\n",
    "print(roc_auc_score(y_binary, score_after))\n",
    "#print(roc_auc_score(data_inj.y.detach().numpy(), score_inj.detach.numpy()))\n",
    "\n",
    "print(\"List of perturbed edges:\")\n",
    "print(perturb)\n",
    "# Testing only for the targetted nodes\n",
    "#for anomalyIndex in target_list:\n",
    "\n",
    "    #print(\"pred score for \" + str(anomalyIndex) + \" before poison: \" + str(prob[anomalyIndex].item()) + \" after poison: \" + str(prob_after[anomalyIndex].item()))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2707\n",
      "tensor(10, dtype=torch.int32)\n",
      "tensor(20, dtype=torch.int32)\n",
      "tensor([[0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0.]])\n",
      "[[0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0.]]\n"
     ]
    }
   ],
   "source": [
    "tensor = torch.tensor(np.arange(data.num_nodes))\n",
    "\n",
    "tensor2 = torch.max(torch.cat((tensor, tensor), dim=0)).item()\n",
    "\n",
    "print(tensor2)\n",
    "\n",
    "number = tensor[10]\n",
    "print(number)\n",
    "\n",
    "number = number + 10\n",
    "\n",
    "print(tensor[number])\n",
    "\n",
    "tens = torch.zeros(2,5)\n",
    "print(tens)\n",
    "tens = tens.numpy()\n",
    "print(tens)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3, 5, 4]\n"
     ]
    }
   ],
   "source": [
    "from gad_adversarial_robustness.utils.subgraphs import get_subset_neighbors\n",
    "from torch_geometric.utils.num_nodes import maybe_num_nodes\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "def get_rest_of_node_idxs(subset_idxs, num_nodes):\n",
    "    \"\"\"\n",
    "        Function to get the indices of the remaining nodes after removing the nodes specified in subset_idxs.\n",
    "\n",
    "        - subset_idxs (tensor): The idxs of the nodes not to include.\n",
    "        - num_nodes (int): The total number of nodes in the graph.\n",
    "\n",
    "        Returns:\n",
    "        A tensor containing all node idxs not in the subset\n",
    "        \"\"\"\n",
    "\n",
    "    rest_of_node_idxs = torch.tensor(np.arange(num_nodes))\n",
    "\n",
    "    for i in subset_idxs:\n",
    "        rest_of_node_idxs = torch.cat([rest_of_node_idxs[0:i], rest_of_node_idxs[i+1:]])\n",
    "    \n",
    "    return rest_of_node_idxs\n",
    "\n",
    "def visualize_local_degree_assortativity(edge_index_list, graph_names = None, cut_off = None):\n",
    "    \"\"\"\n",
    "        Visualizes the cumulative distribution of local_degree_assortativity for a list of edge_indexes\n",
    "        Parameters:\n",
    "        - edge_index_list: List of edge indexes of the graphs\n",
    "        - graph_names (list of str): The names of the graphs\n",
    "        - cut_off (int): Limiter for amount of neighbors to display. Default none.\n",
    "\n",
    "        Returns:\n",
    "        No return value.\n",
    "        \"\"\"\n",
    "    \n",
    "    fig = plt.figure(figsize=(9, 4), layout=\"constrained\")\n",
    "    ax = fig.add_subplot(1, 1, 1)\n",
    "\n",
    "    # For each subset....\n",
    "    for i, edge_index in enumerate(edge_index_list):\n",
    "\n",
    "        # Get amount of neighbors for each node\n",
    "        num_nodes = maybe_num_nodes(edge_index)\n",
    "        node_idxs = torch.tensor(np.arange(num_nodes))\n",
    "        node_idxs_neighbors_amount = []\n",
    "\n",
    "        # Find \n",
    "        for idx in node_idxs:\n",
    "            neighbor_node = get_subset_neighbors(idx, edge_index)  #Get neighbors\n",
    "            neighbor_degrees = np.array(get_subset_neighbors(neighbor_nodes[n], edge_index).size()[0] for n in range(neighbor_node.size()[0])) #Get degrees of neighbors\n",
    "\n",
    "            average_degree = neighbor_degrees.mean()\n",
    "            idx_degree = neighbor_nodes.size()[0]\n",
    "\n",
    "            amount = neighbor_nodes.size()[0]   # Get amount\n",
    "            amount = amount - 1 # Subtract self\n",
    "            node_idxs_neighbors_amount.append(amount)\n",
    "\n",
    "        # Name graph\n",
    "        graph_name = 'graph' + str(i)\n",
    "        if(graph_names is not None):\n",
    "            graph_name = graph_names[i]\n",
    "        ax.ecdf(node_idxs_neighbors_amount, label=graph_name)\n",
    "        \n",
    "   # Label figure\n",
    "    fig.suptitle(\"Cumulative distribution of 2hop node degrees\")\n",
    "\n",
    "    ax.grid(True)\n",
    "    ax.legend()\n",
    "    ax.set_xlabel(\"2hop Node degree\")\n",
    "    ax.set_ylabel(\"Probability of occurrence\")\n",
    "    ax.label_outer()\n",
    "\n",
    "    if(cut_off is not None):\n",
    "        ax.set_xbound(0, cut_off)\n",
    "            \n",
    "    plt.show()\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAA48AAAGbCAYAAABksaWrAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjguMCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy81sbWrAAAACXBIWXMAAA9hAAAPYQGoP6dpAACFgElEQVR4nOzdd3gU1f7H8ffuZtMbCaRRQlG6dFFArtJBpVjxolIEfiIKIja4FoqFK9brVUS9CHZBBSuKKEURUekKSIdQEkICJCQhyWZ3fn9sshB2IQkm2YV8Xs+TZ3fOnJn57p6dZL85Z86YDMMwEBERERERETkLs7cDEBEREREREd+n5FFERERERERKpORRRERERERESqTkUUREREREREqk5FFERERERERKpORRRERERERESqTkUUREREREREqk5FFERERERERKpORRRERERERESqTkUUR8wsaNGxk2bBj16tUjMDCQ0NBQ2rRpw/Tp0zly5Ii3wzuryZMnYzKZzmnbhQsXMnnyZI/r6taty9ChQ889sHJ2ejzLli3DZDKxbNmyMu1nxowZzJkzp0zbeDrW0KFDCQ0NLdN+SrJy5UomT57MsWPH3NZdddVVXHXVVeV6vPK2Z88errnmGqKiojCZTIwbN87bITFnzhxMJhN79uy5II4jIlKV+Xk7ABGRN998k9GjR9OoUSMefPBBmjZtis1mY/Xq1cycOZNffvmFBQsWeDvMCrFw4UJeffVVjwnkggULCA8Pr/ygSqlNmzb88ssvNG3atEzbzZgxg+rVq5cpMT7XY5XVypUrmTJlCkOHDiUyMrLYuhkzZlToscvDfffdx6+//spbb71FXFwc8fHx3g5JREQuIEoeRcSrfvnlF+666y569OjBZ599RkBAgGtdjx49uP/++/n222+9GKH3tG7d2tshnFV4eDiXX355hR7DZrNhMpkq5VglqejEtTz8+eeftG/fngEDBng7lCrDbrdTUFBQ7HeXiMiFSsNWRcSrnn76aUwmE2+88YbHL1/+/v7069fPtWwymTz20p0+pLJoCNuSJUsYOXIk0dHRhIeHM3jwYLKzs0lJSeHmm28mMjKS+Ph4HnjgAWw2m2v7Mw3J3LNnDyaTqcRhl3PnzqVnz57Ex8cTFBREkyZNmDBhAtnZ2a46Q4cO5dVXX3W9rqKfomF3p76mw4cP4+/vz2OPPeZ2rL/++guTycTLL7/sKktJSeHOO++kVq1a+Pv7U69ePaZMmUJBQcFZ4wZnwvbQQw8RFxdHcHAwV1xxBb/99ptbPU/v0a5du7jllltISEggICCA2NhYunXrxvr1612vadOmTSxfvtz1euvWrVtsf++++y73338/NWvWJCAggB07dpx1iOymTZvo1q0bISEh1KhRg3vuuYecnBzX+rO12amfp8mTJ/Pggw8CUK9ePVd8Rcf0NGz1yJEjjB49mpo1a+Lv70/9+vV55JFHyMvLczvOPffcw7vvvkuTJk0IDg6mZcuWfPXVV2duiFMkJSVx2223ERMTQ0BAAE2aNOH555/H4XAUe+927NjBN9984/ZZ8qQsMa1YsYJu3boRFhZGcHAwHTt25Ouvv3art2rVKjp16kRgYCAJCQlMnDix2Hl1qrlz59KhQwdCQkIIDQ2lV69erFu3rlTvR0Uc580336Rhw4YEBATQtGlTPvjgA4YOHer6fMLJz9L06dN58sknqVevHgEBASxduhSA1atX069fP6KioggMDKR169bMmzfP7VilPT9fe+01WrZsSWhoKGFhYTRu3Jh//etfpXqPREQqgnoeRcRr7HY7S5YsoW3bttSuXbtCjjFixAiuv/56PvroI9atW8e//vUvCgoK2Lp1K9dffz3/93//x/fff88zzzxDQkIC48ePL5fjbt++nauvvppx48YREhLCX3/9xTPPPMNvv/3GkiVLAHjsscfIzs7mk08+4ZdffnFt62moYY0aNbj22mt5++23mTJlCmbzyf/9zZ49G39/f2699VbA+cW0ffv2mM1mHn/8cRo0aMAvv/zCk08+yZ49e5g9e/ZZYx85ciTvvPMODzzwAD169ODPP//k+uuv5/jx4yW+7quvvhq73c706dOpU6cOaWlprFy50nUN4YIFC7jxxhuJiIhwDQM9/Z8GEydOpEOHDsycOROz2UxMTAwpKSkej2ez2bj66qu58847mTBhAitXruTJJ59k7969fPnllyXGe6oRI0Zw5MgR/vvf/zJ//nxXO5ypxzE3N5cuXbqwc+dOpkyZQosWLfjpp5+YNm0a69evd0uuvv76a37//XemTp1KaGgo06dP57rrrmPr1q3Ur1//jHEdPnyYjh07kp+fzxNPPEHdunX56quveOCBB9i5cyczZsxwDeu97rrraNCgAc899xzg+bNU1piWL19Ojx49aNGiBbNmzSIgIIAZM2bQt29fPvzwQwYOHAjA5s2b6datG3Xr1mXOnDkEBwczY8YMPvjgA7fjPv300zz66KMMGzaMRx99lPz8fJ599lk6d+7Mb7/9dtZe3oo4zhtvvMGdd97JDTfcwIsvvkhGRgZTpkxx+ydAkZdffpmGDRvy3HPPER4ezsUXX8zSpUvp3bs3l112GTNnziQiIoKPPvqIgQMHkpOT4/pHUGnPz48++ojRo0czZswYnnvuOcxmMzt27GDz5s1nbVMRkQpliIh4SUpKigEYt9xyS6m3AYxJkya5lScmJhpDhgxxLc+ePdsAjDFjxhSrN2DAAAMwXnjhhWLlrVq1Mtq0aeNaXrp0qQEYS5cuLVZv9+7dBmDMnj3bVTZp0iTjbL9OHQ6HYbPZjOXLlxuAsWHDBte6u++++4zbnv6avvjiCwMwvvvuO1dZQUGBkZCQYNxwww2usjvvvNMIDQ019u7dW2x/zz33nAEYmzZtOmOsW7ZsMQDjvvvuK1b+/vvvG0CxeE5/j9LS0gzAeOmll864f8MwjGbNmhlXXnmlW3nR/v7xj3+ccd2p7TFkyBADMP7zn/8Uq/vUU08ZgLFixQrDMDy3WZHTP0/PPvusARi7d+92q3vllVcWi3vmzJkGYMybN69YvWeeecatnQAjNjbWyMzMdJWlpKQYZrPZmDZtmtuxTjVhwgQDMH799ddi5XfddZdhMpmMrVu3usoSExONa6655qz7K2tMl19+uRETE2McP37cVVZQUGA0b97cqFWrluFwOAzDMIyBAwcaQUFBRkpKSrF6jRs3LvaeJiUlGX5+fm7n5vHjx424uDjj5ptvPmvc5X0cu91uxMXFGZdddlmxenv37jWsVquRmJjoKiv6LDVo0MDIz88vVr9x48ZG69atDZvNVqz82muvNeLj4w273W4YRunPz3vuuceIjIw863shIlLZNGxVRC5o1157bbHlJk2aAHDNNde4le/du7fcjrtr1y4GDRpEXFwcFosFq9XKlVdeCcCWLVvOaZ99+vQhLi6uWM/hokWLOHjwIHfccYer7KuvvqJLly4kJCRQUFDg+unTpw/g7Ek6k6Lhd0W9mEVuvvlm/PzOPlglKiqKBg0a8Oyzz/LCCy+wbt0617DKsrjhhhvKVP/0WAcNGgScfC0VZcmSJYSEhHDjjTcWKy/qYfrhhx+KlXfp0oWwsDDXcmxsLDExMSV+7pYsWULTpk1p376923EMw3D1ZJ+LkmLKzs7m119/5cYbbyw2s63FYuH2229n//79bN26FXC+3926dSM2NrZYvaKeySKLFi2ioKCAwYMHF/t8BgYGcuWVV5Y4e295H2fr1q2uYeynqlOnDp06dfIYQ79+/bBara7lHTt28Ndff7k+i6ce7+qrryY5Odn1PpX2/Gzfvj3Hjh3jn//8J59//jlpaWlnfV9ERCqDhq2KiNdUr16d4OBgdu/eXWHHiIqKKrbs7+9/xvLc3NxyOWZWVhadO3cmMDCQJ598koYNGxIcHMy+ffu4/vrrOXHixDnt18/Pj9tvv53//ve/HDt2jMjISObMmUN8fDy9evVy1Tt06BBffvllsS+3pzrbl9D09HQA4uLi3I4dHR191vhMJhM//PADU6dOZfr06dx///1ERUVx66238tRTTxVLUs6mLDOEeoqrKPai11JR0tPTiYuLc7tNS0xMDH5+fm7H9/T+BQQElPh5SE9PL3bdXZGEhATX+nNVUkxHjx7FMAyPbXL68Yvej9OdXnbo0CEALr30Uo8xnTok25PyPk5R/Kcmo0ViY2M9/n46/f0oOtYDDzzAAw884PF4Reddac/P22+/nYKCAt58801uuOEGHA4Hl156KU8++SQ9evTwuK2ISEVT8igiXmOxWOjWrRvffPMN+/fvp1atWiVuExAQ4PE6pPJOFAIDAwHcjlWa//4vWbKEgwcPsmzZMldvI+Dx3oFlNWzYMJ599lnXtVRffPEF48aNw2KxuOpUr16dFi1a8NRTT3ncR9GXfk+KkomUlBRq1qzpKi8oKCjVe5yYmMisWbMA2LZtG/PmzWPy5Mnk5+czc+bMUr3GstwzsyiuU5Ogousji8rO1JZ/9zMTHR3Nr7/+imEYxWJOTU2loKCA6tWr/639n3qc5ORkt/KDBw8ClNtxPKlWrRpms7lUx4+OjvZ4berpZUX1P/nkExITE8scU3kfp+hzUpQAnm2fRU7/jBYda+LEiVx//fUet2nUqJGrbmnPz2HDhjFs2DCys7P58ccfmTRpEtdeey3btm07p/dOROTvUvIoIl41ceJEFi5cyMiRI/n8889dPYNFbDYb3377LX379gWcs3Vu3LixWJ0lS5aQlZVVrnEV9fRs3LixWK/eF198UeK2RV8sT58I5vXXX3erW1TnxIkTBAUFlbjvJk2acNlllzF79mzsdjt5eXkMGzasWJ1rr72WhQsX0qBBA6pVq1biPk9VNJvo+++/T9u2bV3l8+bNK9VMradq2LAhjz76KJ9++ilr1651lZemt60s3n//fcaOHetaLpo4pei1xMbGEhgY6Pa5+fzzz932dWp7lKRbt27MmzePzz77jOuuu85V/s4777jWl4du3boxbdo01q5dS5s2bYodx2Qy0aVLl3I5jichISFcdtllzJ8/n+eee871GXU4HLz33nvUqlWLhg0bAs4hsF988QWHDh1y9eLZ7Xbmzp1bbJ+9evXCz8+PnTt3lnmIckUcp1GjRsTFxTFv3rxiE2YlJSWxcuXKs/6z5dR9XHzxxWzYsIGnn376rHXP5fwMCQmhT58+5OfnM2DAADZt2qTkUUS8QsmjiHhVhw4deO211xg9ejRt27blrrvuolmzZthsNtatW8cbb7xB8+bNXcnj7bffzmOPPcbjjz/OlVdeyebNm3nllVeIiIgo17ji4uLo3r0706ZNo1q1aiQmJvLDDz8wf/78Erft2LEj1apVY9SoUUyaNAmr1cr777/Phg0b3OpecsklADzzzDP06dMHi8VCixYt3JLoU91xxx3ceeedHDx4kI4dO7p6NIpMnTqVxYsX07FjR8aOHUujRo3Izc1lz549LFy4kJkzZ56xl7dJkybcdtttvPTSS1itVrp3786ff/7pmlXybDZu3Mg999zDTTfdxMUXX4y/vz9Llixh48aNTJgwodhr/uijj5g7dy7169cnMDDQ9T6Ulb+/P88//zxZWVlceumlrtlW+/TpwxVXXAE4k/nbbruNt956iwYNGtCyZUt+++03j7NzFsXxn//8hyFDhmC1WmnUqJHHIbeDBw/m1VdfZciQIezZs4dLLrmEFStW8PTTT3P11VfTvXv3c3pNp7vvvvt45513uOaaa5g6dSqJiYl8/fXXzJgxg7vuusuVvFWUadOm0aNHD7p06cIDDzyAv78/M2bM4M8//+TDDz90/bPk0Ucf5YsvvqBr1648/vjjBAcH8+qrrxa7PQ04/zEzdepUHnnkEXbt2kXv3r2pVq0ahw4d4rfffiMkJIQpU6acMZ7yPo7ZbGbKlCnceeed3Hjjjdxxxx0cO3aMKVOmEB8fX+Iw2iKvv/46ffr0oVevXgwdOpSaNWty5MgRtmzZwtq1a/n444+B0p+fI0eOJCgoiE6dOhEfH09KSgrTpk0jIiLijENxRUQqnJcn7BERMQzDMNavX28MGTLEqFOnjuHv72+EhIQYrVu3Nh5//HEjNTXVVS8vL8946KGHjNq1axtBQUHGlVdeaaxfv/6Ms63+/vvvxY5TNDPq4cOHi5UPGTLECAkJKVaWnJxs3HjjjUZUVJQRERFh3Hbbbcbq1atLNdvqypUrjQ4dOhjBwcFGjRo1jBEjRhhr16512zYvL88YMWKEUaNGDcNkMhWbLfL011QkIyPDCAoKMgDjzTff9Ph+Hj582Bg7dqxRr149w2q1GlFRUUbbtm2NRx55xMjKyvK4zakx3X///UZMTIwRGBhoXH755cYvv/ziFs/pM6AeOnTIGDp0qNG4cWMjJCTECA0NNVq0aGG8+OKLRkFBgWu7PXv2GD179jTCwsIMwDWbZdH+Pv74Y7eYzjTbakhIiLFx40bjqquuMoKCgoyoqCjjrrvucnuNGRkZxogRI4zY2FgjJCTE6Nu3r7Fnzx6Ps/dOnDjRSEhIMMxmc7Fjnj7bqmEYRnp6ujFq1CgjPj7e8PPzMxITE42JEycaubm5xeoBxt133+32us7Uxqfbu3evMWjQICM6OtqwWq1Go0aNjGeffdY1g+ep+yvLbKuljemnn34yunbtaoSEhBhBQUHG5Zdfbnz55Zdu2/7888/G5ZdfbgQEBBhxcXHGgw8+aLzxxhseZ7D97LPPjC5duhjh4eFGQECAkZiYaNx4443G999/X2LsFXGcN954w7jooosMf39/o2HDhsZbb71l9O/f32jdurWrTtFsq88++6zHuDZs2GDcfPPNRkxMjGG1Wo24uDija9euxsyZM4vVK835+fbbbxtdunQxYmNjDX9/fyMhIcG4+eabjY0bN5b4/oiIVBSTYRhGZSesIiIiIr7s2LFjNGzYkAEDBvDGG294OxwREZ+gYasiIiJSpaWkpPDUU0/RpUsXoqOj2bt3Ly+++CLHjx/n3nvv9XZ4IiI+Q8mjiIiIVGkBAQHs2bOH0aNHc+TIEYKDg7n88suZOXMmzZo183Z4IiI+Q8NWRUREREREpESlm0JMREREREREqjQljyIiIiIiIlIiJY8iIiIiIiJSIiWPIiIiIiIiUiIljyIiIiIiIlIiJY8iIiIiIiJSIiWPIiIiIiIiUiIljyIiIiIiIlIiryaPP/74I3379iUhIQGTycRnn31W4jbLly+nbdu2BAYGUr9+fWbOnFnxgYqIiIiIiFRxXk0es7OzadmyJa+88kqp6u/evZurr76azp07s27dOv71r38xduxYPv300wqOVEREREREpGozGYZheDsIAJPJxIIFCxgwYMAZ6zz88MN88cUXbNmyxVU2atQoNmzYwC+//FIJUYqIiIiIiFRNft4OoCx++eUXevbsWaysV69ezJo1C5vNhtVqddsmLy+PvLw817LD4eDIkSNER0djMpkqPGYREREREZHKYBgGx48fJyEhAbO5/AeZnlfJY0pKCrGxscXKYmNjKSgoIC0tjfj4eLdtpk2bxpQpUyorRBEREREREa/at28ftWrVKvf9nlfJI+DWW1g06vZMvYgTJ05k/PjxruWMjAzq1KnDtm3biIqKqrhA5ZzYbDaWLl1Kly5dPPYki/eobXyb2sd3qW18l9rGt6l9fJfaphzZbWDPdy2a9v8Gx1NKvbnp6E4w+4PJAkBG1gnq3f4SYWFh5R4qnGfJY1xcHCkpxd/M1NRU/Pz8iI6O9rhNQEAAAQEBbuVRUVFn3Ea8x2azERwcTHR0tH4Z+Ri1jW9T+/gutY3vUtv4NrWP71LbFDIMyDp0ctlRAJkHwVQ4XPTQn7D5C/ALdC6n78CRm4E9uAYAlqM7MdtyyjUkS97ZO9b+rvMqeezQoQNffvllsbLvvvuOdu3aVe0ProiIiIiInF3GAShK1vKzyd7wGXn2wmTLbqNg7y9kBZ0c6lkjZTlHQi5yLdfJXMOxgATAmZhF5h0ocwhmwJxVcs/id/a2pd5nA9NBfnE0xYYfJwpswGdljqu0vJo8ZmVlsWPHDtfy7t27Wb9+PVFRUdSpU4eJEydy4MAB3nnnHcA5s+orr7zC+PHjGTlyJL/88guzZs3iww8/9NZLEBERERERX3M8hZz1n+IosAFgWvcOIZk7i1UJKfw5VQ3WFlsOzVxTbDky76DHwxUYzt5GP5ODE4Y/h40IAKJNmXxg78ZOI6HwmLnsN6qTZwos3M7EH456xFRzDjO1O0wcd1gZ2KH2GV9aenYeLWpFnlwGLIU/BZnH4LnPzrjt3+XV5HH16tV06dLFtVx0beKQIUOYM2cOycnJJCUludbXq1ePhQsXct999/Hqq6+SkJDAyy+/zA033FDpsYuIiIiIiJfkHIHkDScX139K1oEtGIXX/sWm/0rwGTY9ZjhTxmBySaUaP5naAWAxbFgc+TiqNy6saXAiJ4fA+EbFts/wj3M93+uozmWXNHUt5xU4qFc9mKLeySNmE33DA13rA/zMVAvxP5dXXCrp6SH8X4Xt3cvJ41VXXcXZbjM5Z84ct7Irr7yStWvXulcuZ3a7HZvNVuHHESer1YrFYvF2GCIiIiLiCwryIDezcMEg/6sHKUjb5VodnLaxWPXgwp/TpRnh/ORoAUCmEcTxS++lWWNnMhjgZ+bSulH801L+t7S4UJ1X1zxWBsMwSElJ4dixY94OpcqJjIzUJEYiIiIiVdGhzZB9GAAjKxXT/BHFVvsX/pxujyOWEzgnx4wyZfJO8BDCQwoHo4bGcsvN/+S6YPfJM+XcKHk8TVHiGBMTQ3BwcIXNVCQnGYZBTk4Oqamp2O12b4cjIiIiIhUpOx1+fxPyjgNg27EM6+E/XavP9O07zQjn3/5jXcs7TbUYc31XTIVbWKOCeDCmYm5RIU5KHk9ht9tdiaN6wCpXUFAQAIcOHVLCLiIiInIhSdtO9ooZOPJzAQjb/EGx1afeM+Evh3OiGAMTc+y98Gs3xLWua+MYnmsSW+HhypkpeTxF0TWOwcFnurxWKlLR+65rH0VERETOY3nHyd62HKNwRJnlq3sIKcj0WPW1gr4A5OPHL2G9GNmvKwBmk4lH61YjLFC34/MlSh49UM+Xd+h9FxEREfF9tpQtVEtZwdFf0rBYLAQum4K1IAsD58QzAUau2y0wAFKManxk9AIgw+FP9Y6DubRJAwCsFhP31IrEYtb3QV+m5FFERERERM7o0PL/ceLgFueCPZ+6O97hHwDJZ9/usBFBkhEDQJY5nNhBMxjXqPHZNxKfpuRRipk8eTKvvfYaqampLFiwgAEDBng7JBERERGpJHk5mWx/+x6sOSkARJ7YT2zBAY91f3Y0x1F4X8V0RwjW7o9hMTt7H6tFx9K2USJRhSPLTIBZvYrnPSWPF4ihQ4fy9ttvu5ajoqK49NJLmT59Oi1atCjVPrZs2cKUKVNYsGABl19+OdWqVauocEVERETEB2SlH2TPp49jzjsGQP305TQn32PdBUE3FD4zOGCtx51jJmK16prEqkTJ4wWkd+/ezJ49G3DecuTRRx/l2muvJSkpqVTb79y5E4D+/fv/resPbTabfpGIiIiI+KCMgzvZ9+2LYMsBoHnypzQ/Q93vGk4GnL2Gddr15rqGTQDnd72FCxdWfLDic8zeDkDKT0BAAHFxccTFxdGqVSsefvhh9u3bx+HDzhuuHjhwgIEDB1KtWjWio6Pp378/e/bsAZzDVfv2dc52ZTabXcmjw+Fg6tSp1KpVi4CAAFq1asW3337rOuaePXswmUzMmzePq666isDAQN577z0AZs+eTZMmTQgMDKRx48bMmDGjEt8NEREREQEgPxtyMyE3kx2fP03zpHedSWPyp64qDsPEotrjnD+JD7Dr9t/pOeg+eg66jx6D7qNRYeIoVZt6HktgGAYnbN65cX2Q1XLOPYBZWVm8//77XHTRRURHR5OTk0OXLl3o3LkzP/74I35+fjz55JP07t2bjRs38sADD1C3bl2GDRtGcvLJq5//85//8Pzzz/P666/TunVr3nrrLfr168emTZu4+OKLXfUefvhhnn/+eWbPnk1AQABvvvkmkyZN4pVXXqF169asW7eOkSNHEhISwpAhQzyFLCIiIiJ/U/qeDRz6/XMMwwAgccsbhBpZrvVtCx83+LXgUFThkl8QjXvfSa86dSs3WDnvKHkswQmbnaaPL/LKsTdP7UWwf+mb6KuvviI0NBSA7Oxs4uPj+eqrrzCbzXz00UeYzWb+97//uRLS2bNnExkZybJly+jZsyeRkZEAxMXFufb53HPP8fDDD3PLLbcA8Mwzz7B06VJeeuklXn31VVe9cePGcf3117uWn3jiCZ5//nlXWb169di8eTOvv/66kkcRERGR8mIYkH8yOcx79580tXue4KZIthFAfqcH6Nmlf0VHJxcYJY8XkC5duvDaa68BcOTIEWbMmEGfPn347bffWLNmDTt27CAsLKzYNrm5ua5rHU+XmZnJwYMH6dSpU7HyTp06sWHDhmJl7dq1cz0/fPgw+/btY/jw4YwcOdJVXlBQQERExN96jSIiIiJVWV7GIbIObnMtB84bSIiR7VpOKHzcadRkX0gzALItESQOeIyQUOf3wNDAAC6N8HQnRpGzU/JYgiCrhc1Te3nt2GUREhLCRRdd5Fpu27YtERERvPnmmzgcDtq2bcv777/vtl2NGjXOut/Th84ahuFWFhJy8heQw+EA4M033+Syyy4rVs9iKdtrEhERkQuAwwFHdoLhOMN6OxxLAkvhV1N7AUbKZmqmJmH7/RAOD98fHPtWcyKgums56OCv2MJq4pzeBQL2reBYYE0weZ7iI+rYH9hMgeT7Ob/D2B0Gdofhukl9pC0VC3Ycp0wRYhgG/I1JBf8uCw4CgIAS6iUb0VQbu5wG0Wf/jidSVkoeS2Aymco0dNSXmEwmzGYzJ06coE2bNsydO5eYmBjCw8NLtX14eDgJCQmsWLGCf/zjH67ylStX0r59+zNuFxsbS82aNdm1axe33nrr334dIiIiPst2AnIzTi7nZjgnJjmTnDTn5CVnSGjIzYDMAxBQ+Lc6LxPStkNobPnFXAL7/t+xHFxLrt+ZRwsVOByYy5BEBdvP8p6cgT/QDuAsIzCDTl8+7ab1sScOnfUYVvIItmcULzxtqgszpyS8JgDjrPusLHuNk5+J7X4XU++OOa6PVfXIcMKDSkoxRcru/MyKxKO8vDxSUpw3dD169CivvPIKWVlZ9O3bl/bt2/Pss8/Sv39/1+ypSUlJzJ8/nwcffJBatWp53OeDDz7IpEmTaNCgAa1atWL27NmsX7/eYw/mqSZPnszYsWMJDw+nT58+5OXlsXr1ao4ePcr48ePL/bWLiIi4MQwoyD257CiAzIMU9UxxIpOYjA2YdgWBxeJcd/gvsAaXbv9Zh2Dt2yXXO88U9fEFFmSctd65OmKEeiyPMmVhN0xsMRIBCCaXYFMeGx31PdY3ATVNaaw3N3WVxXCEjaZGrmV/WwbEXYKf2XOynnsim4KIukSEBAKQk2cnJNBC9ZCAwmM4yA6Iw1GYlTkMg+iQAOpEl/IzUkEuqlefxICTt0VL9GIsUrUoebyAfPvtt8THxwMQFhZG48aN+fjjj7nqqqsA+PHHH3n44Ye5/vrrOX78ODVr1qRbt25n7YkcO3YsmZmZ3H///aSmptK0aVO++OKLYjOtejJixAiCg4N59tlneeihhwgJCeGSSy5h3Lhx5fVyRUSkKrGdgD8/hRPHnMu5x2D1bIio6bm+4YCUP866SyvQAWDX3w/PYXKmXIZhYMFBivnMPYVxjkP85dcIG+73RM7OtxNtyiTLFMZ+k3MfIcYJCkx+7CW+0maAt2Jnqb0VbZpe5HG94YCMXBuNYsM8rvck1YjgsqYNzjiTvN3hoFa1YAJNRct2flq5nF69ep3x/tFB/haanlbWvdQRiUhZKXm8QMyZM4c5c+actU5cXBxvv33m/5AOGDDANa1zEbPZzOOPP87jjz/ucZu6deu6bVNk0KBBDBo06OyBi4jIhSljv3O4ZZGju8FkOXm9WOpfYA0Cc2E/1+YvnEM0/QqH2h0pzOjMhUmDw+b5ODlpZQ6twByI3eKP3WEQbD/OEb9YTvg5/5EaaUtld3Bzjlndk7/svAIOZeYSGuD8+pSZW4CBic/tnVhveE6yKlJEkPO9cRgGx3ML6N7kZMxpWXn0aX5y9vSjOTaaJZz5n8W5Njv1qodgLrzeL9jfwqjYsHO+ZVh5sNlsbLY4E0RrGeeBEJGKoeRRRETkQpO80ZmsFdm5pPRDMQEO/QkWf2dy50lmMhzbCxGFlzzkZjiTveDCyUvyMsGef26xn85D0nigTj9ybXb+2p/GPr9E/jS5j4axOwxO5Bewy4gnzTh57V4u/sUmQPEo++yr8ZDHXtfa2QNqGAYhAX70aHru1yjaHQa1o4I5U9pmNpuoXz3Eq4mdiFRNSh5FRES8reDURMtwTphSNKojPwsOrgNz4Z/s1C2w7j0IjnYuZx5wXtdnKeyxs+dVWthkHy6+7KkXMLY54OwdM6duIqeuc1BhgcPAemQbx+I7g8nMnvRs0o5lssR6FTaTlYPHcjEwkWxEuXaVh5WjhMO2U/Z/hg7JUzWOOzm08q+U43RpVAOzyYTDcPBX0mFu7nARQQGeh0WeLs/moGFsKDHhhdfEmUw0T4jA36+EhFRE5AKg5FFERKQ82XKL3bDbtGMp9VOXYv5tn3NSlt/egMAIXJO2HFx7bsfJPVZ82VPSWKeD89Ew4HgyNL+h1LvPz0jBFt0Ywy8QhwEHjp7AUZjQ2g2DI8cyMIXUIM8ajsMw2J2aQUBEHPmWIBwOg8/WHyQzOJGCdCtgkJZVmCD/ddqByj7qlEvrVgPAZjfo3TyOLo1izlg3MTqYwDMMebTZbCxcuJCruzQ44zV1IiJykpJHERGR0kr9C5Y84bzVgicZ+yB9R7EiP+ASOOvtBs7o1Ns1hNeCWOcNv7HlQPProUYT57Jhdw4hLeydPHgslz22CNf1hUnpOfhZTvaM/bwjDavFhKkwgZ27eh9Wi8l1f7tc2xnuxXdW1U9brg3ZDqB4UhtoNWMtnPnyeF6BM7nzcyZ3uQV2/nV1E6JC/AEID7TSKK70E7KIiEjFUvIoIiJyJjt+gB+fBXvh2MgDq895V45m12M+9d5+LW4++Tw0FqLquRYzCvxwmJw9YRknbCzbmuq6s9yetGyWbj1M1K/+gIPUzFwOZuRSI8x5S4rDx89t2KrNbmCzl3z/unaJzl6/nHw7J2x2LqnpvJ6wwOHgWI6NFrUiATAwqBUZxKX1Tg47rV0tmJAAffUQETlf6Te4iIhUXfYCyNx/cnn1W7Dlq5MzgKZt87xdnY7QbpjndSYz1O8Cwc6kyWazsfCbb7j66qsxW63Y7A5SMk7ee/Cn7Wls2HgMs3kvAB/+tq9UoScdySm27ClpbBjrvJ+eYcD21CyualTDte7gsRP0b3XyNhdBVgs9msa6JkMNC7ASHlT8a4ImaBERqdqUPIqIyIXDlusc0lkkbRvkHDm5vP59sJxybdumBaXbb4d7oO4VzucBYc5rCc2er6PLK7BzIt8OJ5y9lfPX7GPFXjN/LNqG2WzmjR/P7aaCtaoF0ap2JOC8ZUSni6pTNzoEAJvdQWxEoGv4p8kEF8eEFhuqKiIi8ncpeRQREd9kFM466ii8KfqRnfDn/JNJ29G9cOIIhBT2ph3aDMcPnvvxrM5EjIITcMsHEBBGdn4Bv6X6cSykLuTAhn0ZfPNnMuGBKzzuIjkjl6y8Ag9rzCw5uKdYicVsIqBwhs6cfDtju17kmrEzJiyQ69rUxFLY02cyqddPRES8T8mjiIh4R342HDnlXoT7VsHRPc5hnwA//6f8jlXrUuejYYDtBLQdUrhokB3dDHutywH4Yv0BFqw7gGmJM1Fbs7doYpwNxXZ3KLPs1xUO75SIxeJMfNslVqNns7gSthAREfEtSh6rCMMwuPPOO/nkk084evQo69ato1WrVt4OS0QuVA47bJx3siewIB+W/xv8C2fONOzFh5eWpOgG97YcaNrfde9AcjMgvCYEOSdxOZRdwIGoDhT4O2cp3ZOWhb9/gGs3S/5KJSzQDwrDev/XJCAT+O6shzeZ4IqLnLOJnsi3c1O7WtSJCvFY12yCS2pF4F84ZNRms/Hdom+5uncj3Q5CRETOa0oeLzArV66kc+fO9OjRg2+//dZV/u233zJnzhyWLVtG/fr1qV69OiaTiQULFjBgwADvBSwiF4b9a+C9693vPXi6/OPuZSE1TvY2Zh2Cy+46OTQ1vCZcdieYLeQXOPh9zxHyCpzDWHcdzuaTLfsJLZy9c/Xeo4U73Pq3X870G1oQEexM9KqHBtCmTuQ5Dxs1HLruUERELgxKHi8wb731FmPGjOF///sfSUlJ1KlTB4CdO3cSHx9Px44dy/2YNptN/00XqWpsubDzB+cQUIBt3545cWx9u/PRMCChFTToenJdRG3wc97TLyUjl193p7tWzVm5hy3JmVgXfQ/A8VxP1xJ6Vr+6s1fQbhjsTc9x9RoaGKRn5dOnebyrbuP4MLo2PnmTeYvJhNms6wtFREROp+TxApKdnc28efP4/fffSUlJYc6cOTz++OMMHTqUt99+G3BOuJCYmOja5rrrrgMgMTGRPXv2APDll18yefJkNm3aREJCAkOGDOGRRx7Bz8/PtY/XXnuNb775hu+//54HHniAKVOmVO6LFZHKlZ0GWxeevN/h8umQleJe75Kbofc053OT+eTtKuwORr6zmu1/ZcES5y0pDhw7AfxV4qE93bC+ZS3nvQWP5xVwdfN4mtd0DlO1Wsx0aBBNsL/+vImIiJQ3/XUtiWGU7bqc8mQNhjIMk5o7dy6NGjWiUaNG3HbbbYwZM4bHHnuM//znPzRo0IA33niD33//3TVhQ0xMDLNnz6Z3796uskWLFnHbbbfx8ssv07lzZ3bu3Mn//d//ATBp0iTXsSZNmsS0adN48cUXXduKyHls/2rYc8oMohvnOh9Nhef3oT/OvG29KwHINqwk1b2dnDQLh4/nce9H61yziWaWodewdZ1Igv2dx7WYzUzo3ZigwuWwQD+qhwacbXMRERGpIEoeS2LLgacTvHPsfx0Ef88TMngya9YsbrvtNgB69+5NVlYWP/zwA927dycsLAyLxUJcXPHZ/SIjI4uVPfXUU0yYMIEhQ5wzEdavX58nnniChx56qFjyOGjQIO64446/8+pExJs2fw7JG08u//Rc6bYLjnbe4xAgMBK6/AsiarJoUwp3vrsG/joOrHRVzyso3msYFeLP7KHOmU8NoFqwtVgvYUSQ1XW7ChEREfEtSh4vEFu3buW3335j/vz5APj5+TFw4EDeeustunfvXur9rFmzht9//52nnnrKVWa328nNzSUnJ4fgYOeMh+3atSvfFyAiFcdug+8ehWNJzuXsNNj/m+e6ja+FQOeQUGw5zusVi0ZAhMZCbDMAlm87zIRPN3Ji4yZgE8dybK5dJEY7f08U2A2ua12T69rUBMAEJEaHYNH1hCIiIuclJY8lsQY7ewC9dexSmjVrFgUFBdSsWdNVZhgGVquVo0ePnmXL4hwOB1OmTOH66693WxcYGOh6HhJS+h5REalgOUcwr55N44PrMS/bAEe2wZYvwVz4K95xliGjl406+bzWpXDJjQAcPHaCn7YfxjjiXPX1H8lsO5RMgF8qAElHPA/nf/SaJozoXP9vvyQRERHxPUoeS2IylWnoqDcUFBTwzjvv8Pzzz9OzZ89i62644Qbef/99j9tZrVbsdnuxsjZt2rB161YuuuiiCotXRP6mrMOwaQHYC29U/9PzWE4cpRHAoVPqnZ40mq1wjXN4aoHDICOmPfaoBgD8a/4frP79KKYFzvsdHj2lJ/Fsxna7mH4tnUP7A61malUr/T+9RERE5Pyi5PEC8NVXX3H06FGGDx9OREREsXU33ngjs2bNcl3DeKq6devyww8/0KlTJwICAqhWrRqPP/441157LbVr1+amm27CbDazceNG/vjjD5588snKekkicjZLn4Q1czyusrcbgcVsBsMBTQdAtPMfQXuPnCApPxRMJvILHAx/ezWwp/DnzFrVjnRNUJNXYGdk5/qEBjr/dIQH+nFRTFi5vCQRERHxfUoeLwCzZs2ie/fubokjOHsen376aW6//Xa3dc8//zzjx4/nzTffpGbNmuzZs4devXrx1VdfMXXqVKZPn47VaqVx48aMGDGiMl6KiHiycwmsnu1MCAEOrHE+JrSB6hfjMAwO5lj4+ER7LqrVk/RsG/9bsZtqu0zATvakZXM8z/PQ1VMvP6weGsC7wy9zlcWEBxIRpHu4ioiIiJOSxwvAl19+ecZ1bdq0wTAMAMaPH19sXd++fenbt6/bNr169aJXr15n3GfR/kSkguxfDdsXn1xe/m+P1VbGDWJ/Qm/m/LyHzcmZzsJdG07u5ugJt20ax53sKezbMoG7u2iIuoiIiJSOkkcRkcqWnQYZ+04uL3kSco6cXD641vN2l9wEdTrwxcaDfLPTxncrY7GzsViVdomRmE1mcgvsdGxQncvqRwFgNplol1iNkAD92hcREZFzo28RIiLlKS8L1r0HuRnO5Zw05/WJkXWcy9mHT64rSfMbIDASA8jwjyWj9V1gtvDpH5tY7jhMw9hQ1wQ1QX5mWvntZ+gN7bFaNdRUREREyp+SRxGRsnA4IHXzyZlM07bBn/PBz9+5vPlzz9ul73AvC69V+MRwzurc0zkplWEYZIbUw1GtHgAT5m9k0aZDsOSnYpvfdnkigzvUBcBms7Fw4f6/88pEREREzkrJo4jI2WQehN0/QtG1vl/fD7bs0m3b7g7nY0E+xLeEuOaFK0yQ0AqsQR43G/n273y/ZQfgnnCGFg47rRZipWOD6NK/DhEREZG/ScmjB5oQxjv0votP+PJe2Lbo5PLx5DPXDXPe35Dsw9D6Noht5ly2BkGTvhDonAE5r8DOiXznPVUNAz5Zs5/Dm/YULhu8+dNuYsMDXLs9lJnndqj4iEC+HHOF67YZIiIiIpVNyeMpiq4TysnJISjIc4+AVJycnBwA7Ha7lyORC5a9AH5+ETIKh3c6CpzXJ1pDTi7b3RM3AOJbQUh15/OwOOj9bwhwv8dhdl4Bn67dT+bKVCCVXWnZzF97oMTQTk8YwwL8+HliV0L9nb+mTSYwmUyeNhURERGpFEoeT2GxWIiMjCQ1NRWA4OBgfVmrBIZhkJOTQ2pqKuHh4eqBlPKTeRC+Gg856c7l/b95rudpGOrIpWAu/BUZUQuCnbOWOhwGOw5nUZBuAJnsSsviyw0H8fezAPDlhoOlDu///lEfcJ4D1UMDuOLi6q51taoFEx6oiW9ERETEdyh5PE1cXByAK4GUyhMZGUl0tK7hkr9h1zKYfyfkFyaD+cfPXLfLo4VPDIi+CBJan1wXngB+zuGhhmFwMCMXI8/ZMz7p80388Ffpfj/8s31twHmbjFsurUPThHDXOotZ/5gSERGR84uSx9OYTCbi4+OJiYnBZrN5O5wqw2q1YrFY9J5L2ez+EZZPB3vh52bfKs/1araDK+5zPjdbILETBIZ7rJprs7MnLRtwDiMd/d5adqV5niCnRpgzwUzPyuOmtrVpHO8cxhpktdDnkngigtRzKCIiIhcOJY9nYLFYsFgs3g5DpGpb+y5s+fLk8vZFYA0+OZw0L9PzdpePhvYjnc8tARBR84yHyLXZOZKdD4AB9HhhOTn5nq+7DfAzAxAbHshH/3c5CZG6NlpERESqDiWPIuI99gIoOHFy+a+FcPivk8srXnDfxpbjXtZxLNRu73weEAaJV4DF/dfbiXw7E+Zv5OAx5zFP2Oz8ecBzAmq1mIgIct67sX6NEN4d3p4AP/1DSURERKouJY8iUnmO7IKsw87nucfgg5tLt133yRBSw/nc4g81255cFxgJIZ6vld2RepwRb6929Sxm5hac8RD+hb2KAJfXj+btYZdqwiwRERGRUyh5FJGKYcuFrV9DbmHP3r7fYMMHpdv28tEnn8e3gpYDS7XZ0q2pjP1gHdn5ziTRcYaJe8MD/Xjmhhau5bZ1qxETFli62ERERESqKCWPIlIx1r0LCx/wvK5avZPP2w6Fy0adXPYLcN7UsBTW7zvGGz/uJL/AmSV+v+WQx3q3XV6HOzo5j2kxm6gTpdvwiIiIiJSV15PHGTNm8Oyzz5KcnEyzZs146aWX6Ny58xnrv//++0yfPp3t27cTERFB7969ee6553SLB5HKZjsBSavAKJxc5s/5sP59MBVeF2icMulM42udj2Y/Z69inctKdYjf9xzhx22HXcszl+/EZjdct7mwn6Fr8c5/1Gd4Z2ey6G8xExnsX4YXJiIiIiKeeDV5nDt3LuPGjWPGjBl06tSJ119/nT59+rB582bq1KnjVn/FihUMHjyYF198kb59+3LgwAFGjRrFiBEjWLBggRdegUgV9sUY+ONj9/JTk0ZMMGAGtBrkcRd/Hshgb/rJCXB+3HaYIP+Tk9LMWbnH43anJ42DLqtDi5oRAIQG+tG9SSyBVk1uIyIiIlKevJo8vvDCCwwfPpwRI0YA8NJLL7Fo0SJee+01pk2b5lZ/1apV1K1bl7FjxwJQr1497rzzTqZPn16pcYtckBwOsOedXN61DA6sdQ0htS5/hr6YMW0oTMocp9yTM+4S56PZD3pNg2p1nct+ARAcBUB+gYO5q/dx+LjzGPuP5DB/3YFShdavZQJRIc7ew9AAP269vA7mwrhCAvwIDfD6IAoRERGRC57XvnHl5+ezZs0aJkyYUKy8Z8+erFy50uM2HTt25JFHHmHhwoX06dOH1NRUPvnkE6655pozHicvL4+8vJNfiDMznZN32Gw23ZDeBxW1idqmghkGpoNr4fhB57LtBH5fjD77NoAZhzPJLNqNNZiCEUshqoFb3RP5dr7amMzx3HQAvv/rML/vOepxv+3rVnPuDzh8PI8+zWNd65rFh9OrWazH7Qqj0OcFnTu+TG3ju9Q2vk3t47vUNr6rotvEZBjGGeYjrFgHDx6kZs2a/Pzzz3Ts2NFV/vTTT/P222+zdetWj9t98sknDBs2jNzcXAoKCujXrx+ffPIJVqvVY/3JkyczZcoUt/IPPviA4ODg8nkxIueZyJxdXLl1cqnq7q7eDQNnL1++Xxh7o690rbNZQrBbAlzLdoczAQT4McXE53s9Dx3tHFuYgJqgTbSD+uFlfgkiIiIicpqcnBwGDRpERkYG4eHl/wXL62O9Tp/x0DCMM86CuHnzZsaOHcvjjz9Or169SE5O5sEHH2TUqFHMmjXL4zYTJ05k/PjxruXMzExq165Nly5dNMmOD7LZbCxevJgePXqc8R8C8veZtn0DW8HwD8GIvcRVbjS6Gker209W9A+lVuH5WFLbzF93gEc/34zN7v7/qH4t4gHws5i47bLaXFJ4faKUH507vktt47vUNr5N7eO71Da+Kz09vUL377XksXr16lgsFlJSUoqVp6amEhvreYjatGnT6NSpEw8++CAALVq0ICQkhM6dO/Pkk08SHx/vtk1AQAABAQFu5VarVR92H6b2KWfJG+GDm+FE4bBRh3NSG1NMU0zDFxWrWtI0M0Vt87+fdvHC4m2uyWvyChxudf3MJl4Y2Ip+LRP+9kuQ0tG547vUNr5LbePb1D6+S23jeyq6PbyWPPr7+9O2bVsWL17Mdddd5ypfvHgx/fv397hNTk4Ofn7FQ7ZYnF91vTT6VsQ35WbC5s8gv3Am0z0/wfFk93o125Z6l6v3HmXBHjMbvtmK2Wzmfyt2e6w387a2dLrI2atvtZg166mIiIjIBcKrw1bHjx/P7bffTrt27ejQoQNvvPEGSUlJjBrlvGH4xIkTOXDgAO+88w4Affv2ZeTIkbz22muuYavjxo2jffv2JCSoZ0OqMLsNDqxxPgIs+zfsXeFer9n10GOq87nZAmEne+uTM06wJ+3kbTPeXrmH7PwC1/JP29MAM8uS9xbb5fQbWtDp4uoAhPr7ERGs/0CKiIiIXIi8mjwOHDiQ9PR0pk6dSnJyMs2bN2fhwoUkJiYCkJycTFJSkqv+0KFDOX78OK+88gr3338/kZGRdO3alWeeecZbL0HEN3w7AX7/n+d1zW9wPvoFQscxEFkbwzD480AmyfsOAXAsx8ZDn24s1aH6t4wnLjIIgLjwQK5vUxM/i/lvvwQRERER8W1enzBn9OjRjB7t+RYBc+bMcSsbM2YMY8aMqeCoRHzc5i9g7dtQNFz74DrnY2gcBEU6nweEQ9+XILaZ2+abDmbS9xUPPZPAxTGhruc2u4N7u18MgL3AzsFt67nrxkt0fYOIiIhIFeT15FFEzsGyaZC62b28/6twcfcSN0/OyAUg2N9Co7gwV/n1bWpx++WJHrex2WwsPLj+nMIVERERkfOfkkeR88GSp2DLlyeX03c4HzvfD9HOnkFCa0D9rh4335KcyYi3V3MsJx+AgsIZUhvFhbFgdKcKC1tERERELhxKHkV80dE9kPrXyeUVL4CjoHgdkxnaDoXIOh53cSLfjs3hvH3Gkr9SOXDshFud5gm636KIiIiIlI6SRxFfk5cFMzqALcd93c3vnrymMbLOGRPHLzcc5L656109jEW6N4nhsWubAmA2mahVLag8IxcRERGRC9g5JY8FBQUsW7aMnTt3MmjQIMLCwjh48CDh4eGEhoaWvAMROenEUXj9Sji2131dQpuTz2tdCk37edzFiu1pvLp0BwWFPY2/7znqVsdqMdGrWRyJ0SHlEraIiIiIVC1lTh737t1L7969SUpKIi8vjx49ehAWFsb06dPJzc1l5syZFRGnyIUr5U/PiWO9K2HIF6XaxZyVu/llV7pb+eS+TRl0mXMCHLMJ3VJDRERERM5ZmZPHe++9l3bt2rFhwwaio6Nd5ddddx0jRowo1+BEqpSoBnDHopPLIdXPWHXTwQy++SMFA+ew1G2HsgAY3CGRjg2c52VYoJXL60djMZsqLmYRERERqTLKnDyuWLGCn3/+GX9//2LliYmJHDhwoNwCE7lgHdkN798E2Yedy0UT4Zj9nDOmlsK/5v/Bhv0ZbuWX14+md/P48opURERERMSlzMmjw+HAbre7le/fv5+wsDAPW4hUcbZc2Po15B13Lif9Cunb3evFNT/jLp5euIVv/kx2LScfc96n8epL4ogNDwSgemgAXRvHlF/cIiIiIiKnKHPy2KNHD1566SXeeOMNAEwmE1lZWUyaNImrr7663AMUOe+tmQ3fTnAvb9AV+kx3PjeZoVo916odqcfZmpLlWp61Yjf202ZO9TObePSapiREasZUEREREal4ZU4eX3zxRbp06ULTpk3Jzc1l0KBBbN++nerVq/Phhx9WRIwi5xd7Aez7Fex5zuX9vzsfIxMhtrB30WKFjmOg+sVum2flFXDNyyvIK3C4rZsz7FIigqwAJEQGuXodRUREREQqWpmTx4SEBNavX89HH33EmjVrcDgcDB8+nFtvvZWgIPWAiLDkCfj5JffyxtdA72luxQV2B//+5i/2HXXe1/GEzUFegQOTCdrXjXLVa12nGlc10rBUEREREfGOc7rPY1BQEMOGDWPYsGHlHY/I+Wffb7DuXSi8xyJ7fnI+hsVDcOGMqf4hcMlNHjffsP8Y/1ux2608LjyQuXd2qIiIRURERETKrMzJ47Rp04iNjeWOO+4oVv7WW29x+PBhHn744XILTuS88P1k2Puze3n3ydDyFo+bnMi3k53vnGX18PF8AGqEBTCu+8lhrJfVi/K4rYiIiIiIN5Q5eXz99df54IMP3MqbNWvGLbfcouRRLnwH1sD2xSeXj+xyPrYcBDUaOp8HRUHTAR43//NABjfOXEmurfg1jRFBVm69LLECAhYRERER+fvKnDympKQQH+9+H7kaNWqQnJzsYQuRC8wnd8DRPe7lLW+B+le6FRfYHfy6+wjHc509jSt3prkljiYT9GgaWxHRioiIiIiUizInj7Vr1+bnn3+mXr16xcp//vlnEhISyi0wEZ9hGOA45d6muRnOx2bXQ1Ck83l4TUjs5HHzD39L4rHPN7mV92gay5uD25VzsCIiIiIiFaPMyeOIESMYN24cNpuNrl27AvDDDz/w0EMPcf/995d7gCJeZRgw+2pIWum+7qoJUKORx82O59oosDvvy7g7zTmLao2wAOpEBQNgtZgY2rFuhYQsIiIiIlIRypw8PvTQQxw5coTRo0eTn++c6CMwMJCHH36YiRMnlnuAIpXOMMAoHFaam+E5cYyoA5F1PG7+zi97mPTFJgyjePk1l8QzuV+zcg5WRERERKRylDl5NJlMPPPMMzz22GNs2bKFoKAgLr74YgICAioiPpHKlZ8NMzvDkZ3u6+7fBn7+zuf+YWBxnj6rdqXz4W9J2B3ObPGrje7X/gZazXS6qHqFhS0iIiIiUtHO6T6PAKGhoVx66aXlGYuI96Xv8Jw41roUQmOcM9uc5vnvtvL7nqNu5S/c3JL+rWoCYALMZvdtRURERETOF2VOHrOzs/n3v//NDz/8QGpqKg5H8Vkjd+3aVW7BiVQ4w4DkDXA8xbl8dLfzMTQWRq86WS8w0pU47jycxcodaa5VB4/lAvDP9nVoFBsKQLUQf/o0j8eihFFERERELhDnNGHO8uXLuf3224mPj8fkoSdG5LxxYA38r5t7ucUfgqM8bjLyndXsOpztVn71JXF0vrhGeUcoIiIiIuITypw8fvPNN3z99dd06uT5tgQiPq0gD7Z8CbnHnMvJG5yP/qGnzJxqgta3ujZJzjjBX8nHXcupmXkAdL64OmGBzlMoPiKI9vU8J5siIiIiIheCMieP1apVIypKX5LlPLVxHnxxj3t5rXYw+HO3YpvdQZ///MSxHJvbuin9mlG/RmhFRCkiIiIi4nPKnDw+8cQTPP7447z99tsEBwdXREwiFScn3fkYURsSWjmfm/2g/f+5qtgdBrk2OwDHcwtciWPzmuGYC4dpN44Lo171kEoLW0RERETE28qcPD7//PPs3LmT2NhY6tati9VqLbZ+7dq15RacyN9my4VdS8GW41w+9Kfzsd4/YMAMt+rZeQX0fPFHDhw74bbu07s6EuBnqchoRURERER8VpmTxwEDBlRAGCIVZMWLsPzf7uVmz0ng7rRsj4nj5fWj8LeYyzs6EREREZHzRpmTx0mTJlVEHCLlI/MgbP4c7IXXKO743vkYWQciE53PrUHQ7g4A8gsc/G/FLtckOGlZzsfY8ACWP9jFtdsAP7NmFhYRERGRKq3MySPAsWPH+OSTT9i5cycPPvggUVFRrF27ltjYWGrWrFneMYqcnS0XMJzPvxoP275xr3PpSOg01q34551pTP92q1t5eKCVQKuGqIqIiIiIFClz8rhx40a6d+9OREQEe/bsYeTIkURFRbFgwQL27t3LO++8UxFxinj21X2w+i33cpMFLrnJ+TwwAlreAkCuzc4XGw6SecLZM7k5OROAhIhAbmhby7kp0L1pbIWHLiIiIiJyPilz8jh+/HiGDh3K9OnTCQsLc5X36dOHQYMGlWtwIiXa8YN7WWAEjPgBql/stuqzdQeYMP8Pt/IGMaHc37ORW7mIiIiIiDiVOXn8/fffef31193Ka9asSUpKSrkEJXJGDsfJ220AGA7n4+AvoGZb53O/ALBY3bcFjhX2ONaJCqZtYjUALGYTt15Wp8JCFhERERG5EJQ5eQwMDCQzM9OtfOvWrdSoUaNcghI5o9l9YN8q93JrMASElno37etF8dxNLcsxMBERERGRC1uZk8f+/fszdepU5s2bB4DJZCIpKYkJEyZwww03lHuAIsV4ShyjGkBMY4/Vd6RmMWPpDk7Y7ADsOpxdkdGJiIiIiFywypw8Pvfcc1x99dXExMRw4sQJrrzySlJSUujQoQNPPfVURcQo4u7BnRBSvcRq763ay/x1B9zKo0P8KyIqEREREZELVpmTx/DwcFasWMGSJUtYu3YtDoeDNm3a0L1794qIT6RMdqRm8ena/RTYnddCrtrlvD6ya+MYujRyDqsOsFro3TzOazGKiIiIiJyPypQ8FhQUEBgYyPr16+natStdu3atqLhEnDKTIX1HqatP//Yvvtt8yK2800XVub1D3XIMTERERESkailT8ujn50diYiJ2u72i4hE5KTcT/tsWbB6uUzSZXU8zTtjAOOU5zp7Gi2OcE+iEB1m5sfAejiIiIiIicm7KPGz10UcfZeLEibz33ntERUVVREwiTjlphYmjCao3PFme2AGCnZ+9Bz/ewMdr9rtt2r9VAv1b1aykQEVERERELnxlTh5ffvllduzYQUJCAomJiYSEhBRbv3bt2nILTgQA/xC45zePq1btTncriw7xp2WtyAoOSkRERESkailz8jhgwIAKCEPEybRvFbWOrMT0ZzacOFLq7T4e1YHWtSMBMJtMmM2mCopQRERERKRqKvOEOQB33HEHtWvXrpCApAo7tAm/d66lLcDeU8rNJz+m89fuZ/m2w67l9Kx8ACxmE34WMyIiIiIiUjHKPGHOc889x5AhQyoqHqnKspyzpBaYAzAnXo7ZVNh72HSAq8qE+X+QX+Bw27RasO7bKCIiIiJSkco8bLVbt24sW7aMoUOHVkA4IpAdEEvwoE8xW61u64oSx/t7NCQ4wPnxrVc9mHrVQ9zqioiIiIhI+Slz8tinTx8mTpzIn3/+Sdu2bd0mzOnXr1+5BScXOIcD9vwI2WnO5UObSr3poMvqEB0aUEGBiYiIiIjI6cqcPN51110AvPDCC27rTCaT7gEppbftG/hokFuxga5dFBERERHxNWVOHh0O9+vNRM7J8RTnY3A0xDQFwIGJbaZWtC6s8p/vt/PHgQzvxCciIiIiIi5lTh5Fyl2dDnDL+wDYbTaSFy6kNXDw2Ale/H6bW/VAq5lgf310RUREREQqU5m/gU+dOvWs6x9//PFzDkbkVDa7s5fb32JmSv9mrvLmCREE+Vu8FZaIiIiISJVU5uRxwYIFxZZtNhu7d+/Gz8+PBg0aKHmUMzu8Db6fDPnHncuZB0u1mdVi4p/t61RcXCIiIiIiUqIyJ4/r1q1zK8vMzGTo0KFcd9115RKUXKA2fAhbv3YvD4tzPf3jQAbr002YNx3i6ImCSgxORERERETOplwuHAsPD2fq1Klce+213H777eWxS7kQOQqTwYt7QYubnc/9AqB+FwC2HTrO9TN/BSzM3rbBtZnFbKrkQEVERERE5HTldk+EY8eOkZFR9lkxZ8yYQb169QgMDKRt27b89NNPZ62fl5fHI488QmJiIgEBATRo0IC33nrrXMMWb6jREC650fnTpC8EhAJwKDMXAH+zQbvESNrXjaJ93Sju79nIm9GKiIiIiAjn0PP48ssvF1s2DIPk5GTeffddevfuXaZ9zZ07l3HjxjFjxgw6derE66+/Tp8+fdi8eTN16ni+xu3mm2/m0KFDzJo1i4suuojU1FQKCjS88UJSIxA+HNEeq9Xq7VBERERERKRQmZPHF198sdiy2WymRo0aDBkyhIkTJ5ZpXy+88ALDhw9nxIgRALz00kssWrSI1157jWnTprnV//bbb1m+fDm7du0iKioKgLp165b1JYgPOXDsBEez8wHYk5bt5WhERERERORMypw87t69u1wOnJ+fz5o1a5gwYUKx8p49e7Jy5UqP23zxxRe0a9eO6dOn8+677xISEkK/fv144oknCAoK8rhNXl4eeXl5ruXMzEzAOUuszWYrl9ciZ5CZjHnTx2B3vs+mpF8xA3aHA4fNxqpdR7h99mqPm6ptfE9Rm6htfJPax3epbXyX2sa3qX18l9rGd1V0m5Q5eczIyMBut7t6/oocOXIEPz8/wsPDS7WftLQ07HY7sbGxxcpjY2NJSUnxuM2uXbtYsWIFgYGBLFiwgLS0NEaPHs2RI0fOeN3jtGnTmDJlilv50qVLCQ4OLlWscm5a7f0fiUd+dCvfvucAWxcuZEWKCbDgZzIIKRyhagIuj3GwePHiSo1VSk9t49vUPr5LbeO71Da+Te3ju9Q2vicnJ6dC91/m5PGWW26hb9++jB49ulj5vHnz+OKLL1i4cGGZ9mcyFZ9J0zAMt7IiDocDk8nE+++/T0REBOAc+nrjjTfy6quveux9nDhxIuPHj3ctZ2ZmUrt2bbp06UJ0dHSZYpWysXwyD46Ao9ZlGDUKJ73xD6XBZXfRICyeY7/t4+PdW+jSOJYZg1oBzv+WLF68mB49euiaRx+jtvFtah/fpbbxXWob36b28V1qG9+Vnp5eofsvc/L466+/8sILL7iVX3XVVTzyyCOl3k/16tWxWCxuvYypqaluvZFF4uPjqVmzpitxBGjSpAmGYbB//34uvvhit20CAgIICAhwK7darfqwV7TCW2yYW94Ml45wFVuKHi3OZ2azya0t1D6+S23j29Q+vktt47vUNr5N7eO71Da+p6Lbo8y36sjLy/M4u6nNZuPEiROl3o+/vz9t27Z16+5evHgxHTt29LhNp06dOHjwIFlZWa6ybdu2YTabqVWrVqmPLd6RmWvj7ZV7eHXpDl5duoPl2w57OyQRERERESmlMiePl156KW+88YZb+cyZM2nbtm2Z9jV+/Hj+97//8dZbb7Flyxbuu+8+kpKSGDVqFOAccjp48GBX/UGDBhEdHc2wYcPYvHkzP/74Iw8++CB33HHHGSfMkUqWdxxyM5w/9uL/ZHj3l71M+mITzy7ayrOLtrJ48yEAAq0WT3sSEREREREfUuZhq0899RTdu3dnw4YNdOvWDYAffviB33//ne+++65M+xo4cCDp6elMnTqV5ORkmjdvzsKFC0lMTAQgOTmZpKQkV/3Q0FAWL17MmDFjaNeuHdHR0dx88808+eSTZX0ZUhEWPQK/vHLG1ZknnLM/NYoNo1XtSAD8/cwM7pBYGdGJiIiIiMjfUObksVOnTvzyyy88++yzzJs3j6CgIFq0aMGsWbM8XnNYktGjR7tNvlNkzpw5bmWNGzfWzE6+avdy97LACKjVvljRlY1q8K+rm1RSUCIiIiIiUh7KnDwCtGrVivfff7+8Y5ELxT/nQoMuzudmPzBrWKqIiIiIyPmuzMnjwoULsVgs9OrVq1j5okWLcDgc9OnTp9yCk/OUxQp+7jPcioiIiIjI+avME+ZMmDABu93uVm4YBhMmTCiXoOTCkJNfwKJNKXy18SBfbTzIzsNZJW8kIiIiIiI+qcw9j9u3b6dp06Zu5Y0bN2bHjh3lEpScR/JzTj43jGKrnvnmL97+Za/bJpbC+z+KiIiIiMj5o8zJY0REBLt27aJu3brFynfs2EFISEh5xSXng3mDYfPnZ1x9KDMPgHrVQ4gNdw5jDQ3w44Y2NSslPBERERERKT9lTh779evHuHHjWLBgAQ0aNACcieP9999Pv379yj1A8WE7lriXhdSA2ObFiu64oh63X67bcYiIiIiInM/KnDw+++yz9O7dm8aNG1OrVi0A9u/fT+fOnXnuuefKPUA5D4z6GaLqOZ9bAsByTpP4ioiIiIiIDzunYasrV65k8eLFbNiwwXWfx3/84x8VEZ+cD6xB4K8hyyIiIiIiF7Jz6iIymUz07NmTnj17lnc8ch7LOGFj1a50jMKJc1Iyc70ckYiIiIiIlJdzSh6XL1/Oc889x5YtWzCZTDRp0oQHH3yQzp07l3d84kuyUiF1y8llR0Gx1ffNXc+Sv1LdNvPT7KoiIiIiIue9MieP7733HsOGDeP6669n7NixGIbBypUr6datG3PmzGHQoEEVEad4W0EevNoeThx1X2dy3i40JcPZ03hxTCgRQVYAokL86dY4ptLCFBERERGRilHm5PGpp55i+vTp3Hfffa6ye++9lxdeeIEnnnhCyeOFKi/rZOJYozFQ2JsY3xKq1S1W9bFrm/KPhjUqNTwREREREalYZU4ed+3aRd++fd3K+/Xrx7/+9a9yCUp83OhVYNJQVBERERGRqsRc1g1q167NDz/84Fb+ww8/ULt27XIJSs4fDofh+jG8HYyIiIiIiFSYMvc83n///YwdO5b169fTsWNHTCYTK1asYM6cOfznP/+piBjFW1L/gqO7nc/zjrutHvfROj5bf7CSgxIREREREW8oc/J41113ERcXx/PPP8+8efMAaNKkCXPnzqV///7lHqB4ScZ+mHE5nN6faDrZWf39FveZVSOCrDSKC6vg4EREREREpLKd0606rrvuOq677rryjkV8yfEUwACLP8S1OFnesLfb9Y6f392JOlHBAAQHWAjws1RioCIiIiIiUhnOKXmUKiQsDka6X+N6qoggK9VC/CspIBERERER8QYlj1JqG/Yd448DGa7lfLvDi9GIiIiIiEhlUvIopXIi387AN34h1+aeMPr7lXnSXhEREREROc+UKnnMzMwkPDy8omMRbzp+CObeBlkpzuWCvGKrT9jsrsSxV7NYTDive2yWEE5CZFClhioiIiIiIpWvVMljtWrVSE5OJiYmhq5duzJ//nwiIyMrODSpVHt+gv2/uZdHX+RWNPO2tphOmzRHREREREQubKVKHkNDQ0lPTycmJoZly5Zhs9kqOi7xloTWcPXzAGTZCkgJvAhSj5NxQm0uIiIiIlKVlSp57N69O126dKFJkyaA81Yd/v6eZ9dcsmRJ+UUnlS8gHGq1JT0rj87Tl5KTv8rbEYmIiIiIiA8oVfL43nvv8fbbb7Nz506WL19Os2bNCA4OrujYxIuSjuSQk2/HZHLeiqNIjyaxGrIqIiIiIlIFlSp5DAoKYtSoUQCsXr2aZ555Rtc8VhE1I4NY8XBXb4chIiIiIiJeVuZbdSxdutT13DAMAPVEiYiIiIiIXODO6QZ977zzDpdccglBQUEEBQXRokUL3n333fKOTURERERERHxEmXseX3jhBR577DHuueceOnXqhGEY/Pzzz4waNYq0tDTuu+++iohTylvecVj3HuRmOJcPbQLAYUBBgYMCh+HF4ERERERExNeUOXn873//y2uvvcbgwYNdZf3796dZs2ZMnjxZyeP5Yv0H8O0Et+Ifdh5n5KPfeCEgERERERHxZWVOHpOTk+nYsaNbeceOHUlOTi6XoKQS5GY6H6s3hLpXsDstm2U7jjHX3qVYtY4Nor0QnIiIiIiI+JoyJ48XXXQR8+bN41//+lex8rlz53LxxReXW2BSSep0gGtfZOP6A0z5az3t60WxYXA7AEwmCA+0lrADERERERGpCsqcPE6ZMoWBAwfy448/0qlTJ0wmEytWrOCHH35g3rx5FRGjVCKrxVTsvo4iIiIiIiJwDrOt3nDDDfz6669Ur16dzz77jPnz51O9enV+++03rrvuuoqIUURERERERLyszD2PAG3btuW9994r71hERERERETER51T8ijnocPbYOV/wJbrXE7d4t14RERERETkvKLksar4dabzvo6n+XpHHp/M/o2UzDwvBCUiIiIiIucLJY9VRUFhctiwN9S/ihU70vhqyzEWpl5GZuphV7XqoQFeClBERERERHyZkseqps7lcPldrMvezkd/bqN9vShubFsLcM602qVRjJcDFBERERERX1Tm5HHOnDncfPPNBAcHV0Q8Uska1Ajh5na1vR2GiIiIiIj4uDLfqmPixInExcUxfPhwVq5cWRExSXk4tg9+eRV+/o/zJ3WTtyMSEREREZHzWJl7Hvfv38/XX3/NnDlz6NKlC/Xq1WPYsGEMGTKEuLi4iohRzsW3E+Cvr9zL/YIqPxYRERERETnvlTl5tFgs9OvXj379+pGamsp7773HnDlzeOyxx+jduzfDhw+nb9++mM1l7tSU8nTiqPMx8QqIrEPGCRtrDxt8seVisratZtfhLO/GJyIiIiIi55W/NWFOTEwMnTp1YuvWrWzbto0//viDoUOHEhkZyezZs7nqqqvKKUw5Z+1HQLPreGbBH3yQnATJuUCua3V0iGZXFRERERGRkp1T8njo0CHeffddZs+eza5duxgwYABfffUV3bt358SJEzz66KMMGTKEvXv3lne8co5sBQ4AejWL5arCGVWDrBZ6NI31ZlgiIiIiInKeKHPy2LdvXxYtWkTDhg0ZOXIkgwcPJioqyrU+KCiI+++/nxdffLFcA5Xy0ap2Nf7Zvo63wxARERERkfNMmZPHmJgYli9fTocOHc5YJz4+nt27d/+twERERERERMR3lHlWmyuvvJI2bdq4lefn5/POO+8AYDKZSExM/PvRiYiIiIiIiE8oc/I4bNgwMjIy3MqPHz/OsGHDyiUoOQfZ6bDlK9jyJWz5kqyjhwB45tu/6P/KCr7fcsjLAYqIiIiIyPmszMNWDcPAZDK5le/fv5+IiIhyCUrOwQc3w4HVrsXQwsdd6XlscJxM9hMiAys5MBERERERuRCUOnls3bo1JpMJk8lEt27d8PM7uandbmf37t307t27QoKUUjie7HyMvQT8Q/grJZMdueE07nAtN19UG4CIICttE6t5MUgRERERETlflTp5HDBgAADr16+nV69ehIaGutb5+/tTt25dbrjhhnIPUMqo/yuQ0IrHX/+F33Yf4dXEmnRrottxiIiIiIjI31Pq5HHSpEkA1K1bl4EDBxIYqOGPIiIiIiIiVUWZJ8wZMmRIuSaOM2bMoF69egQGBtK2bVt++umnUm33888/4+fnR6tWrcotFhEREREREfGsVMljVFQUaWlpAFSrVo2oqKgz/pTF3LlzGTduHI888gjr1q2jc+fO9OnTh6SkpLNul5GRweDBg+nWrVuZjiciIiIiIiLnplTDVl988UXCwsJczz3NtnouXnjhBYYPH86IESMAeOmll1i0aBGvvfYa06ZNO+N2d955J4MGDcJisfDZZ5+VSyznO4dhYAY2JWeSk3+E47kF3g5JREREREQuIKVKHocMGeJ6PnTo0HI5cH5+PmvWrGHChAnFynv27MnKlSvPuN3s2bPZuXMn7733Hk8++WSJx8nLyyMvL8+1nJmZCYDNZsNms51j9L4nIzuf6sBDn2xkk3HcVe5w2M+r11kU6/kUc1WhtvFtah/fpbbxXWob36b28V1qG99V0W1SquSxKOEqjfDw8FLVS0tLw263ExtbfCbQ2NhYUlJSPG6zfft2JkyYwE8//VTsViFnM23aNKZMmeJWvnTpUoKDg0u1j/PBZXYHmCDcahBjNgCI8DfI3LGGhXu9HNw5WLx4sbdDkDNQ2/g2tY/vUtv4LrWNb1P7+C61je/Jycmp0P2XKgOLjIwscaiqYRiYTCbsdnuZAjh9v0X7OZ3dbmfQoEFMmTKFhg0blnr/EydOZPz48a7lzMxMateuTZcuXYiOji5TrD6lIBeO7nEtZq5zADC5fwvqt+jopaD+PpvNxuLFi+nRowdWq9Xb4cgp1Da+Te3ju9Q2vktt49vUPr5LbeO70tPTK3T/pUoely5dWu4Hrl69OhaLxa2XMTU11a03EuD48eOsXr2adevWcc899wDgcDgwDAM/Pz++++47unbt6rZdQEAAAQEBbuVWq/X8/bAbBszsAunbXUVFabDFz3L+vq5TnNftc4FT2/g2tY/vUtv4LrWNb1P7+C61je+p6PYoVfJ45ZVXlvuB/f39adu2LYsXL+a6665zlS9evJj+/fu71Q8PD+ePP/4oVjZjxgyWLFnCJ598Qr169co9Rp9lt51MHIOiwGTmSE4+2x0JhFYrfa+siIiIiIhIaZUqedy4cSPNmzfHbDazcePGs9Zt0aJFqQ8+fvx4br/9dtq1a0eHDh144403SEpKYtSoUYBzyOmBAwd45513MJvNNG/evNj2MTExBAYGupVXKWPXQVAk10z7geSMXL6yuPeyioiIiIiI/F2lSh5btWpFSkoKMTExtGrVCpPJhGEYbvXKes3jwIEDSU9PZ+rUqSQnJ9O8eXMWLlxIYmIiAMnJySXe81FEREREREQqXqmSx927d1OjRg3X8/I0evRoRo8e7XHdnDlzzrrt5MmTmTx5crnGIyIiIiIiIu5KlTwW9QSe/ly8L7fAATY7HjqCRUREREREyk3pbpZ4mq1bt/Lf//6XLVu2YDKZaNy4MWPGjKFRo0blHZ94YGBQdDOT9k99TyYhXo1HREREREQufOaybvDJJ5/QvHlz1qxZQ8uWLWnRogVr166lefPmfPzxxxURo5zGZvfczZgQEUjd6kokRURERESk/JW55/Ghhx5i4sSJTJ06tVj5pEmTePjhh7npppvKLTgp2aJx/yCsWnUAgqwWLGZTCVuIiIiIiIiUXZmTx5SUFAYPHuxWftttt/Hss8+WS1DiwaqZcOhPACynzGgbHOBHaMA5jT4WEREREREptTJnHVdddRU//fQTF110UbHyFStW0Llz53ILTE5xLAm+fdi1aCl8zDWsYPH3TkwiIiIiIlKllCp5/OKLL1zP+/Xrx8MPP8yaNWu4/PLLAVi1ahUff/wxU6ZMqZgoqzpbrvPRLwiufJACh8EL321jnXERM61B3o1NRERERESqhFIljwMGDHArmzFjBjNmzChWdvfddzNq1KhyCUw8sAZC5/txFDiY8c033o5GRERERESqkFIljw6Ho6LjEBERERERER9W5lt1iIiIiIiISNVzTtN0Zmdns3z5cpKSksjPzy+2buzYseUSmJxkYGACsvIKGDP7Nxyeb/MoIiIiIiJSYcqcPK5bt46rr76anJwcsrOziYqKIi0tjeDgYGJiYpQ8lgfDgG2LIHM/ABmp+4kEbHaDpVsPu6qFBvgRaFXnsYiIiIiIVLwyJ4/33Xcfffv25bXXXiMyMpJVq1ZhtVq57bbbuPfeeysixqrnwFr4cKBrMbLw0YaVZ29s4Sq/pFYEAX4WREREREREKlqZk8f169fz+uuvY7FYsFgs5OXlUb9+faZPn86QIUO4/vrrKyLOqiUnzfkYGAH1riQrr4Aft6exzK8T09vV9m5sIiIiIiJSJZU5ebRarZhMJgBiY2NJSkqiSZMmREREkJSUVO4BVmlR9WHgu6SkZjF683IirVamezsmERERERGpksqcPLZu3ZrVq1fTsGFDunTpwuOPP05aWhrvvvsul1xySUXEKCIiIiIiIl5W5tlWnn76aeLj4wF44okniI6O5q677iI1NZU33nij3AMUERERERER7ytzz2O7du1cz2vUqMHChQvLNSCBnPwCgoEtKce5c/pSbHaHt0MSEREREZEq7pzu8wiQmprK1q1bMZlMNGrUiBo1apRnXFXajtQsWgD5BQ6SjuS4yutGh3gvKBERERERqdLKnDxmZmZy991389FHH2G32wGwWCwMHDiQV199lYiIiHIPsqoxMAAI8DMzf0RHV3nT+HBvhSQiIiIiIlVcmZPHESNGsH79er766is6dOiAyWRi5cqV3HvvvYwcOZJ58+ZVRJwXtux0+GEK5KQDUPfwfgAsZhNt6lTzZmQiIiIiIiLAOSSPX3/9NYsWLeKKK65wlfXq1Ys333yT3r17l2twVcaWz2Ht267For7bDJN6cUVERERExDeUOXmMjo72ODQ1IiKCatXUS3ZO7DbnY3wraDOYvw4dZ84v+0ip9g/meDMuERERERGRQmW+Vcejjz7K+PHjSU5OdpWlpKTw4IMP8thjj5VrcFVOVH24dDgHL/onH9m7csQS7e2IREREREREgFL2PLZu3RqTyeRa3r59O4mJidSpUweApKQkAgICOHz4MHfeeWfFRCoiIiIiIiJeU6rkccCAARUchgCkZeWzfWc6W5KPezsUERERERGRYkqVPE6aNKmi46jStqZk0gj4ZVcaY7aucpWf2tsrIiIiIiLiTWWeMKfImjVr2LJlCyaTiaZNm9K6devyjKtKOZrjnDDHz2zm4phQwHmbjsGXJ3ozLBEREREREZcyJ4+pqanccsstLFu2jMjISAzDICMjgy5duvDRRx9Ro0aNioizSogJD2Dx+Cu9HYaIiIiIiIibMs+2OmbMGDIzM9m0aRNHjhzh6NGj/Pnnn2RmZjJ27NiKiPHCc+IY/Po6/PQ8/PQ8NdN/8XZEIiIiIiIiZ1Xmnsdvv/2W77//niZNmrjKmjZtyquvvkrPnj3LNbgL1qrXYPm/XYu1Cx9tpgDvxCMiIiIiIlKCMiePDocDq9XqVm61WnE4HOUS1AUvN8P5GNscElqz7VAWq5Ky2BP1Ty73bmQiIiIiIiIelXnYateuXbn33ns5ePCgq+zAgQPcd999dOvWrVyDu+Bd3BP6v8LKZpN4vGAYqf51vB2RiIiIiIiIR2VOHl955RWOHz9O3bp1adCgARdddBH16tXj+PHj/Pe//62IGEVERERERMTLyjxstXbt2qxdu5bFixfz119/YRgGTZs2pXv37hUR3wUpt8BOILBqdzo/LfqLjfszvB2SiIiIiIjIWZUpeSwoKCAwMJD169fTo0cPevToUVFxXdA2H8ykDbBm71Fe3bnTVR7if8633RQREREREalQZcpW/Pz8SExMxG63V1Q8VUK+3TmxUI2wQIY2qQtAgJ+ZWy9L9GJUIiIiIiIiZ1bmrq5HH32UiRMn8t577xEVFVURMVUZtasFcXO/Zt4OQ0REREREpERlTh5ffvllduzYQUJCAomJiYSEhBRbv3bt2nIL7oJhGHBsL9htAAQVZHo5IBERERERkbIpc/LYv39/TCZTRcRy4Vr6FPz4rGuxpRdDERERERERORdlTh4nT55cAWFc4FL+dD5ag8HizwmbnfSCAHZV60QH70YmIiIiIiJSKqW+z2NOTg533303NWvWJCYmhkGDBpGWllaRsV14+jwDE/YyvdUirsh7mQNh6oMUEREREZHzQ6mTx0mTJjFnzhyuueYabrnlFhYvXsxdd91VkbGJiIiIiIiIjyj1sNX58+cza9YsbrnlFgBuu+02OnXqhN1ux2KxVFiAF4I8u4MA4KftaWzP2c2mg5owR0REREREzi+lTh737dtH586dXcvt27fHz8+PgwcPUrt27QoJ7kKxI/U4zYAvNx5k3rrNrvIAPyXdIiIiIiJyfih18mi32/H39y++sZ8fBQUF5R7UhcZmNwDnfR371kwAIDTAj5va1fJmWCIiIiIiIqVW6uTRMAyGDh1KQECAqyw3N5dRo0YVu9fj/PnzyzfCC8hl9aIZc0Nrb4chIiIiIiJSZqVOHocMGeJWdtttt5VrMCIiIiIiIuKbSp08zp49uyLjuPAYhuup6ZTnIiIiIiIi56NSJ49SBt9PhhUvAc6kUXdzFBERERGR812p7/MoZbD1G4oSxyI5RgBHI5p4Jx4REREREZG/ScljRRr4Pjy4i3F1PqV13uscU/IoIiIiIiLnKSWPFSkwHEKiybJEkId/yfVFRERERER8lNeTxxkzZlCvXj0CAwNp27YtP/300xnrzp8/nx49elCjRg3Cw8Pp0KEDixYtqsRoS+doTj4AYz5YR6d/L+Gn7WlejkhEREREROTv8WryOHfuXMaNG8cjjzzCunXr6Ny5M3369CEpKclj/R9//JEePXqwcOFC1qxZQ5cuXejbty/r1q2r5MjPLuOEDYC07DwOHDtBXoEDgLrRIWfbTERERERExGd5dbbVF154geHDhzNixAgAXnrpJRYtWsRrr73GtGnT3Oq/9NJLxZaffvppPv/8c7788ktat25dGSGXybCOdXm4ZScAokP8qR0V7OWIREREREREzo3Xksf8/HzWrFnDhAkTipX37NmTlStXlmofDoeD48ePExUVdcY6eXl55OXluZYzMzMBsNls2Gy2c4i89OLCA2gSd7K3saKPdyEoeo/0XvketY1vU/v4LrWN71Lb+Da1j+9S2/iuim4TryWPaWlp2O12YmNji5XHxsaSkpJSqn08//zzZGdnc/PNN5+xzrRp05gyZYpb+dKlSwkOrpiewEsczmGqW7ZsYffRCjnEBW/x4sXeDkHOQG3j29Q+vktt47vUNr5N7eO71Da+Jycnp0L379VhqwAmk6nYsmEYbmWefPjhh0yePJnPP/+cmJiYM9abOHEi48ePdy1nZmZSu3ZtunTpQnR09LkHfirDAdknJ8VJWW+AAU2aNKFJh6vL5xhVhM1mY/HixfTo0QOr1ertcOQUahvfpvbxXWob36W28W1qH9+ltvFd6enpFbp/ryWP1atXx2KxuPUypqamuvVGnm7u3LkMHz6cjz/+mO7du5+1bkBAAAEBAW7lVqu1/D7sb/eD3ctdi7ULH80Ws06oc1Su7SPlSm3j29Q+vktt47vUNr5N7eO71Da+p6Lbw2uzrfr7+9O2bVu37u7FixfTsWPHM2734YcfMnToUD744AOuueaaig6zdPb9esqCCQcm9jpiyK7W1GshiYiIiIiIlCevDlsdP348t99+O+3ataNDhw688cYbJCUlMWrUKMA55PTAgQO88847gDNxHDx4MP/5z3+4/PLLXb2WQUFBREREeO11uIz7EyJr0+uF5WxPzeKDAB+ISUREREREpBx4NXkcOHAg6enpTJ06leTkZJo3b87ChQtJTEwEIDk5udg9H19//XUKCgq4++67ufvuu13lQ4YMYc6cOZUdvoiIiIiISJXh9QlzRo8ezejRoz2uOz0hXLZsWcUHdA5sdgdWoMvzy0imOrk2h7dDEhERERERKVdeu+bxQmJ3GADk2RyuxDHE30KDGqHeDEtERERERKTceL3n8UIy8/Y2RCU0AKBasD8hAXp7RURERETkwqDsphzFhAUSVy3Y22GIiIiIiIiUOw1bFRERERERkRIpeRQREREREZESKXkUERERERGREil5FBERERERkRIpeRQREREREZESabbVsnLYYXYf2PebqyjQZHgxIBERERERkYqn5LGsslJh369uxXsdMfiFxHghIBERERERkYqn5PEcOTAzs+3XAMz5ZQ9HHCEst/h7OSoREREREZGKoeSxjDJzbYQDDgOm/3y0sDQCkwmCrBZvhiYiIiIiIlJhlDyWUV6Bw/V8aMe6rueX1IwgKkQ9jyIiIiIicmFS8vg3TO7XzNshiIiIiIiIVArdqkNERERERERKpORRRERERERESqTkUUREREREREqk5FFERERERERKpORRRERERERESqTkUUREREREREqkW3WUhmGAUXh/R8Pu3VhERERERES8QMljSU4cg9c7w7EkAGp4NxoRERERERGv0LDVEhipm12J46l+NZp6IRoRERERERHvUM9jCXanZVMf2OOIpX/+E65yc1Ak67wXloiIiIiISKVS8liCvILCax3NZob3aOMq73RRtJciEhERERERqXxKHkvJYjIxttvF3g5DRERERETEK3TNo4iIiIiIiJRIyaOIiIiIiIiUSMmjiIiIiIiIlEjJo4iIiIiIiJRIyaOIiIiIiIiUSMmjiIiIiIiIlEi36vAkPxvysgDwyzvq5WBERERERES8T8nj6VL+gP/1gIITAOjOjiIiIiIiIhq26ubIzjWuxNGOGTsmbIaFFX6XezkyERERERER71HP42l2Hs4iClhmb8lQ28Ou8j4Xx/FP74UlIiIiIiLiVUoezyAiyMp39/wDALMJ6lUP9XJEIiIiIiIi3qPk8QwsZhMNY8O8HYaIiIiIiIhP0DWPIiIiIiIiUiIljyIiIiIiIlIiJY8iIiIiIiJSIiWPIiIiIiIiUiJNmJO2A759GHIzAWhyJNnLAYmIiIiIiPieKp88Zq+dS8iO713LRTfkOGKp7p2AREREREREfFCVTx63HDhKO2CpvSUf2rsCYMOPahd34yqvRiYiIiIiIuI7qnzyaHMYAOSE1KZZu1sB8LOY6N8qwZthiYiIiIiI+JQqnzwWqR7qzzXdL/Z2GCIiIiIiIj5Js62KiIiIiIhIiZQ8ioiIiIiISImUPIqIiIiIiEiJlDyKiIiIiIhIiZQ8ioiIiIiISImUPIqIiIiIiEiJvJ48zpgxg3r16hEYGEjbtm356aefzlp/+fLltG3blsDAQOrXr8/MmTMrKVIREREREZGqy6vJ49y5cxk3bhyPPPII69ato3PnzvTp04ekpCSP9Xfv3s3VV19N586dWbduHf/6178YO3Ysn376aSVHLiIiIiIiUrV4NXl84YUXGD58OCNGjKBJkya89NJL1K5dm9dee81j/ZkzZ1KnTh1eeuklmjRpwogRI7jjjjt47rnnKjlyERERERGRqsXPWwfOz89nzZo1TJgwoVh5z549WblypcdtfvnlF3r27FmsrFevXsyaNQubzYbVanXbJi8vj7y8PNdyRkYGAEeOHAEgKzuXzDyDrJx80tPT/9Zrkr/PZrORk5NDenq6x/YU71Hb+Da1j+9S2/gutY1vU/v4LrWN7yrKcQzDqJD9ey15TEtLw263ExsbW6w8NjaWlJQUj9ukpKR4rF9QUEBaWhrx8fFu20ybNo0pU6a4lTds2PC0kg/g4Q/K9iJERERERER8THp6OhEREeW+X68lj0VMJlOxZcMw3MpKqu+pvMjEiRMZP368a/nYsWMkJiaSlJRUIW+o/D2ZmZnUrl2bffv2ER4e7u1w5BRqG9+m9vFdahvfpbbxbWof36W28V0ZGRnUqVOHqKioCtm/15LH6tWrY7FY3HoZU1NT3XoXi8TFxXms7+fnR3R0tMdtAgICCAgIcCuPiIjQh92HhYeHq318lNrGt6l9fJfaxnepbXyb2sd3qW18l9lcMVPbeG3CHH9/f9q2bcvixYuLlS9evJiOHTt63KZDhw5u9b/77jvatWun8dYiIiIiIiIVyKuzrY4fP57//e9/vPXWW2zZsoX77ruPpKQkRo0aBTiHnA4ePNhVf9SoUezdu5fx48ezZcsW3nrrLWbNmsUDDzzgrZcgIiIiIiJSJXj1mseBAweSnp7O1KlTSU5Opnnz5ixcuJDExEQAkpOTi93zsV69eixcuJD77ruPV199lYSEBF5++WVuuOGGUh8zICCASZMmeRzKKt6n9vFdahvfpvbxXWob36W28W1qH9+ltvFdFd02JqOi5nEVERERERGRC4ZXh62KiIiIiIjI+UHJo4iIiIiIiJRIyaOIiIiIiIiUSMmjiIiIiIiIlKjKJY8zZsygXr16BAYG0rZtW3766Sdvh1TlTJs2jUsvvZSwsDBiYmIYMGAAW7duLVZn6NChmEymYj+XX365lyKuOiZPnuz2vsfFxbnWG4bB5MmTSUhIICgoiKuuuopNmzZ5MeKqpW7dum7tYzKZuPvuuwGdN5Xpxx9/pG/fviQkJGAymfjss8+KrS/NuZKXl8eYMWOoXr06ISEh9OvXj/3791fiq7gwna1tbDYbDz/8MJdccgkhISEkJCQwePBgDh48WGwfV111ldu5dMstt1TyK7kwlXTulOb3mM6dilFS23j6+2MymXj22WdddXTuVIzSfHeurL87VSp5nDt3LuPGjeORRx5h3bp1dO7cmT59+hS7HYhUvOXLl3P33XezatUqFi9eTEFBAT179iQ7O7tYvd69e5OcnOz6WbhwoZcirlqaNWtW7H3/448/XOumT5/OCy+8wCuvvMLvv/9OXFwcPXr04Pjx416MuOr4/fffi7XN4sWLAbjppptcdXTeVI7s7GxatmzJK6+84nF9ac6VcePGsWDBAj766CNWrFhBVlYW1157LXa7vbJexgXpbG2Tk5PD2rVreeyxx1i7di3z589n27Zt9OvXz63uyJEji51Lr7/+emWEf8Er6dyBkn+P6dypGCW1zaltkpyczFtvvYXJZHK7ZZ7OnfJXmu/OlfZ3x6hC2rdvb4waNapYWePGjY0JEyZ4KSIxDMNITU01AGP58uWusiFDhhj9+/f3XlBV1KRJk4yWLVt6XOdwOIy4uDjj3//+t6ssNzfXiIiIMGbOnFlJEcqp7r33XqNBgwaGw+EwDEPnjbcAxoIFC1zLpTlXjh07ZlitVuOjjz5y1Tlw4IBhNpuNb7/9ttJiv9Cd3jae/PbbbwZg7N2711V25ZVXGvfee2/FBice26ek32M6dypHac6d/v37G127di1WpnOncpz+3bky/+5UmZ7H/Px81qxZQ8+ePYuV9+zZk5UrV3opKgHIyMgAICoqqlj5smXLiImJoWHDhowcOZLU1FRvhFflbN++nYSEBOrVq8ctt9zCrl27ANi9ezcpKSnFzqGAgACuvPJKnUNekJ+fz3vvvccdd9yByWRyleu88b7SnCtr1qzBZrMVq5OQkEDz5s11PlWyjIwMTCYTkZGRxcrff/99qlevTrNmzXjggQc0wqISne33mM4d33Do0CG+/vprhg8f7rZO507FO/27c2X+3fErjxdwPkhLS8NutxMbG1usPDY2lpSUFC9FJYZhMH78eK644gqaN2/uKu/Tpw833XQTiYmJ7N69m8cee4yuXbuyZs0aAgICvBjxhe2yyy7jnXfeoWHDhhw6dIgnn3ySjh07smnTJtd54ukc2rt3rzfCrdI+++wzjh07xtChQ11lOm98Q2nOlZSUFPz9/alWrZpbHf1Nqjy5ublMmDCBQYMGER4e7iq/9dZbqVevHnFxcfz5559MnDiRDRs2uIaKS8Up6feYzh3f8PbbbxMWFsb1119frFznTsXz9N25Mv/uVJnkscip/6EHZwOcXiaV55577mHjxo2sWLGiWPnAgQNdz5s3b067du1ITEzk66+/dvtFJeWnT58+rueXXHIJHTp0oEGDBrz99tuuCQt0DvmGWbNm0adPHxISElxlOm98y7mcKzqfKo/NZuOWW27B4XAwY8aMYutGjhzpet68eXMuvvhi2rVrx9q1a2nTpk1lh1qlnOvvMZ07leutt97i1ltvJTAwsFi5zp2Kd6bvzlA5f3eqzLDV6tWrY7FY3DLr1NRUtyxdKseYMWP44osvWLp0KbVq1Tpr3fj4eBITE9m+fXslRScAISEhXHLJJWzfvt0166rOIe/bu3cv33//PSNGjDhrPZ033lGacyUuLo78/HyOHj16xjpScWw2GzfffDO7d+9m8eLFxXodPWnTpg1Wq1Xnkhec/ntM5473/fTTT2zdurXEv0Ggc6e8nem7c2X+3akyyaO/vz9t27Z16zZfvHgxHTt29FJUVZNhGNxzzz3Mnz+fJUuWUK9evRK3SU9PZ9++fcTHx1dChFIkLy+PLVu2EB8f7xqGcuo5lJ+fz/Lly3UOVbLZs2cTExPDNddcc9Z6Om+8ozTnStu2bbFarcXqJCcn8+eff+p8qmBFieP27dv5/vvviY6OLnGbTZs2YbPZdC55wem/x3TueN+sWbNo27YtLVu2LLGuzp3yUdJ350r9u/N3Zvo533z00UeG1Wo1Zs2aZWzevNkYN26cERISYuzZs8fboVUpd911lxEREWEsW7bMSE5Odv3k5OQYhmEYx48fN+6//35j5cqVxu7du42lS5caHTp0MGrWrGlkZmZ6OfoL2/33328sW7bM2LVrl7Fq1Srj2muvNcLCwlznyL///W8jIiLCmD9/vvHHH38Y//znP434+Hi1SyWy2+1GnTp1jIcffrhYuc6bynX8+HFj3bp1xrp16wzAeOGFF4x169a5ZuwszbkyatQoo1atWsb3339vrF271ujatavRsmVLo6CgwFsv64Jwtrax2WxGv379jFq1ahnr168v9jcoLy/PMAzD2LFjhzFlyhTj999/N3bv3m18/fXXRuPGjY3WrVurbcrB2dqntL/HdO5UjJJ+rxmGYWRkZBjBwcHGa6+95ra9zp2KU9J3Z8OovL87VSp5NAzDePXVV43ExETD39/faNOmTbHbQ0jlADz+zJ492zAMw8jJyTF69uxp1KhRw7BarUadOnWMIUOGGElJSd4NvAoYOHCgER8fb1itViMhIcG4/vrrjU2bNrnWOxwOY9KkSUZcXJwREBBg/OMf/zD++OMPL0Zc9SxatMgAjK1btxYr13lTuZYuXerx99iQIUMMwyjduXLixAnjnnvuMaKiooygoCDj2muvVXuVg7O1ze7du8/4N2jp0qWGYRhGUlKS8Y9//MOIiooy/P39jQYNGhhjx4410tPTvfvCLhBna5/S/h7TuVMxSvq9ZhiG8frrrxtBQUHGsWPH3LbXuVNxSvrubBiV93fHVBiQiIiIiIiIyBlVmWseRURERERE5NwpeRQREREREZESKXkUERERERGREil5FBERERERkRIpeRQREREREZESKXkUERERERGREil5FBERERERkRIpeRQREREREZESKXkUERGfUbduXV566SVvh1HuJk+eTKtWrcp9v1dddRXjxo0r9/2KiIh4ouRRREQqxbRp07j00ksJCwsjJiaGAQMGsHXrVm+HBcCyZcswmUw0b94cu91ebF1kZCRz5szxTmAiIiI+RMmjiIhUiuXLl3P33XezatUqFi9eTEFBAT179iQ7O9vbobns3LmTd955x9th+BSbzebtEERExEcoeRQRkUrx7bffMnToUJo1a0bLli2ZPXs2SUlJrFmzpli9nJwc7rjjDsLCwqhTpw5vvPFGsfV//PEHXbt2JSgoiOjoaP7v//6PrKws1/qhQ4cyYMAApkyZQkxMDOHh4dx5553k5+eXGOOYMWOYNGkSubm5Z6yTlJRE//79CQ0NJTw8nJtvvplDhw4Vq/Pvf/+b2NhYwsLCGD58uMf9zZ49myZNmhAYGEjjxo2ZMWPGWWPLzs5m8ODBhIaGEh8fz/PPP+9WJz8/n4ceeoiaNWsSEhLCZZddxrJly4rVefPNN6lduzbBwcFcd911vPDCC0RGRrrWFw2xfeutt6hfvz4BAQEYhkFGRgb/93//53pPu3btyoYNG4rt+8svv6Rt27YEBgZSv359pkyZQkFBwVlfl4iInD+UPIqIiFdkZGQAEBUVVaz8+eefp127dqxbt47Ro0dz11138ddffwHOxLJ3795Uq1aN33//nY8//pjvv/+ee+65p9g+fvjhB7Zs2cLSpUv58MMPWbBgAVOmTCkxpnHjxlFQUMArr7zicb1hGAwYMIAjR46wfPlyFi9ezM6dOxk4cKCrzrx585g0aRJPPfUUq1evJj4+3i0xfPPNN3nkkUd46qmn2LJlC08//TSPPfYYb7/99hlje/DBB1m6dCkLFizgu+++Y9myZW6J97Bhw/j555/56KOP2LhxIzfddBO9e/dm+/btAPz888+MGjWKe++9l/Xr19OjRw+eeuopt2Pt2LGDefPm8emnn7J+/XoArrnmGlJSUli4cCFr1qyhTZs2dOvWjSNHjgCwaNEibrvtNsaOHcvmzZt5/fXXmTNnjsf9i4jIecoQERGpZA6Hw+jbt69xxRVXFCtPTEw0brvttmL1YmJijNdee80wDMN44403jGrVqhlZWVmuOl9//bVhNpuNlJQUwzAMY8iQIUZUVJSRnZ3tqvPaa68ZoaGhht1u9xjP0qVLDcA4evSoMXPmTCMqKso4duyYYRiGERERYcyePdswDMP47rvvDIvFYiQlJbm23bRpkwEYv/32m2EYhtGhQwdj1KhRxfZ/2WWXGS1btnQt165d2/jggw+K1XniiSeMDh06eIzv+PHjhr+/v/HRRx+5ytLT042goCDj3nvvNQzDMHbs2GGYTCbjwIEDxbbt1q2bMXHiRMMwDGPgwIHGNddcU2z9rbfeakRERLiWJ02aZFitViM1NdVV9sMPPxjh4eFGbm5usW0bNGhgvP7664ZhGEbnzp2Np59+utj6d99914iPj/f4mkRE5PyjnkcREal099xzDxs3buTDDz90W9eiRQvXc5PJRFxcHKmpqQBs2bKFli1bEhIS4qrTqVMnHA5Hscl3WrZsSXBwsGu5Q4cOZGVlsW/fvhJjGz58ONWrV+eZZ55xW7dlyxZq165N7dq1XWVNmzYlMjKSLVu2uOp06NCh2HanLh8+fJh9+/YxfPhwQkNDXT9PPvkkO3fu9BjTzp07yc/PL7afqKgoGjVq5Fpeu3YthmHQsGHDYvtdvny5a79bt26lffv2xfZ9+jJAYmIiNWrUcC2vWbOGrKwsoqOji+179+7drn2vWbOGqVOnFls/cuRIkpOTycnJ8fi6RETk/OLn7QBERKRqGTNmDF988QU//vgjtWrVcltvtVqLLZtMJhwOB+AcNmoymTzu90zlZa3j5+fHk08+ydChQ92Gw57p+GeL63RFr+XNN9/ksssuK7bOYrF43MYwjFLt12KxsGbNGrf9hIaGnjFOT/s+NTkv2nd8fLzb9ZOA63pJh8PBlClTuP76693qBAYGlhi/iIj4PiWPIiJSKQzDYMyYMSxYsIBly5ZRr169Mu+jadOmvP3222RnZ7sSnJ9//hmz2UzDhg1d9TZs2MCJEycICgoCYNWqVYSGhnpMVj256aabePbZZ92uk2zatClJSUns27fP1fu4efNmMjIyaNKkCQBNmjRh1apVDB482LXdqlWrXM9jY2OpWbMmu3bt4tZbby1VPBdddBFWq5VVq1ZRp04dAI4ePcq2bdu48sorAWjdujV2u53U1FQ6d+7scT+NGzfmt99+K1a2evXqEo/fpk0bUlJS8PPzo27dumess3XrVi666KJSvSYRETn/KHkUEZFKcffdd/PBBx/w+eefExYWRkpKCgARERGuJK8kt956K5MmTWLIkCFMnjyZw4cPM2bMGG6//XZiY2Nd9fLz8/n/9u4dJP01juP4x8aKIBqiIQIhnSxChSL5GWpIkeLQDQSLtKHoQkU0FObQ0FWipYYgGxraHEKLwKWpaCqCxlyaogtNQXDOFkiHY2c5Ff/3C37Lj4eH7/NsH55bNBrVwsKC8vm8FhcXNTY2ppKSr5/WWF5elt/vL/jn8/nU0NCgcDiszc1Nvb+/a3R0VG63Ww6HQ5I0OTmpgYEBORwOuVwuHRwc6ObmRmaz+aOfRCKhiYkJVVRUqKOjQ29vb7q8vNTT05Omp6c/1VJeXq5oNKrZ2VlVVVWpurpa8/PzBeOxWCwKh8OKRCLa2NhQU1OTHh4elMvlZLPZ1NnZqfHxcRmGoWQyqUAgoFwup2w2W3TV1OfzqaWlRaFQSCsrK7Jarbq/v1cmk1EoFJLD4VA8HldXV5dqa2vV09OjkpISXV1d6fr6WktLS1+edwDAz8WZRwDA/2J7e1svLy9qa2tTTU3Nx3d4ePjlPkpLS3VycqLHx0c5nU51d3fL6/V+uh3V6/Wqvr5ehmGot7dXgUBAiUTiP9Xr8Xjk8XgKnpowmUxKp9OqrKyUYRjy+Xwym80FY+jr61M8Htfc3Jzsdrvy+bxGRkYK+o7FYtrd3VUqlZLNZpPb7VYqlfrX1di1tTUZhqFgMCifzyeXyyW73V7QZm9vT5FIRDMzM7JarQoGgzo/P/9YJW1tbdXOzo6SyaQaGxt1fHysqampottKTSaTMpmMDMPQ0NCQLBaL+vv7dXd39xHa/X6/jo6OdHp6KqfTqebmZiWTSdXV1X1twgEAP57pr68cpAAA4JcYHBzU8/Oz0un0d5fyKwwPD+v29lZnZ2ffXQoA4Idj2yoAAH+Q9fV1tbe3q6ysTNlsVvv7+5/eoQQA4J8QHgEA+INcXFxodXVVr6+vMpvN2traUiwW++6yAAC/ANtWAQAAAABFcWEOAAAAAKAowiMAAAAAoCjCIwAAAACgKMIjAAAAAKAowiMAAAAAoCjCIwAAAACgKMIjAAAAAKAowiMAAAAAoKi/AetudzlDy2DuAAAAAElFTkSuQmCC",
      "text/plain": [
       "<Figure size 900x400 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "\n",
    "#from gad_adversarial_robustness.utils.visualizations import visualize_neighbors_amount\n",
    "\n",
    "tensor_target = torch.from_numpy(target_list)\n",
    "\n",
    "normalize = True\n",
    "cut_off = 200\n",
    "\n",
    "# visualize_neighbors_amount(data.edge_index, tensor_target, data.num_nodes, max_val=max_val, normalize=normalize)\n",
    "# visualize_neighbors_amount(data_after_poison.edge_index, tensor_target, data_after_poison.num_nodes, max_val=max_val, normalize=normalize)\n",
    "\n",
    "\n",
    "visualize_2hop_node_degree([data.edge_index, data_after_poison.edge_index], [\"Before\", \"After\"], cut_off = cut_off)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<built-in method type of Tensor object at 0x0000026E31788A90>\n",
      "amount of neighbors before: 10524 avg before: 0.15594277257813216 anomaly percent before: 0.09492588369441277\n",
      "999.0\n",
      "amount of neighbors after: 9982 avg after: 0.14872725149463178 anomaly percent after: 0.050591063915047085\n",
      "505.0\n",
      "For anomaliesss\n",
      "amount of neighbors before: 1034 avg before: 0.1865738933513367 anomaly percent before: 0.5222437137330754\n",
      "540.0\n",
      "amount of neighbors after: 532 avg after: 0.16427809229563514 anomaly percent after: 0.16165413533834586\n",
      "86.0\n",
      "Avg neighbor pure clean 4.094941634241245 Avg neighbor pure poison 3.884046692607004\n",
      "Avg neighbor anom clean 7.492753623188406 Avg neighbor anom poison 3.8550724637681157\n"
     ]
    }
   ],
   "source": [
    "#Total of anomalies: 138\n",
    "\n",
    "\n",
    "#my_list = target_list\n",
    "\n",
    "my_list = torch.tensor(np.arange(data.num_nodes))\n",
    "\n",
    "print(my_list.type)\n",
    "\n",
    "for i in target_list:\n",
    "    my_list = torch.cat([my_list[0:i], my_list[i+1:]])\n",
    "\n",
    "my_list = my_list.numpy()\n",
    "\n",
    "neighbor_nodes, avg, anomaly_percent = getAvgScoreOfNeighbors(my_list, prob, data)\n",
    "print(\"amount of neighbors before: \" + str(neighbor_nodes.size) + \" avg before: \" + str(avg) + \" anomaly percent before: \" + str(anomaly_percent))\n",
    "#print(\"neighbor_nodes: \" + str(neighbor_nodes))\n",
    "print(anomaly_percent*neighbor_nodes.size)\n",
    "\n",
    "neighbor_pure_nodes_clean = neighbor_nodes\n",
    "\n",
    "neighbor_nodes, avg, anomaly_percent = getAvgScoreOfNeighbors(my_list, prob_after, data_after_poison)\n",
    "print(\"amount of neighbors after: \" + str(neighbor_nodes.size) + \" avg after: \" + str(avg) + \" anomaly percent after: \" + str(anomaly_percent))\n",
    "#print(\"neighbor_nodes: \" + str(neighbor_nodes))\n",
    "print(anomaly_percent*neighbor_nodes.size)\n",
    "\n",
    "neighbor_pure_nodes_poison = neighbor_nodes\n",
    "\n",
    "print(\"For anomaliesss\")\n",
    "my_list = target_list\n",
    "\n",
    "neighbor_nodes, avg, anomaly_percent = getAvgScoreOfNeighbors(my_list, prob, data)\n",
    "print(\"amount of neighbors before: \" + str(neighbor_nodes.size) + \" avg before: \" + str(avg) + \" anomaly percent before: \" + str(anomaly_percent))\n",
    "#print(\"neighbor_nodes: \" + str(neighbor_nodes))\n",
    "print(anomaly_percent*neighbor_nodes.size)\n",
    "\n",
    "neighbor_anom_nodes_clean = neighbor_nodes\n",
    "\n",
    "neighbor_nodes, avg, anomaly_percent = getAvgScoreOfNeighbors(my_list, prob_after, data_after_poison)\n",
    "print(\"amount of neighbors after: \" + str(neighbor_nodes.size) + \" avg after: \" + str(avg) + \" anomaly percent after: \" + str(anomaly_percent))\n",
    "#print(\"neighbor_nodes: \" + str(neighbor_nodes))\n",
    "print(anomaly_percent*neighbor_nodes.size)\n",
    "\n",
    "neighbor_anom_nodes_poison = neighbor_nodes\n",
    "\n",
    "\n",
    "length = len(target_list)\n",
    "\n",
    "print(\"Avg neighbor pure clean\", neighbor_pure_nodes_clean.size/(data.num_nodes - length), \n",
    "      \"Avg neighbor pure poison\", neighbor_pure_nodes_poison.size/(data.num_nodes - length))\n",
    "\n",
    "print(\"Avg neighbor anom clean\", neighbor_anom_nodes_clean.size/length, \n",
    "      \"Avg neighbor anom poison\", neighbor_anom_nodes_poison.size/length)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "before...\n",
      "amount detected tensor(69) accuracy: tensor(0.5000) total probability: tensor(19.9885) avg_probability: tensor(0.1448)\n",
      "after...\n",
      "amount detected tensor(14) accuracy: tensor(0.1014) total probability: tensor(11.7051) avg_probability: tensor(0.0848)\n"
     ]
    }
   ],
   "source": [
    "sum_found = 0\n",
    "sum_prob = 0\n",
    "for node in target_list:\n",
    "    sum_found += pred[node]\n",
    "    sum_prob += prob[node]\n",
    "\n",
    "print(\"before...\")\n",
    "print(\"amount detected\", sum_found, \"accuracy:\", sum_found/len(target_list), \"total probability:\", sum_prob, \"avg_probability:\", sum_prob/len(target_list))\n",
    "\n",
    "sum_found = 0\n",
    "sum_prob = 0\n",
    "for node in target_list:\n",
    "    sum_found += pred_after[node]\n",
    "    sum_prob += prob_after[node]\n",
    "    # if(pred_after[node] == 1):\n",
    "    #     print(node)\n",
    "\n",
    "print(\"after...\")\n",
    "print(\"amount detected\", sum_found, \"accuracy:\", sum_found/len(target_list), \"total probability:\", sum_prob, \"avg_probability:\", sum_prob/len(target_list))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Create poison compatible adjacency matrix...\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.])\n",
      "node_attrs\n",
      "[[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "adj\n",
      "SparseTensor(row=tensor([   0,    0,    0,  ..., 2707, 2707, 2707]),\n",
      "             col=tensor([ 633, 1862, 2582,  ...,  598, 1473, 2706]),\n",
      "             val=tensor([1., 1., 1.,  ..., 1., 1., 1.]),\n",
      "             size=(2708, 2708), nnz=11054, density=0.15%)\n",
      "labels\n",
      "tensor([0, 0, 0,  ..., 0, 0, 0])\n",
      "Making model...\n",
      "Starting attack...\n",
      "triple copy type: <class 'numpy.ndarray'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\grace\\anaconda3\\envs\\PyG2\\lib\\site-packages\\gad_adversarial_robustness\\poison\\greedy.py:35: UserWarning: Sparse CSR tensor support is in beta state. If you miss a functionality in the sparse tensor support, please submit a feature request to https://github.com/pytorch/pytorch/issues. (Triggered internally at C:\\cb\\pytorch_1000000000000\\work\\aten\\src\\ATen\\SparseCsrTensorImpl.cpp:55.)\n",
      "  return torch.sparse.mm(torch.sparse.mm(A_sp, A_sp), A_sp).to_dense()\n",
      "c:\\Users\\grace\\anaconda3\\envs\\PyG2\\lib\\site-packages\\gad_adversarial_robustness\\poison\\greedy.py:39: UserWarning: The use of `x.T` on tensors of dimension other than 2 to reverse their shape is deprecated and it will throw an error in a future release. Consider `x.mT` to transpose batches of matrices or `x.permute(*torch.arange(x.ndim - 1, -1, -1))` to reverse the dimensions of a tensor. (Triggered internally at C:\\cb\\pytorch_1000000000000\\work\\aten\\src\\ATen\\native\\TensorShape.cpp:3618.)\n",
      "  E = torch.sum(A, 1) + 0.5 * torch.diag(self.sparse_matrix_power(A, 3)).T\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "initial anomaly score: 350.9628624456122\n",
      "iter 1 anomaly score: 346.6987703271884\n",
      "iter 2 anomaly score: 341.2406180708062\n",
      "iter 3 anomaly score: 337.3620232251917\n",
      "iter 4 anomaly score: 333.7385697175731\n",
      "iter 5 anomaly score: 329.50391797501845\n",
      "iter 6 anomaly score: 325.39382010815854\n",
      "iter 7 anomaly score: 321.3425601986489\n",
      "iter 8 anomaly score: 317.5167619236698\n",
      "iter 9 anomaly score: 313.4219933045914\n",
      "iter 10 anomaly score: 309.0142055763874\n",
      "iter 11 anomaly score: 305.7359028071064\n",
      "iter 12 anomaly score: 301.8869749481308\n",
      "iter 13 anomaly score: 298.3467216385668\n",
      "iter 14 anomaly score: 294.59401804658097\n",
      "iter 15 anomaly score: 291.56750593155715\n",
      "iter 16 anomaly score: 287.87021106491227\n",
      "iter 17 anomaly score: 284.2041540246569\n",
      "iter 18 anomaly score: 280.13574147426374\n",
      "iter 19 anomaly score: 275.6951718223874\n",
      "iter 20 anomaly score: 270.8844996775314\n",
      "iter 21 anomaly score: 266.837855182466\n",
      "iter 22 anomaly score: 263.8609857542011\n",
      "iter 23 anomaly score: 260.848587650538\n",
      "iter 24 anomaly score: 256.3195823720752\n",
      "iter 25 anomaly score: 252.63389864178257\n",
      "iter 26 anomaly score: 247.9811200603876\n",
      "iter 27 anomaly score: 244.6283555405947\n",
      "iter 28 anomaly score: 241.33958649347937\n",
      "iter 29 anomaly score: 239.73575781274474\n",
      "iter 30 anomaly score: 236.41627937480763\n",
      "iter 31 anomaly score: 233.04324549713004\n",
      "iter 32 anomaly score: 228.3726613553442\n",
      "iter 33 anomaly score: 224.89824306511332\n",
      "iter 34 anomaly score: 221.40850375369936\n",
      "iter 35 anomaly score: 218.61295390822414\n",
      "Converting to torch.geometric.data.Data...\n"
     ]
    }
   ],
   "source": [
    "#PPoison\n",
    "\n",
    "from gad_adversarial_robustness.poison.greedy import inject_greedy_poison\n",
    "from pygod.utils import load_data\n",
    "from typing import List\n",
    "\n",
    "data = load_data(\"inj_cora\")\n",
    "y_binary: List[int] = data.y.bool()\n",
    "\n",
    "anomaly_list = np.where(y_binary == True)[0]\n",
    "\n",
    "\n",
    "poison_data = inject_greedy_poison(data, anomaly_list, print_stats = True)\n",
    " \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Cleaninggg\n",
    "\n",
    "\n",
    "class PGD(Optimizer):\n",
    "    \"\"\"Proximal gradient descent.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    params : iterable\n",
    "        iterable of parameters to optimize or dicts defining parameter groups\n",
    "    proxs : iterable\n",
    "        iterable of proximal operators\n",
    "    alpha : iterable\n",
    "        iterable of coefficients for proximal gradient descent\n",
    "    lr : float\n",
    "        learning rate\n",
    "    momentum : float\n",
    "        momentum factor (default: 0)\n",
    "    weight_decay : float\n",
    "        weight decay (L2 penalty) (default: 0)\n",
    "    dampening : float\n",
    "        dampening for momentum (default: 0)\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, params, proxs, alphas, lr=required, momentum=0, dampening=0, weight_decay=0):\n",
    "        defaults = dict(lr=lr, momentum=0, dampening=0,\n",
    "                        weight_decay=0, nesterov=False)\n",
    "\n",
    "\n",
    "        super(PGD, self).__init__(params, defaults)\n",
    "\n",
    "        self.proxs = proxs\n",
    "        self.alphas = alphas\n",
    "\n",
    "        for group in self.param_groups:\n",
    "            group.setdefault('proxs', proxs)\n",
    "            group.setdefault('alphas', alphas)\n",
    "\n",
    "    def __setstate__(self, state):\n",
    "        super(PGD, self).__setstate__(state)\n",
    "        for group in self.param_groups:\n",
    "            group.setdefault('nesterov', False)\n",
    "            group.setdefault('proxs', self.proxs)   #Added self'\n",
    "            group.setdefault('alphas', self.alphas) #Added self\n",
    "\n",
    "    def step(self, delta=0, closure=None):\n",
    "         for group in self.param_groups:\n",
    "            lr = group['lr']\n",
    "            weight_decay = group['weight_decay']\n",
    "            momentum = group['momentum']\n",
    "            dampening = group['dampening']\n",
    "            nesterov = group['nesterov']\n",
    "            proxs = group['proxs']\n",
    "            alphas = group['alphas']\n",
    "\n",
    "            # apply the proximal operator to each parameter in a group\n",
    "            for param in group['params']:\n",
    "                for prox_operator, alpha in zip(proxs, alphas):\n",
    "                    # param.data.add_(lr, -param.grad.data)\n",
    "                    # param.data.add_(delta)\n",
    "                    param.data = prox_operator(param.data, alpha=alpha*lr)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class ProxOperators():\n",
    "    \"\"\"Proximal Operators.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self):\n",
    "        self.nuclear_norm = None\n",
    "\n",
    "    def prox_l1(self, data, alpha):\n",
    "        \"\"\"Proximal operator for l1 norm.\n",
    "        \"\"\"\n",
    "        data = torch.mul(torch.sign(data), torch.clamp(torch.abs(data)-alpha, min=0))\n",
    "        return data\n",
    "\n",
    "    def prox_nuclear(self, data, alpha):\n",
    "        \"\"\"Proximal operator for nuclear norm (trace norm).\n",
    "        \"\"\"\n",
    "        device = data.device\n",
    "        U, S, V = np.linalg.svd(data.cpu())\n",
    "        U, S, V = torch.FloatTensor(U).to(device), torch.FloatTensor(S).to(device), torch.FloatTensor(V).to(device)\n",
    "        self.nuclear_norm = S.sum()\n",
    "        # print(\"nuclear norm: %.4f\" % self.nuclear_norm)\n",
    "\n",
    "        diag_S = torch.diag(torch.clamp(S-alpha, min=0))\n",
    "        return torch.matmul(torch.matmul(U, diag_S), V)\n",
    "\n",
    "    def prox_nuclear_truncated_2(self, data, alpha, k=50):\n",
    "        device = data.device\n",
    "        import tensorly as tl\n",
    "        tl.set_backend('pytorch')\n",
    "        U, S, V = tl.truncated_svd(data.cpu(), n_eigenvecs=k)\n",
    "        U, S, V = torch.FloatTensor(U).to(device), torch.FloatTensor(S).to(device), torch.FloatTensor(V).to(device)\n",
    "        self.nuclear_norm = S.sum()\n",
    "        # print(\"nuclear norm: %.4f\" % self.nuclear_norm)\n",
    "\n",
    "        S = torch.clamp(S-alpha, min=0)\n",
    "\n",
    "        # diag_S = torch.diag(torch.clamp(S-alpha, min=0))\n",
    "        # U = torch.spmm(U, diag_S)\n",
    "        # V = torch.matmul(U, V)\n",
    "\n",
    "        # make diag_S sparse matrix\n",
    "        indices = torch.tensor((range(0, len(S)), range(0, len(S)))).to(device)\n",
    "        values = S\n",
    "        diag_S = torch.sparse.FloatTensor(indices, values, torch.Size((len(S), len(S))))\n",
    "        V = torch.spmm(diag_S, V)\n",
    "        V = torch.matmul(U, V)\n",
    "        return V\n",
    "\n",
    "    def prox_nuclear_truncated(self, data, alpha, k=50):\n",
    "        device = data.device\n",
    "        indices = torch.nonzero(data).t()\n",
    "        values = data[indices[0], indices[1]] # modify this based on dimensionality\n",
    "        data_sparse = sp.csr_matrix((values.cpu().numpy(), indices.cpu().numpy()))\n",
    "        U, S, V = sp.linalg.svds(data_sparse, k=k)\n",
    "        U, S, V = torch.FloatTensor(U).to(device), torch.FloatTensor(S).to(device), torch.FloatTensor(V).to(device)\n",
    "        self.nuclear_norm = S.sum()\n",
    "        diag_S = torch.diag(torch.clamp(S-alpha, min=0))\n",
    "        return torch.matmul(torch.matmul(U, diag_S), V)\n",
    "\n",
    "    def prox_nuclear_cuda(self, data, alpha):\n",
    "\n",
    "        device = data.device\n",
    "        U, S, V = torch.svd(data)\n",
    "        # self.nuclear_norm = S.sum()\n",
    "        # print(f\"rank = {len(S.nonzero())}\")\n",
    "        self.nuclear_norm = S.sum()\n",
    "        S = torch.clamp(S-alpha, min=0)\n",
    "        indices = torch.tensor([range(0, U.shape[0]),range(0, U.shape[0])]).to(device)\n",
    "        values = S\n",
    "        diag_S = torch.sparse.FloatTensor(indices, values, torch.Size(U.shape))\n",
    "        # diag_S = torch.diag(torch.clamp(S-alpha, min=0))\n",
    "        # print(f\"rank_after = {len(diag_S.nonzero())}\")\n",
    "        V = torch.spmm(diag_S, V.t_())\n",
    "        V = torch.matmul(U, V)\n",
    "        return V\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "class SGD(Optimizer):\n",
    "\n",
    "\n",
    "    def __init__(self, params, lr=required, momentum=0, dampening=0,\n",
    "                 weight_decay=0, nesterov=False):\n",
    "        if lr is not required and lr < 0.0:\n",
    "            raise ValueError(\"Invalid learning rate: {}\".format(lr))\n",
    "        if momentum < 0.0:\n",
    "            raise ValueError(\"Invalid momentum value: {}\".format(momentum))\n",
    "        if weight_decay < 0.0:\n",
    "            raise ValueError(\"Invalid weight_decay value: {}\".format(weight_decay))\n",
    "\n",
    "        defaults = dict(lr=lr, momentum=momentum, dampening=dampening,\n",
    "                        weight_decay=weight_decay, nesterov=nesterov)\n",
    "        if nesterov and (momentum <= 0 or dampening != 0):\n",
    "            raise ValueError(\"Nesterov momentum requires a momentum and zero dampening\")\n",
    "        super(SGD, self).__init__(params, defaults)\n",
    "\n",
    "    def __setstate__(self, state):\n",
    "        super(SGD, self).__setstate__(state)\n",
    "        for group in self.param_groups:\n",
    "            group.setdefault('nesterov', False)\n",
    "\n",
    "    def step(self, closure=None):\n",
    "        \"\"\"Performs a single optimization step.\n",
    "\n",
    "        Arguments:\n",
    "            closure (callable, optional): A closure that reevaluates the model\n",
    "                and returns the loss.\n",
    "        \"\"\"\n",
    "        loss = None\n",
    "        if closure is not None:\n",
    "            loss = closure()\n",
    "\n",
    "        for group in self.param_groups:\n",
    "            weight_decay = group['weight_decay']\n",
    "            momentum = group['momentum']\n",
    "            dampening = group['dampening']\n",
    "            nesterov = group['nesterov']\n",
    "\n",
    "            for p in group['params']:\n",
    "                if p.grad is None:\n",
    "                    continue\n",
    "                d_p = p.grad.data\n",
    "                if weight_decay != 0:\n",
    "                    d_p.add_(weight_decay, p.data)\n",
    "                if momentum != 0:\n",
    "                    param_state = self.state[p]\n",
    "                    if 'momentum_buffer' not in param_state:\n",
    "                        buf = param_state['momentum_buffer'] = torch.clone(d_p).detach()\n",
    "                    else:\n",
    "                        buf = param_state['momentum_buffer']\n",
    "                        buf.mul_(momentum).add_(1 - dampening, d_p)\n",
    "                    if nesterov:\n",
    "                        d_p = d_p.add(momentum, buf)\n",
    "                    else:\n",
    "                        d_p = buf\n",
    "\n",
    "                p.data.add_(-group['lr'], d_p)\n",
    "\n",
    "        return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "prox_operators = ProxOperators()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy(output, labels):\n",
    "    \"\"\"Return accuracy of output compared to labels.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    output : torch.Tensor\n",
    "        output from model\n",
    "    labels : torch.Tensor or numpy.array\n",
    "        node labels\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    float\n",
    "        accuracy\n",
    "    \"\"\"\n",
    "    if not hasattr(labels, '__len__'):\n",
    "        labels = [labels]\n",
    "    if type(labels) is not torch.Tensor:\n",
    "        labels = torch.LongTensor(labels)\n",
    "    preds = output.max(1)[1].type_as(labels)\n",
    "    correct = preds.eq(labels).double() #Checks equality of predictions and labels\n",
    "    correct = correct.sum()\n",
    "    return correct / len(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Code for pro-gnn\n",
    "\n",
    "import time\n",
    "import numpy as np\n",
    "from copy import deepcopy\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import warnings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EstimateAdj(nn.Module):\n",
    "    \"\"\"Provide a pytorch parameter matrix for estimated\n",
    "    adjacency matrix and corresponding operations.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, adj, symmetric=False, device='cpu'):\n",
    "        super(EstimateAdj, self).__init__()\n",
    "        n = len(adj)\n",
    "        self.estimated_adj = nn.Parameter(torch.FloatTensor(n, n))\n",
    "        self._init_estimation(adj)\n",
    "        self.symmetric = symmetric\n",
    "        self.device = device\n",
    "\n",
    "    def _init_estimation(self, adj):\n",
    "        with torch.no_grad():\n",
    "            n = len(adj)\n",
    "            self.estimated_adj.data.copy_(adj)\n",
    "\n",
    "    def forward(self):\n",
    "        return self.estimated_adj\n",
    "\n",
    "    def normalize(self):\n",
    "\n",
    "        if self.symmetric:\n",
    "            adj = (self.estimated_adj + self.estimated_adj.t())/2\n",
    "        else:\n",
    "            adj = self.estimated_adj\n",
    "\n",
    "        normalized_adj = self._normalize(adj + torch.eye(adj.shape[0]).to(self.device))\n",
    "        return normalized_adj\n",
    "\n",
    "    def _normalize(self, mx):\n",
    "        rowsum = mx.sum(1)\n",
    "        r_inv = rowsum.pow(-1/2).flatten()\n",
    "        r_inv[torch.isinf(r_inv)] = 0.\n",
    "        r_mat_inv = torch.diag(r_inv)\n",
    "        mx = r_mat_inv @ mx\n",
    "        mx = mx @ r_mat_inv\n",
    "        return mx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class ProGNN:\n",
    "    \"\"\" ProGNN (Properties Graph Neural Network). See more details in Graph Structure Learning for Robust Graph Neural Networks, KDD 2020, https://arxiv.org/abs/2005.10203.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    model:\n",
    "        model: The backbone GNN model in ProGNN\n",
    "    args:\n",
    "        model configs\n",
    "    device: str\n",
    "        'cpu' or 'cuda'.\n",
    "\n",
    "    Examples\n",
    "    --------\n",
    "    See details in https://github.com/ChandlerBang/Pro-GNN.\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, model, args, device):\n",
    "        self.device = device\n",
    "        self.args = args\n",
    "        self.best_val_acc = 0\n",
    "        self.best_val_loss = 10\n",
    "        self.best_graph = None\n",
    "        self.weights = None\n",
    "        self.estimator = None\n",
    "        self.model = model.to(device)\n",
    "\n",
    "    def fit(self, features, adj, labels, idx_train, idx_val, **kwargs):\n",
    "        \"\"\"Train Pro-GNN.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        features :\n",
    "            node features\n",
    "        adj :\n",
    "            the adjacency matrix. The format could be torch.tensor or scipy matrix\n",
    "        labels :\n",
    "            node labels\n",
    "        idx_train :\n",
    "            node training indices\n",
    "        idx_val :\n",
    "            node validation indices\n",
    "        \"\"\"\n",
    "        args = self.args\n",
    "\n",
    "        self.optimizer = optim.Adam(self.model.parameters(),\n",
    "                               lr=args.lr, weight_decay=args.weight_decay)\n",
    "        estimator = EstimateAdj(adj, symmetric=args.symmetric, device=self.device).to(self.device)\n",
    "        self.estimator = estimator\n",
    "        self.optimizer_adj = optim.SGD(estimator.parameters(),\n",
    "                              momentum=0.9, lr=args.lr_adj)\n",
    "\n",
    "        self.optimizer_l1 = PGD(estimator.parameters(),\n",
    "                        proxs=[prox_operators.prox_l1],\n",
    "                        lr=args.lr_adj, alphas=[args.alpha])\n",
    "\n",
    "        # warnings.warn(\"If you find the nuclear proximal operator runs too slow on Pubmed, you can  uncomment line 67-71 and use prox_nuclear_cuda to perform the proximal on gpu.\")\n",
    "        # if args.dataset == \"pubmed\":\n",
    "        #     self.optimizer_nuclear = PGD(estimator.parameters(),\n",
    "        #               proxs=[prox_operators.prox_nuclear_cuda],\n",
    "        #               lr=args.lr_adj, alphas=[args.beta])\n",
    "        # else:\n",
    "        warnings.warn(\"If you find the nuclear proximal operator runs too slow, you can modify line 77 to use prox_operators.prox_nuclear_cuda instead of prox_operators.prox_nuclear to perform the proximal on GPU. See details in https://github.com/ChandlerBang/Pro-GNN/issues/1\")\n",
    "        self.optimizer_nuclear = PGD(estimator.parameters(),\n",
    "                  proxs=[prox_operators.prox_nuclear],\n",
    "                  lr=args.lr_adj, alphas=[args.beta])\n",
    "\n",
    "        # Train model\n",
    "        t_total = time.time()\n",
    "        for epoch in range(args.epochs):\n",
    "            if args.only_gcn:\n",
    "                self.train_gcn(epoch, features, estimator.estimated_adj,\n",
    "                        labels, idx_train, idx_val)\n",
    "            else:\n",
    "                for i in range(int(args.outer_steps)):\n",
    "                    self.train_adj(epoch, features, adj, labels,\n",
    "                            idx_train, idx_val)\n",
    "\n",
    "                for i in range(int(args.inner_steps)):\n",
    "                    self.train_gcn(epoch, features, estimator.estimated_adj,\n",
    "                            labels, idx_train, idx_val)\n",
    "\n",
    "        print(\"Optimization Finished!\")\n",
    "        print(\"Total time elapsed: {:.4f}s\".format(time.time() - t_total))\n",
    "        print(args)\n",
    "\n",
    "        # Testing\n",
    "        print(\"picking the best model according to validation performance\")\n",
    "        self.model.load_state_dict(self.weights)\n",
    "\n",
    "    def train_gcn(self, epoch, features, adj, labels, idx_train, idx_val):\n",
    "        args = self.args\n",
    "        estimator = self.estimator\n",
    "        adj = estimator.normalize()\n",
    "\n",
    "        t = time.time()\n",
    "        self.model.train()\n",
    "        self.optimizer.zero_grad()\n",
    "\n",
    "        output = self.model(features, adj)\n",
    "        loss_train = F.nll_loss(output[idx_train], labels[idx_train])\n",
    "        acc_train = accuracy(output[idx_train], labels[idx_train])\n",
    "        loss_train.backward()\n",
    "        self.optimizer.step()\n",
    "\n",
    "        # Evaluate validation set performance separately,\n",
    "        # deactivates dropout during validation run.\n",
    "        self.model.eval()\n",
    "        output = self.model(features, adj)\n",
    "\n",
    "        loss_val = F.nll_loss(output[idx_val], labels[idx_val])\n",
    "        acc_val = accuracy(output[idx_val], labels[idx_val])\n",
    "\n",
    "        if acc_val > self.best_val_acc:\n",
    "            self.best_val_acc = acc_val\n",
    "            self.best_graph = adj.detach()\n",
    "            self.weights = deepcopy(self.model.state_dict())\n",
    "            if args.debug:\n",
    "                print('\\t=== saving current graph/gcn, best_val_acc: %s' % self.best_val_acc.item())\n",
    "\n",
    "        if loss_val < self.best_val_loss:\n",
    "            self.best_val_loss = loss_val\n",
    "            self.best_graph = adj.detach()\n",
    "            self.weights = deepcopy(self.model.state_dict())\n",
    "            if args.debug:\n",
    "                print(f'\\t=== saving current graph/gcn, best_val_loss: %s' % self.best_val_loss.item())\n",
    "\n",
    "        if args.debug:\n",
    "            if epoch % 1 == 0:\n",
    "                print('Epoch: {:04d}'.format(epoch+1),\n",
    "                      'loss_train: {:.4f}'.format(loss_train.item()),\n",
    "                      'acc_train: {:.4f}'.format(acc_train.item()),\n",
    "                      'loss_val: {:.4f}'.format(loss_val.item()),\n",
    "                      'acc_val: {:.4f}'.format(acc_val.item()),\n",
    "                      'time: {:.4f}s'.format(time.time() - t))\n",
    "\n",
    "\n",
    "\n",
    "    def train_adj(self, epoch, features, adj, labels, idx_train, idx_val):\n",
    "        estimator = self.estimator\n",
    "        args = self.args\n",
    "        if args.debug:\n",
    "            print(\"\\n=== train_adj ===\")\n",
    "        t = time.time()\n",
    "        estimator.train()\n",
    "        self.optimizer_adj.zero_grad()\n",
    "\n",
    "        loss_l1 = torch.norm(estimator.estimated_adj, 1)\n",
    "        loss_fro = torch.norm(estimator.estimated_adj - adj, p='fro')\n",
    "        normalized_adj = estimator.normalize()\n",
    "\n",
    "        if args.lambda_:\n",
    "            loss_smooth_feat = self.feature_smoothing(estimator.estimated_adj, features)\n",
    "        else:\n",
    "            loss_smooth_feat = 0 * loss_l1\n",
    "\n",
    "        output = self.model(features, normalized_adj)\n",
    "        loss_gcn = F.nll_loss(output[idx_train], labels[idx_train])\n",
    "        acc_train = accuracy(output[idx_train], labels[idx_train])\n",
    "\n",
    "        loss_symmetric = torch.norm(estimator.estimated_adj \\\n",
    "                        - estimator.estimated_adj.t(), p=\"fro\")\n",
    "\n",
    "        loss_diffiential =  loss_fro + args.gamma * loss_gcn + args.lambda_ * loss_smooth_feat + args.phi * loss_symmetric\n",
    "\n",
    "        loss_diffiential.backward()\n",
    "\n",
    "        self.optimizer_adj.step()\n",
    "        loss_nuclear =  0 * loss_fro\n",
    "        if args.beta != 0:\n",
    "            self.optimizer_nuclear.zero_grad()\n",
    "            self.optimizer_nuclear.step()\n",
    "            loss_nuclear = prox_operators.nuclear_norm\n",
    "\n",
    "        self.optimizer_l1.zero_grad()\n",
    "        self.optimizer_l1.step()\n",
    "\n",
    "        total_loss = loss_fro \\\n",
    "                    + args.gamma * loss_gcn \\\n",
    "                    + args.alpha * loss_l1 \\\n",
    "                    + args.beta * loss_nuclear \\\n",
    "                    + args.phi * loss_symmetric\n",
    "\n",
    "        estimator.estimated_adj.data.copy_(torch.clamp(\n",
    "                  estimator.estimated_adj.data, min=0, max=1))\n",
    "\n",
    "        # Evaluate validation set performance separately,\n",
    "        # deactivates dropout during validation run.\n",
    "        self.model.eval()\n",
    "        normalized_adj = estimator.normalize()\n",
    "        output = self.model(features, normalized_adj)\n",
    "\n",
    "        loss_val = F.nll_loss(output[idx_val], labels[idx_val])\n",
    "        acc_val = accuracy(output[idx_val], labels[idx_val])\n",
    "        print('Epoch: {:04d}'.format(epoch+1),\n",
    "              'acc_train: {:.4f}'.format(acc_train.item()),\n",
    "              'loss_val: {:.4f}'.format(loss_val.item()),\n",
    "              'acc_val: {:.4f}'.format(acc_val.item()),\n",
    "              'time: {:.4f}s'.format(time.time() - t))\n",
    "\n",
    "        if acc_val > self.best_val_acc:\n",
    "            self.best_val_acc = acc_val\n",
    "            self.best_graph = normalized_adj.detach()\n",
    "            self.weights = deepcopy(self.model.state_dict())\n",
    "            if args.debug:\n",
    "                print(f'\\t=== saving current graph/gcn, best_val_acc: %s' % self.best_val_acc.item())\n",
    "\n",
    "        if loss_val < self.best_val_loss:\n",
    "            self.best_val_loss = loss_val\n",
    "            self.best_graph = normalized_adj.detach()\n",
    "            self.weights = deepcopy(self.model.state_dict())\n",
    "            if args.debug:\n",
    "                print(f'\\t=== saving current graph/gcn, best_val_loss: %s' % self.best_val_loss.item())\n",
    "\n",
    "        if args.debug:\n",
    "            if epoch % 1 == 0:\n",
    "                print('Epoch: {:04d}'.format(epoch+1),\n",
    "                      'loss_fro: {:.4f}'.format(loss_fro.item()),\n",
    "                      'loss_gcn: {:.4f}'.format(loss_gcn.item()),\n",
    "                      'loss_feat: {:.4f}'.format(loss_smooth_feat.item()),\n",
    "                      'loss_symmetric: {:.4f}'.format(loss_symmetric.item()),\n",
    "                      'delta_l1_norm: {:.4f}'.format(torch.norm(estimator.estimated_adj-adj, 1).item()),\n",
    "                      'loss_l1: {:.4f}'.format(loss_l1.item()),\n",
    "                      'loss_total: {:.4f}'.format(total_loss.item()),\n",
    "                      'loss_nuclear: {:.4f}'.format(loss_nuclear.item()))\n",
    "\n",
    "\n",
    "    def test(self, features, labels, idx_test):\n",
    "        \"\"\"Evaluate the performance of ProGNN on test set\n",
    "        \"\"\"\n",
    "        print(\"\\t=== testing ===\")\n",
    "        self.model.eval()\n",
    "        adj = self.best_graph\n",
    "        if self.best_graph is None:\n",
    "            adj = self.estimator.normalize()\n",
    "        output = self.model(features, adj)\n",
    "        loss_test = F.nll_loss(output[idx_test], labels[idx_test])\n",
    "        acc_test = accuracy(output[idx_test], labels[idx_test])\n",
    "        print(\"\\tTest set results:\",\n",
    "              \"loss= {:.4f}\".format(loss_test.item()),\n",
    "              \"accuracy= {:.4f}\".format(acc_test.item()))\n",
    "        return acc_test.item()\n",
    "\n",
    "    def feature_smoothing(self, adj, X):\n",
    "        adj = (adj.t() + adj)/2\n",
    "        rowsum = adj.sum(1)\n",
    "        r_inv = rowsum.flatten()\n",
    "        D = torch.diag(r_inv)\n",
    "        L = D - adj\n",
    "\n",
    "        r_inv = r_inv  + 1e-3\n",
    "        r_inv = r_inv.pow(-1/2).flatten()\n",
    "        r_inv[torch.isinf(r_inv)] = 0.\n",
    "        r_mat_inv = torch.diag(r_inv)\n",
    "        # L = r_mat_inv @ L\n",
    "        L = r_mat_inv @ L @ r_mat_inv\n",
    "\n",
    "        XLXT = torch.matmul(torch.matmul(X.t(), L), X)\n",
    "        loss_smooth_feat = torch.trace(XLXT)\n",
    "        return loss_smooth_feat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['c:\\\\Users\\\\grace\\\\GitHub\\\\AAU-Dat6-Poison-GAD\\\\Defence', 'c:\\\\Users\\\\grace\\\\anaconda3\\\\envs\\\\PyG2\\\\python39.zip', 'c:\\\\Users\\\\grace\\\\anaconda3\\\\envs\\\\PyG2\\\\DLLs', 'c:\\\\Users\\\\grace\\\\anaconda3\\\\envs\\\\PyG2\\\\lib', 'c:\\\\Users\\\\grace\\\\anaconda3\\\\envs\\\\PyG2', '', 'c:\\\\Users\\\\grace\\\\anaconda3\\\\envs\\\\PyG2\\\\lib\\\\site-packages', 'c:\\\\Users\\\\grace\\\\anaconda3\\\\envs\\\\PyG2\\\\lib\\\\site-packages\\\\win32', 'c:\\\\Users\\\\grace\\\\anaconda3\\\\envs\\\\PyG2\\\\lib\\\\site-packages\\\\win32\\\\lib', 'c:\\\\Users\\\\grace\\\\anaconda3\\\\envs\\\\PyG2\\\\lib\\\\site-packages\\\\Pythonwin', 'c:\\\\Users\\\\grace\\\\GitHub\\\\AAU-Dat6-Poison-GAD\\\\learning\\\\learning_Dominant', 'c:\\\\Users\\\\grace\\\\GitHub\\\\AAU-Dat6-Poison-GAD\\\\learning\\\\learning_Dominant']\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'GCN' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[11], line 10\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28mprint\u001b[39m(sys\u001b[38;5;241m.\u001b[39mpath)\n\u001b[0;32m      7\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mdominant_Model\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Dominant\n\u001b[1;32m---> 10\u001b[0m model \u001b[38;5;241m=\u001b[39m \u001b[43mGCN\u001b[49m(nfeat\u001b[38;5;241m=\u001b[39mfeatures\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m],\n\u001b[0;32m     11\u001b[0m             nhid\u001b[38;5;241m=\u001b[39margs\u001b[38;5;241m.\u001b[39mhidden,\n\u001b[0;32m     12\u001b[0m             nclass\u001b[38;5;241m=\u001b[39mlabels\u001b[38;5;241m.\u001b[39mmax()\u001b[38;5;241m.\u001b[39mitem() \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m,\n\u001b[0;32m     13\u001b[0m             dropout\u001b[38;5;241m=\u001b[39margs\u001b[38;5;241m.\u001b[39mdropout, device\u001b[38;5;241m=\u001b[39mdevice)\n\u001b[0;32m     15\u001b[0m perturbed_adj, features, labels \u001b[38;5;241m=\u001b[39m preprocess(perturbed_adj, features, labels, preprocess_adj\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, device\u001b[38;5;241m=\u001b[39mdevice)\n\u001b[0;32m     16\u001b[0m prognn \u001b[38;5;241m=\u001b[39m ProGNN(model, args, device)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'GCN' is not defined"
     ]
    }
   ],
   "source": [
    "# Use model\n",
    "from gad_adversarial_robustness.gad.dominant.dominant import Dominant\n",
    "from gad_adversarial_robustness.utils.graph_utils import prepare_graph\n",
    "model = Dominant()\n",
    "\n",
    "\n",
    "#perturbed_adj, features, labels = preprocess(perturbed_adj, features, labels, preprocess_adj=False, device=device)\n",
    "\n",
    "\n",
    "node_attr, adj, labels = prepare_graph(poison_data)\n",
    "\n",
    "prognn = ProGNN(model, args, device)\n",
    "prognn.fit(node_attr, adj, labels, idx_train, idx_val)\n",
    "\n",
    "prognn.test(node_attr, labels, idx_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prognn = ProGNN(model, args, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "prognn.fit(node_attr, adj, labels, idx_train, idx_val)\n",
    "prognn.test(node_attr, labels, idx_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prognn.test(node_attr, labels, idx_test)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PyG2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
