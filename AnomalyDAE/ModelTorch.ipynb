{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch_geometric.datasets import Planetoid\n",
    "import torch_geometric.utils as pyg_utils\n",
    "import networkx as nx\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torch_geometric.transforms as T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the [0] at the end is used to access the attributes\n",
    "data = Planetoid('./data/Cora', 'Cora', transform=T.NormalizeFeatures())[0]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the dataset name ('Cora', 'CiteSeer', or 'PubMed')\n",
    "dataset_name = 'Cora'\n",
    "\n",
    "# Load the dataset\n",
    "dataset = Planetoid(root='./data', name=dataset_name)\n",
    "\n",
    "# Access the dataset attributes\n",
    "data = dataset[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'num_nodes': 2708, 'num_edges': 10556, 'num_edge_features': 0, 'num_node_features': 1433, 'num_node_classes': 7}\n"
     ]
    }
   ],
   "source": [
    "# Dataset information\n",
    "# print(f'Dataset: {dataset_name}')\n",
    "# print(f'Number of nodes: {data.num_nodes}')\n",
    "# print(f'Number of edges: {data.num_edges}')\n",
    "# print(f'Number of node features: {data.num_node_features}')\n",
    "# print(f'Number of node classes: {dataset.num_classes}')\n",
    "\n",
    "data_details = {\n",
    "    \"num_nodes\" : data.num_nodes, \n",
    "    \"num_edges\" : data.num_edges, \n",
    "    \"num_edge_features\": dataset.num_edge_features,\n",
    "    \"num_node_features\": dataset.num_node_features,\n",
    "    \"num_node_classes\": dataset.num_classes   \n",
    "}\n",
    "\n",
    "print(data_details)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "############ Visualization ####################\n",
    "# Convert PyTorch Geometric data to NetworkX graph ---\n",
    "\n",
    "# graph = pyg_utils.to_networkx(data, to_undirected=True)\n",
    "\n",
    "# Draws the graph ----\n",
    "\n",
    "# plt.figure(figsize=(8, 8))\n",
    "# nx.draw(graph, node_size=10, node_color='b', edge_color='gray', with_labels=False)\n",
    "# plt.title('CORA Dataset Graph')\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# AnomalyDAE (Anomaly Detection Autoencoder) model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1) Data preprocessing: Convert the PyTorch Geometric Data object into a format suitable for training an autoencoder. \n",
    "\n",
    "# 2) Define the Autoencoder Architecture: Define the architecture of the AnomalyDAE model. This typically involves defining the encoder and decoder networks.\n",
    "\n",
    "# 3) Loss function: Define a suitable loss function for training the AnomalyDAE model. \n",
    "\n",
    "# 4) Training: Train the AnomalyDAE model using the CORA dataset. \n",
    "\n",
    "# 5) Anomaly Detection: Use the trained AnomalyDAE model to detect anomalies in the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pygod.generator import gen_contextual_outlier, gen_structural_outlier\n",
    "\n",
    "data, ya = gen_contextual_outlier(data, n=100, k=50)\n",
    "data, ys = gen_structural_outlier(data, m=10, n=10)\n",
    "data.y = torch.logical_or(ys, ya).long()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.nn import Sigmoid\n",
    "from pygod import detector\n",
    "from pygod.detector import AnomalyDAE\n",
    "\n",
    "import torch.nn.functional as F\n",
    "from pygod.detector import DeepDetector\n",
    "from pygod.nn import AnomalyDAEBase\n",
    "\n",
    "class AnomalyDAE(DeepDetector):\n",
    "    def __init__(self,\n",
    "                 emb_dim=64,\n",
    "                 hid_dim=64,\n",
    "                 num_layers=4,\n",
    "                 dropout=0.,\n",
    "                 weight_decay=0.,\n",
    "                 act=F.relu,\n",
    "                 backbone=None,\n",
    "                 alpha=0.5,\n",
    "                 theta=1.,\n",
    "                 eta=1.,\n",
    "                 contamination=0.1,\n",
    "                 lr=0.004,\n",
    "                 epoch=5,\n",
    "                 gpu=-1,\n",
    "                 batch_size=0,\n",
    "                 num_neigh=-1,\n",
    "                 verbose=0,\n",
    "                 save_emb=False,\n",
    "                 compile_model=False,\n",
    "                 **kwargs):\n",
    "\n",
    "        if backbone is not None or num_layers != 4:\n",
    "            warnings.warn(\"Backbone and num_layers are not used in AnomalyDAE\")\n",
    "\n",
    "        super(AnomalyDAE, self).__init__(hid_dim=hid_dim,\n",
    "                                         num_layers=num_layers,\n",
    "                                         dropout=dropout,\n",
    "                                         weight_decay=weight_decay,\n",
    "                                         act=act,\n",
    "                                         backbone=backbone,\n",
    "                                         contamination=contamination,\n",
    "                                         lr=lr,\n",
    "                                         epoch=epoch,\n",
    "                                         gpu=gpu,\n",
    "                                         batch_size=batch_size,\n",
    "                                         num_neigh=num_neigh,\n",
    "                                         verbose=verbose,\n",
    "                                         save_emb=save_emb,\n",
    "                                         compile_model=compile_model,\n",
    "                                         **kwargs)\n",
    "\n",
    "        self.emb_dim = emb_dim\n",
    "        self.alpha = alpha\n",
    "        self.theta = theta\n",
    "        self.eta = eta\n",
    "\n",
    "    def process_graph(self, data):\n",
    "        AnomalyDAEBase.process_graph(data)\n",
    "\n",
    "    def init_model(self, **kwargs):\n",
    "        if self.save_emb:\n",
    "            self.emb = torch.zeros(self.num_nodes,\n",
    "                                   self.hid_dim)\n",
    "\n",
    "        return AnomalyDAEBase(in_dim=self.in_dim,\n",
    "                              num_nodes=self.num_nodes,\n",
    "                              emb_dim=self.emb_dim,\n",
    "                              hid_dim=self.hid_dim,\n",
    "                              dropout=self.dropout,\n",
    "                              act=self.act,\n",
    "                              **kwargs).to(self.device)\n",
    "\n",
    "    def forward_model(self, data):\n",
    "        batch_size = data.batch_size\n",
    "        node_idx = data.n_id\n",
    "\n",
    "        x = data.x.to(self.device)\n",
    "        s = data.s.to(self.device)\n",
    "        edge_index = data.edge_index.to(self.device)\n",
    "\n",
    "        x_, s_ = self.model(x, edge_index, batch_size)\n",
    "\n",
    "        # positive weight conversion\n",
    "        weight = 1 - self.alpha\n",
    "        pos_weight_a = self.eta / (1 + self.eta)\n",
    "        pos_weight_s = self.theta / (1 + self.theta)\n",
    "\n",
    "        score = self.model.loss_func(x[:batch_size],\n",
    "                                     x_[:batch_size],\n",
    "                                     s[:batch_size, node_idx],\n",
    "                                     s_[:batch_size],\n",
    "                                     weight,\n",
    "                                     pos_weight_a,\n",
    "                                     pos_weight_s)\n",
    "\n",
    "        loss = torch.mean(score)\n",
    "\n",
    "        return loss, score.detach().cpu()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AnomalyDAE(act=<function relu at 0x000002659D874180>, alpha=0.5,\n",
      "           backbone=None, batch_size=0, compile_model=False,\n",
      "           contamination=0.1, dropout=0.0, emb_dim=64, epoch=5, eta=1.0,\n",
      "           gpu=None, hid_dim=64, lr=0.004, num_layers=4,\n",
      "           num_neigh=[-1, -1, -1, -1], save_emb=False, theta=1.0,\n",
      "           verbose=0, weight_decay=0.0)\n"
     ]
    }
   ],
   "source": [
    "res = AnomalyDAE()\n",
    "\n",
    "print(res)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
