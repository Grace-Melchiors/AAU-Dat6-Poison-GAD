{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-05T15:29:18.344761Z",
     "start_time": "2024-03-05T15:29:18.321170Z"
    }
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'torch_geometric'",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mModuleNotFoundError\u001B[0m                       Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[31], line 1\u001B[0m\n\u001B[1;32m----> 1\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mtorch_geometric\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mdatasets\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m Planetoid\n\u001B[0;32m      2\u001B[0m \u001B[38;5;28;01mimport\u001B[39;00m \u001B[38;5;21;01mtorch_geometric\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mutils\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m \u001B[38;5;21;01mpyg_utils\u001B[39;00m\n\u001B[0;32m      3\u001B[0m \u001B[38;5;28;01mimport\u001B[39;00m \u001B[38;5;21;01mnetworkx\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m \u001B[38;5;21;01mnx\u001B[39;00m\n",
      "\u001B[1;31mModuleNotFoundError\u001B[0m: No module named 'torch_geometric'"
     ]
    }
   ],
   "source": [
    "from torch_geometric.datasets import Planetoid\n",
    "import torch_geometric.utils as pyg_utils\n",
    "import networkx as nx\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torch_geometric.transforms as T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-05T15:29:18.346768Z",
     "start_time": "2024-03-05T15:29:18.346768Z"
    }
   },
   "outputs": [],
   "source": [
    "# the [0] at the end is used to access the attributes\n",
    "data = Planetoid('./data/Cora', 'Cora', transform=T.NormalizeFeatures())[0]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-05T15:29:18.419448Z",
     "start_time": "2024-03-05T15:29:18.397822Z"
    }
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'Planetoid' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mNameError\u001B[0m                                 Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[32], line 5\u001B[0m\n\u001B[0;32m      2\u001B[0m dataset_name \u001B[38;5;241m=\u001B[39m \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mCora\u001B[39m\u001B[38;5;124m'\u001B[39m\n\u001B[0;32m      4\u001B[0m \u001B[38;5;66;03m# Load the dataset\u001B[39;00m\n\u001B[1;32m----> 5\u001B[0m dataset \u001B[38;5;241m=\u001B[39m Planetoid(root\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124m./data\u001B[39m\u001B[38;5;124m'\u001B[39m, name\u001B[38;5;241m=\u001B[39mdataset_name)\n\u001B[0;32m      7\u001B[0m \u001B[38;5;66;03m# Access the dataset attributes\u001B[39;00m\n\u001B[0;32m      8\u001B[0m data \u001B[38;5;241m=\u001B[39m dataset[\u001B[38;5;241m0\u001B[39m]\n",
      "\u001B[1;31mNameError\u001B[0m: name 'Planetoid' is not defined"
     ]
    }
   ],
   "source": [
    "# Define the dataset name ('Cora', 'CiteSeer', or 'PubMed')\n",
    "dataset_name = 'Cora'\n",
    "\n",
    "# Load the dataset\n",
    "dataset = Planetoid(root='./data', name=dataset_name)\n",
    "\n",
    "# Access the dataset attributes\n",
    "data = dataset[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-05T15:29:18.486730Z",
     "start_time": "2024-03-05T15:29:18.453065Z"
    }
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'data' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mNameError\u001B[0m                                 Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[33], line 9\u001B[0m\n\u001B[0;32m      1\u001B[0m \u001B[38;5;66;03m# Dataset information\u001B[39;00m\n\u001B[0;32m      2\u001B[0m \u001B[38;5;66;03m# print(f'Dataset: {dataset_name}')\u001B[39;00m\n\u001B[0;32m      3\u001B[0m \u001B[38;5;66;03m# print(f'Number of nodes: {data.num_nodes}')\u001B[39;00m\n\u001B[0;32m      4\u001B[0m \u001B[38;5;66;03m# print(f'Number of edges: {data.num_edges}')\u001B[39;00m\n\u001B[0;32m      5\u001B[0m \u001B[38;5;66;03m# print(f'Number of node features: {data.num_node_features}')\u001B[39;00m\n\u001B[0;32m      6\u001B[0m \u001B[38;5;66;03m# print(f'Number of node classes: {dataset.num_classes}')\u001B[39;00m\n\u001B[0;32m      8\u001B[0m data_details \u001B[38;5;241m=\u001B[39m {\n\u001B[1;32m----> 9\u001B[0m     \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mnum_nodes\u001B[39m\u001B[38;5;124m\"\u001B[39m : data\u001B[38;5;241m.\u001B[39mnum_nodes, \n\u001B[0;32m     10\u001B[0m     \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mnum_edges\u001B[39m\u001B[38;5;124m\"\u001B[39m : data\u001B[38;5;241m.\u001B[39mnum_edges, \n\u001B[0;32m     11\u001B[0m     \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mnum_edge_features\u001B[39m\u001B[38;5;124m\"\u001B[39m: dataset\u001B[38;5;241m.\u001B[39mnum_edge_features,\n\u001B[0;32m     12\u001B[0m     \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mnum_node_features\u001B[39m\u001B[38;5;124m\"\u001B[39m: dataset\u001B[38;5;241m.\u001B[39mnum_node_features,\n\u001B[0;32m     13\u001B[0m     \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mnum_node_classes\u001B[39m\u001B[38;5;124m\"\u001B[39m: dataset\u001B[38;5;241m.\u001B[39mnum_classes   \n\u001B[0;32m     14\u001B[0m }\n\u001B[0;32m     16\u001B[0m \u001B[38;5;28mprint\u001B[39m(data_details)\n",
      "\u001B[1;31mNameError\u001B[0m: name 'data' is not defined"
     ]
    }
   ],
   "source": [
    "# Dataset information\n",
    "# print(f'Dataset: {dataset_name}')\n",
    "# print(f'Number of nodes: {data.num_nodes}')\n",
    "# print(f'Number of edges: {data.num_edges}')\n",
    "# print(f'Number of node features: {data.num_node_features}')\n",
    "# print(f'Number of node classes: {dataset.num_classes}')\n",
    "\n",
    "data_details = {\n",
    "    \"num_nodes\" : data.num_nodes, \n",
    "    \"num_edges\" : data.num_edges, \n",
    "    \"num_edge_features\": dataset.num_edge_features,\n",
    "    \"num_node_features\": dataset.num_node_features,\n",
    "    \"num_node_classes\": dataset.num_classes   \n",
    "}\n",
    "\n",
    "print(data_details)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-05T15:29:18.600514Z",
     "start_time": "2024-03-05T15:29:18.596340Z"
    }
   },
   "outputs": [],
   "source": [
    "############ Visualization ####################\n",
    "# Convert PyTorch Geometric data to NetworkX graph ---\n",
    "\n",
    "# graph = pyg_utils.to_networkx(data, to_undirected=True)\n",
    "\n",
    "# Draws the graph ----\n",
    "\n",
    "# plt.figure(figsize=(8, 8))\n",
    "# nx.draw(graph, node_size=10, node_color='b', edge_color='gray', with_labels=False)\n",
    "# plt.title('CORA Dataset Graph')\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# AnomalyDAE (Anomaly Detection Autoencoder) model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-05T15:29:18.700731Z",
     "start_time": "2024-03-05T15:29:18.695816Z"
    }
   },
   "outputs": [],
   "source": [
    "# 1) Data preprocessing: Convert the PyTorch Geometric Data object into a format suitable for training an autoencoder. \n",
    "\n",
    "# 2) Define the Autoencoder Architecture: Define the architecture of the AnomalyDAE model. This typically involves defining the encoder and decoder networks.\n",
    "\n",
    "# 3) Loss function: Define a suitable loss function for training the AnomalyDAE model. \n",
    "\n",
    "# 4) Training: Train the AnomalyDAE model using the CORA dataset. \n",
    "\n",
    "# 5) Anomaly Detection: Use the trained AnomalyDAE model to detect anomalies in the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-05T15:29:18.810423Z",
     "start_time": "2024-03-05T15:29:18.787559Z"
    }
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'pygod'",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mModuleNotFoundError\u001B[0m                       Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[36], line 1\u001B[0m\n\u001B[1;32m----> 1\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mpygod\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mgenerator\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m gen_contextual_outlier, gen_structural_outlier\n\u001B[0;32m      3\u001B[0m data, ya \u001B[38;5;241m=\u001B[39m gen_contextual_outlier(data, n\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m100\u001B[39m, k\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m50\u001B[39m)\n\u001B[0;32m      4\u001B[0m data, ys \u001B[38;5;241m=\u001B[39m gen_structural_outlier(data, m\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m10\u001B[39m, n\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m10\u001B[39m)\n",
      "\u001B[1;31mModuleNotFoundError\u001B[0m: No module named 'pygod'"
     ]
    }
   ],
   "source": [
    "from pygod.generator import gen_contextual_outlier, gen_structural_outlier\n",
    "\n",
    "data, ya = gen_contextual_outlier(data, n=100, k=50)\n",
    "data, ys = gen_structural_outlier(data, m=10, n=10)\n",
    "data.y = torch.logical_or(ys, ya).long()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-05T15:29:18.893271Z",
     "start_time": "2024-03-05T15:29:18.844026Z"
    }
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'torch'",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mModuleNotFoundError\u001B[0m                       Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[37], line 1\u001B[0m\n\u001B[1;32m----> 1\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mtorch\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mnn\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m Sigmoid\n\u001B[0;32m      2\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mpygod\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m detector\n\u001B[0;32m      3\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mpygod\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mdetector\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m AnomalyDAE\n",
      "\u001B[1;31mModuleNotFoundError\u001B[0m: No module named 'torch'"
     ]
    }
   ],
   "source": [
    "from torch.nn import Sigmoid\n",
    "from pygod import detector\n",
    "from pygod.detector import AnomalyDAE\n",
    "\n",
    "import torch.nn.functional as F\n",
    "from pygod.detector import DeepDetector\n",
    "from pygod.nn import AnomalyDAEBase\n",
    "\n",
    "# from: https://docs.pygod.org/en/latest/generated/pygod.detector.AnomalyDAE.html\n",
    "class AnomalyDAE(DeepDetector):\n",
    "    def __init__(self,\n",
    "                 emb_dim=64,\n",
    "                 hid_dim=64,\n",
    "                 num_layers=4,\n",
    "                 dropout=0.,\n",
    "                 weight_decay=0.,\n",
    "                 act=F.relu,\n",
    "                 backbone=None,\n",
    "                 alpha=0.5,\n",
    "                 theta=1.,\n",
    "                 eta=1.,\n",
    "                 contamination=0.1,\n",
    "                 lr=0.004,\n",
    "                 epoch=5,\n",
    "                 gpu=-1,\n",
    "                 batch_size=0,    \n",
    "                 num_neigh=-1,\n",
    "                 verbose=0,\n",
    "                 save_emb=False,\n",
    "                 compile_model=False,\n",
    "                 **kwargs):\n",
    "\n",
    "        if backbone is not None or num_layers != 4:\n",
    "            warnings.warn(\"Backbone and num_layers are not used in AnomalyDAE\")\n",
    "\n",
    "        super(AnomalyDAE, self).__init__(hid_dim=hid_dim,\n",
    "                                         num_layers=num_layers,\n",
    "                                         dropout=dropout,\n",
    "                                         weight_decay=weight_decay,\n",
    "                                         act=act,\n",
    "                                         backbone=backbone,\n",
    "                                         contamination=contamination,\n",
    "                                         lr=lr,\n",
    "                                         epoch=epoch,\n",
    "                                         gpu=gpu,\n",
    "                                         batch_size=batch_size,\n",
    "                                         num_neigh=num_neigh,\n",
    "                                         verbose=verbose,\n",
    "                                         save_emb=save_emb,\n",
    "                                         compile_model=compile_model,\n",
    "                                         **kwargs)\n",
    "\n",
    "        self.emb_dim = emb_dim\n",
    "        self.alpha = alpha\n",
    "        self.theta = theta\n",
    "        self.eta = eta\n",
    "\n",
    "    def process_graph(self, data):\n",
    "        AnomalyDAEBase.process_graph(data)\n",
    "\n",
    "    def init_model(self, **kwargs):\n",
    "        if self.save_emb:\n",
    "            self.emb = torch.zeros(self.num_nodes,\n",
    "                                   self.hid_dim)\n",
    "\n",
    "        return AnomalyDAEBase(in_dim=self.in_dim,\n",
    "                              num_nodes=self.num_nodes,\n",
    "                              emb_dim=self.emb_dim,\n",
    "                              hid_dim=self.hid_dim,\n",
    "                              dropout=self.dropout,\n",
    "                              act=self.act,\n",
    "                              **kwargs).to(self.device)\n",
    "\n",
    "    def forward_model(self, data):\n",
    "        # batch_size = data.batch_size              # changed from \"data.batch_size\".. assuming it was refering to the data points it should be including\n",
    "        # node_idx = data.n_id                      # not sure what n_id or node_idx is..?\n",
    "        batch_size = data.train_mask    \n",
    "        node_idx = data.test_mask            \n",
    "\n",
    "\n",
    "\n",
    "        x = data.x.to(self.device)                  # not sure what this is trying to pull from the data\n",
    "        s = data.s.to(self.device)                  # not sure what this is trying to pull from the data either...\n",
    "        edge_index = data.edge_index.to(self.device)\n",
    "\n",
    "        x_, s_ = self.model(x, edge_index, batch_size)\n",
    "\n",
    "        # positive weight conversion\n",
    "        weight = 1 - self.alpha\n",
    "        pos_weight_a = self.eta / (1 + self.eta)\n",
    "        pos_weight_s = self.theta / (1 + self.theta)\n",
    "\n",
    "        score = self.model.loss_func(x[:batch_size],\n",
    "                                     x_[:batch_size],\n",
    "                                     s[:batch_size, node_idx],  # batch size and node_idx used here\n",
    "                                     s_[:batch_size],\n",
    "                                     weight,\n",
    "                                     pos_weight_a,\n",
    "                                     pos_weight_s)\n",
    "\n",
    "        loss = torch.mean(score)\n",
    "\n",
    "        return loss, score.detach().cpu()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-05T15:29:19.071882Z",
     "start_time": "2024-03-05T15:29:19.042563Z"
    }
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'AnomalyDAE' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mNameError\u001B[0m                                 Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[38], line 1\u001B[0m\n\u001B[1;32m----> 1\u001B[0m model \u001B[38;5;241m=\u001B[39m AnomalyDAE()\n\u001B[0;32m      4\u001B[0m \u001B[38;5;66;03m# ---------- having trouble running the statement below, bc I need to resolve the uncertainties about what the code is referencing from the dataset above\u001B[39;00m\n\u001B[0;32m      5\u001B[0m \u001B[38;5;66;03m#                   Possibly reference: https://github.com/haoyfan/AnomalyDAE/blob/master/src/run.py   for a solution\u001B[39;00m\n\u001B[0;32m      6\u001B[0m \n\u001B[0;32m      7\u001B[0m \u001B[38;5;66;03m# model.forward_model(data)\u001B[39;00m\n\u001B[0;32m      9\u001B[0m \u001B[38;5;28mprint\u001B[39m(data\u001B[38;5;241m.\u001B[39mbatch)\n",
      "\u001B[1;31mNameError\u001B[0m: name 'AnomalyDAE' is not defined"
     ]
    }
   ],
   "source": [
    "model = AnomalyDAE()\n",
    "\n",
    "\n",
    "# ---------- having trouble running the statement below, bc I need to resolve the uncertainties about what the code is referencing from the dataset above\n",
    "#                   Possibly reference: https://github.com/haoyfan/AnomalyDAE/blob/master/src/run.py   for a solution\n",
    "\n",
    "# model.forward_model(data)\n",
    "\n",
    "print(data.batch)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
